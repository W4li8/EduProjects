{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7aeb0ad91d5c963a1b0cde78eb547227",
     "grade": false,
     "grade_id": "cell-67dd05f3d01a8340",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src=\"https://www.epfl.ch/about/overview/wp-content/uploads/2020/07/logo-epfl-1024x576.png\" style=\"padding-right:10px;width:140px;float:left\"></td>\n",
    "<h2 style=\"white-space: nowrap\">Image Processing Laboratory Notebooks</h2>\n",
    "<hr style=\"clear:both\">\n",
    "<p style=\"font-size:0.85em; margin:2px; text-align:justify\">\n",
    "This Juypter notebook is part of a series of computer laboratories which are designed\n",
    "to teach image-processing programming; they are running on the EPFL's Noto server. They are the practical complement of the theoretical lectures of the EPFL's Master course <b>Image Processing II</b> \n",
    "(<a href=\"https://moodle.epfl.ch/course/view.php?id=463\">MICRO-512</a>) taught by Dr. D. Sage, Dr. M. Liebling, Prof. M. Unser and Prof. D. Van de Ville.\n",
    "</p>\n",
    "<p style=\"font-size:0.85em; margin:2px; text-align:justify\">\n",
    "The project is funded by the Center for Digital Education and the School of Engineering. It is owned by the <a href=\"http://bigwww.epfl.ch/\">Biomedical Imaging Group</a>. \n",
    "The distribution or the reproduction of the notebook is strictly prohibited without the written consent of the authors.  &copy; EPFL 2021.\n",
    "</p>\n",
    "<p style=\"font-size:0.85em; margin:0px\"><b>Authors</b>: \n",
    "    <a href=\"mailto:pol.delaguilapla@epfl.ch\">Pol del Aguila Pla</a>, \n",
    "    <a href=\"mailto:kay.lachler@epfl.ch\">Kay Lächler</a>,\n",
    "    <a href=\"mailto:alejandro.nogueronaramburu@epfl.ch\">Alejandro Noguerón Arámburu</a>,\n",
    "    <a href=\"mailto:daniel.sage@epfl.ch\">Daniel Sage</a>, and\n",
    "    <a href=\"mailto:kamil.seghrouchni@epfl.ch\">Kamil Seghrouchni</a>.\n",
    "     \n",
    "</p>\n",
    "<hr style=\"clear:both\">\n",
    "<h1>Lab 5.2: Geometric transformation - Applications</h1>\n",
    "<div style=\"background-color:#F0F0F0;padding:4px\">\n",
    "    <p style=\"margin:4px;\"><b>Released</b>: Monday April 12, 2021</p>\n",
    "    <p style=\"margin:4px;\"><b>Submission</b>: <span style=\"color:red\">Tuesday April 20, 2021</span> (before 11:59PM) on <a href=\"https://moodle.epfl.ch/course/view.php?id=463\">Moodle</a></p>\n",
    "    <p style=\"margin:4px;\"><b>Grade weigth</b> Lab 5 (25 points): 7.5 % of the overall grade</p>\n",
    "    <p style=\"margin:4px;\"><b>Remote help</b>: Thursday 15 and Monday 19 April, 2021 on Zoom (see Moodle for link)</p>    \n",
    "    <p style=\"margin:4px;\"><b>Related lectures</b>: Chapter 7</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Name: \n",
    "### SCIPER: \n",
    "\n",
    "Double-click on this cell and fill your name and SCIPER number. Then, run the cell below to verify your identity in Noto and set the seed for random results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0548867981f4cb15c61eef63b431d425",
     "grade": true,
     "grade_id": "cell-9972da644c816f1b",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCIPER: 286557\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "# This line recovers your camipro number to mark the images with your ID\n",
    "uid = int(getpass.getuser().split('-')[2]) if len(getpass.getuser().split('-')) > 2 else ord(getpass.getuser()[0])\n",
    "print(f'SCIPER: {uid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c30d73d8bad8da97b6b6b477b0e0a22f",
     "grade": false,
     "grade_id": "cell-d61777f1057378a0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## <a name=\"imports_\"></a> Imports\n",
    "In the next cell we import standard Python libraries that we will use throughout the lab, as well as the following libraries that are required for the exercises:\n",
    "\n",
    "* [`matplotlib.pyplot`](https://matplotlib.org/3.2.2/api/_as_gen/matplotlib.pyplot.html), to display images,\n",
    "* [`ipywidgets`](https://ipywidgets.readthedocs.io/en/latest/), to make the image display interactive,\n",
    "* [`numpy`](https://numpy.org/doc/stable/reference/index.html), for mathematical operations on arrays,\n",
    "* [`openCV` (cv2)](https://docs.opencv.org/2.4/index.html), for image processing tasks,\n",
    "* [`scipy`(scipy)](https://www.scipy.org), also for image processing tasks.\n",
    "\n",
    "Moreover, we will import the `IPLabViewer()` class (see documentation [here](https://github.com/poldap/IPLABs2020/wiki/Python-ImageViewer()-class), or run the python command `help(ImageViewer)` after loading the class), created specifically for this course, which provides interactive image visualization based on the `ipywidgets` library.\n",
    "\n",
    "Finally, we load the images you will use in the exercise to test your routines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9e551d6e8c5a44e019fc55aba21f425",
     "grade": false,
     "grade_id": "cell-964042fb8296d105",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Configure plotting as dynamic\n",
    "%matplotlib widget\n",
    "\n",
    "# Import standard required packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import ipywidgets as widgets\n",
    "from scipy import ndimage\n",
    "import warnings\n",
    "# Import IPLabViewer() Class\n",
    "from lib.iplabs import IPLabViewer as viewer\n",
    "\n",
    "# Load images to be used in this lab\n",
    "sicilia_map = cv.imread('images/sicilia_map.png',cv.IMREAD_UNCHANGED).astype(np.float64)\n",
    "sicilia_photo = cv.imread('images/sicilia_photo.png',cv.IMREAD_UNCHANGED).astype(np.float64)\n",
    "EPFL_map = cv.imread('images/EPFL_map.png',cv.IMREAD_UNCHANGED).astype(np.float64)\n",
    "EPFL_photo= cv.imread('images/EPFL_photo.png',cv.IMREAD_UNCHANGED).astype(np.float64)\n",
    "eiffel  = cv.imread('images/eiffel.png',cv.IMREAD_UNCHANGED).astype(np.float64)\n",
    "alsace = cv.imread('images/alsace.png',cv.IMREAD_UNCHANGED).astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cf0a1a7244f028e3746f3fa6153ed45d",
     "grade": false,
     "grade_id": "cell-39492e60020936d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Geometric transformation applications  (10 points)\n",
    "\n",
    "In this part of the laboratory we will first compare the various interpolators you have studied in Part 1 in more detail, and then we will use geometric transformations for several applications. You will learn about *image registration*, *image distortion*, and how to use Python for other image processing applications. We will only cover two-dimensional graylevel geometric transformations, but keep in mind that the same operations can easily be adapted to color images by treating each color channel as an independent graylevel image.\n",
    "\n",
    "<div class = 'alert alert-info'>\n",
    "\n",
    "**Note:** This part of the lab will be carried out completely in Python. Before starting, you should have completed the [first part](./1_GT_Implementations.ipynb) of this lab and understood how to use [`cv.getRotationMatrix2D`](https://docs.opencv.org/3.4/da/d54/group__imgproc__transform.html#gafbbc470ce83812914a70abfb604f4326) and [`ndimage.affine_transform`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.affine_transform.html#scipy-ndimage-affine-transform) to perform geometric transformations in Python.\n",
    "</div>\n",
    "\n",
    "## Index\n",
    "1. [Comparison of interpolators](#1.-Comparison-of-interpolators-(4-points)) **(4 points)** \n",
    "2. [Image registration](#2.-Image-registration)\n",
    "    1. [Implementation](#2.A.-Implementation-(3-points)) **(3 points)** \n",
    "    2. [Experimentation](#2.B.-Experimentation)\n",
    "3. [Image distortion](#3.-Image-distortion)\n",
    "    1. [Implementation](#3.A.-Implementation-(3-points)) **(3 points)**\n",
    "    2. [Experimentation](#3.B.-Experimentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bfb8af9a15a012dd89e01ffb87bb5c3b",
     "grade": false,
     "grade_id": "cell-a6bb851ffcb397ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Visualize images\n",
    "Use the next cell to get familiar with the images you are going to be using. Remember that you can use `Next` / `Prev` to cycle through the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71ca276b6beee538dede8bcdc15ace0a",
     "grade": false,
     "grade_id": "cell-eb50e679ac96398d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05255bdc0e34ecc9e1a109481df0162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display images\n",
    "image_list = [sicilia_map , sicilia_photo, EPFL_map, EPFL_photo, eiffel, alsace]\n",
    "\n",
    "plt.close('all')\n",
    "imgs_viewer = viewer(image_list, widgets = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e4db24c15743b2853b047ab816dd45e",
     "grade": false,
     "grade_id": "cell-0591e6054f6cd0e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 1. Comparison of interpolators (4 points)\n",
    "[Back to index](#Index)\n",
    "\n",
    "In the last cell of Part 1 you already got a glimpse of what difference a good interpolator can make on an image transformation. In this part, we will use Python to perform a numerical comparison of the three interpolators we studied there. To make the rest of the code simpler and easier to read, we will first redefine the transform function in Python. \n",
    "\n",
    "In the next cell, **for 2 points**, implement the function `transform(img, angle, scaling, center, order)` that takes as input parameters\n",
    "\n",
    "* `img`: the original image,\n",
    "* `angle`: the angle of rotation in degrees,\n",
    "* `scaling`: the scaling factor,\n",
    "* `center`: the center of rotation following NumPy indexing protocols, i.e., ($c_2$, $c_1$),\n",
    "* `order`: the order of interpolation to use (`0` = nearest neighbor, `1` = linear, and `3` = cubic),\n",
    "\n",
    "and returns\n",
    "\n",
    "* `out`: the transformed image.\n",
    "\n",
    "<div class='alert alert-danger'>\n",
    "\n",
    "**Important:** Only use the two functions `cv.getRotationMatrix2D(center, angle, scale)` and `ndimage.affine_transform(img, matrix, order)`. If you don't remember how to do it, look at [Section 1.D](./1_GT_Implementations.ipynb/#1.D.-Geometric-transformations-in-Python-(1-point)) of the first notebook.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4c07d43dd2fe5f0850f148c88cf4fb4",
     "grade": false,
     "grade_id": "cell-37ef81303cdf82aa",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def transform(img, angle, scaling, center, order):\n",
    "    out = np.zeros(img.shape)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    M = cv.getRotationMatrix2D(center, angle, 1/scaling)\n",
    "    out = ndimage.affine_transform(img, M, order=order)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "31fdfb444fb9de9ee767392e80450c10",
     "grade": false,
     "grade_id": "cell-239efcc2a07bbb12",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the next cell for a quick sanity check. In it, we also define the function `SNR` that calculates the signal-to-noise ratio between two images, which we will use for the upcoming analysis.\n",
    "\n",
    "<div class = 'alert alert-danger'>\n",
    "\n",
    "**Note:** Remember that this is **NOT** a definitive test, and the fact that the cell runs does not guarantee that you will get the points. \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f2b458fdef940a26cb213ea260f5024",
     "grade": true,
     "grade_id": "cell-741f29d71134af53",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c030c58c0e3a41d588c0cf71917bacf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f580f9dc5654fdaa5da3729801535be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice! Your transform function passed the sanity check.\n"
     ]
    }
   ],
   "source": [
    "# Define test image\n",
    "test_img = np.zeros((7,7)); test_img[1:6, 1:6] = 255; test_img[2:5, 2:5] = 0\n",
    "correct = []\n",
    "correct.append(np.array([[  0.,   0.,   0.,   0., 255., 255., 255.], \n",
    "                         [  0.,   0.,   0., 255.,   0.,   0., 255.],\n",
    "                         [  0.,   0., 255., 255.,   0.,   0.,   0.], \n",
    "                         [  0.,   0.,   0., 255., 255.,   0., 255.],\n",
    "                         [  0.,   0.,   0.,   0., 255., 255., 255.], \n",
    "                         [  0.,   0.,   0.,   0.,   0., 255.,   0.],\n",
    "                         [  0.,   0.,   0.,   0.,   0.,   0.,   0.]]))\n",
    "correct.append(np.array([[  0.,   0.,   0.,   0., 200., 193., 164.], \n",
    "                         [  0.,   0.,   0., 200., 109.,   0., 146.],\n",
    "                         [  0.,   0., 129., 193.,   0.,   0.,   0.], \n",
    "                         [  0.,   0.,   0., 164., 146.,   0., 182.],\n",
    "                         [  0.,   0.,   0.,   0., 164., 224., 128.], \n",
    "                         [  0.,   0.,   0.,   0.,   0.,  82.,   0.],\n",
    "                         [  0.,   0.,   0.,   0.,   0.,   0.,   0.]]))\n",
    "correct.append(np.array([[  0.,   0.,   0.,  -0., 215., 259., 171.], \n",
    "                         [  0.,   0.,  -0., 215., 134., -59., 181.],\n",
    "                         [  0.,   0., 115., 259., -59.,  -4., -40.], \n",
    "                         [  0.,   0.,   0., 171., 181., -40., 224.],\n",
    "                         [  0.,   0.,   0.,   0., 172., 299., 120.], \n",
    "                         [  0.,   0.,   0.,   0.,   0.,  59.,   0.],\n",
    "                         [  0.,   0.,   0.,   0.,   0.,   0.,   0.]]))\n",
    "# Check the results\n",
    "orders = [0, 1, 3]\n",
    "names_interp = {0:'Nearest neighbors',1:'Linear', 3:'Cubic'}\n",
    "transformed = [np.round(transform(test_img, 45, 0.9, (0, 3), i)) for i in orders]\n",
    "names = [f'Transformed, {names_interp[i]}' for i in orders]\n",
    "plt.close('all')\n",
    "img_list = []; title_list = []; err_count = 0\n",
    "for i, o in enumerate(orders):\n",
    "    try:\n",
    "        np.testing.assert_array_almost_equal(correct[i], transformed[i])\n",
    "    except:\n",
    "        warnings.warn(f'\\nCalling transform with {names_interp[o]} interpolation did not produce the correct result. Check the images below:')\n",
    "        img_list.append(transformed[i]); img_list.append(correct[i]); img_list.append(transformed[i] - correct[i])\n",
    "        title_list.append(names[i]); title_list.append(names[i] + ' (correct)'); title_list.append('Difference')\n",
    "        err_count += 1\n",
    "\n",
    "if err_count > 0:\n",
    "    view = viewer(test_img, title=['Test image'], subplots=(1,1))\n",
    "    view_err = viewer(img_list, title=title_list, subplots=(err_count,3))\n",
    "else:\n",
    "    view = viewer([test_img] + transformed, title=['Test image'] + names, subplots=(2,2))\n",
    "    print('Nice! Your transform function passed the sanity check.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "68479115c5376ce2566571679e1293ec",
     "grade": false,
     "grade_id": "cell-90bac97696fbdfce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that we have the `transform` function ready, we can start the comparison process. In order to clearly see differences, we want to apply multiple transformations consecutively on the same image using the same interpolation. Specifically, we want to create a function that rotates an image a total of $n$ times around its center by an angle $\\alpha$. For example if $n=5$ and $\\alpha=10$, the image should be roted $5$ times by $10^{\\circ}$ around its center, and not just one time by $50^{\\circ}$. Set the scaling parameter $\\rho = 1$.\n",
    "\n",
    "In the next cell, for **2 points**, implement the function `rotate_n(img, alpha, n, order)` that takes as input parameters\n",
    "\n",
    "* `img`: the input image,\n",
    "* `alpha`: the angle of each rotation in degrees,\n",
    "* `n`: the number of times the image should be rotated by `alpha`,\n",
    "* `order`: the order of interpolation, as above,\n",
    "\n",
    "and returns:\n",
    "\n",
    "* `out`: the rotated image.\n",
    "\n",
    "<div class='alert alert-info'>\n",
    "\n",
    "**Hints:** \n",
    "* Make use of the function `transform()` that you implemented above.\n",
    "* Be careful when selecting the center point of an image. Calculating the index of the center point of an array `a` of length $2n + 1$ might not be as simple as calling `len(a)/2`. To convince yourself, you can run a simple example using a short one-dimensional array. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76bf39ec6d3a3d04cb595545bfd313e3",
     "grade": false,
     "grade_id": "cell-a03b10d684bb5d32",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Function that rotates an image n times by anlge alpha\n",
    "def rotate_n(img, alpha, n, order):\n",
    "    out = np.zeros(img.shape)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    nx, ny = img.shape\n",
    "    for i in range(n):\n",
    "        img = transform(img, angle=alpha, scaling=1, center=(ny//2, nx//2), order=order)\n",
    "    \n",
    "    out = img\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f63b6ebf3121a40a9d46a038ef9a1c8",
     "grade": false,
     "grade_id": "cell-9825fb7baf075db9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the next cell to perform a quick sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9c934ad75325873a60aafe3bd3e8e39",
     "grade": true,
     "grade_id": "cell-d22b17683b2a606a",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "926f2a2e304a4b37bd9c34b85150a3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e76f61a93d487788185ce37720c187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice! Your rotate_n function passed the sanity check.\n"
     ]
    }
   ],
   "source": [
    "# Define test image\n",
    "test_img = np.zeros((7,7)); test_img[test_img.shape[0]//2, :] = 255\n",
    "# Correct results\n",
    "correct = []\n",
    "correct.append(np.array([[  0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
    "                      [  0.,   0.,   0., 255.,   0.,   0.,   0.],\n",
    "                      [  0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
    "                      [  0.,   0., 255., 255.,   0.,   0.,   0.],\n",
    "                      [  0.,   0., 255.,   0.,   0.,   0.,   0.],\n",
    "                      [  0.,   0.,   0., 255.,   0.,   0.,   0.],\n",
    "                      [  0.,   0.,   0.,   0.,   0.,   0.,   0.]]))\n",
    "correct.append(np.array([[  0.,   0.,   0.,  56.,  25.,   0.,   0.],\n",
    "                      [  0.,   6.,  51., 161.,  26.,   0.,   0.],\n",
    "                      [  0.,   1.,  58., 121.,  57.,   0.,   0.],\n",
    "                      [  0.,   4.,  63., 255.,  63.,   4.,   0.],\n",
    "                      [  0.,   0.,  57., 121.,  58.,   1.,   0.],\n",
    "                      [  0.,   0.,  26., 161.,  51.,   6.,   0.],\n",
    "                      [  0.,   0.,  25.,  56.,   0.,   0.,   0.]]))\n",
    "correct.append(np.array([[  0.,   0.,   0.,  66., -13.,   0.,   0.],\n",
    "                      [  0.,  -8.,  31., 268.,   2.,  -7.,   0.],\n",
    "                      [  2., -14.,  13., 200.,  32.,  -8.,   0.],\n",
    "                      [  3., -15.,  28., 255.,  28., -15.,   3.],\n",
    "                      [  0.,  -8.,  32., 200.,  13., -14.,   2.],\n",
    "                      [  0.,  -7.,   2., 268.,  31.,  -8.,   0.],\n",
    "                      [  0.,   0., -13.,  66.,   0.,   0.,   0.]]))\n",
    "orders = [0, 1, 3]\n",
    "# Rotate 3 times by 30 degrees\n",
    "rotated = [np.round(rotate_n(test_img, alpha=30, n=3, order=o)) for o in orders]\n",
    "# Check if correct\n",
    "names_interp = {0:'Nearest neighbors',1:'Linear', 3:'Cubic'}\n",
    "names = [f'Rotated 3x30, {names_interp[i]}' for i in orders]\n",
    "plt.close('all')\n",
    "img_list = []; title_list = []; err_count = 0\n",
    "for i, o in enumerate(orders):\n",
    "    try:\n",
    "        np.testing.assert_array_almost_equal(correct[i], rotated[i])\n",
    "    except:\n",
    "        warnings.warn(f'\\nCalling rotate_n with {names_interp[o]} interpolation did not produce the correct result. Check the images below:')\n",
    "        img_list.append(rotated[i]); img_list.append(correct[i]); img_list.append(rotated[i] - correct[i])\n",
    "        title_list.append(names[i]); title_list.append(names[i] + ' (correct)'); title_list.append('Difference')\n",
    "        err_count += 1\n",
    "if err_count > 0:\n",
    "    view = viewer(test_img, title=['Test image'], subplots=(1,1))\n",
    "    view_err = viewer(img_list, title=title_list, subplots=(err_count,3))\n",
    "else:\n",
    "    view = viewer([test_img] + rotated, title=['Test image'] + names, subplots=(2,2))\n",
    "    print('Nice! Your rotate_n function passed the sanity check.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73719d88fb983811aef9e2fd1d2d4800",
     "grade": false,
     "grade_id": "cell-3a706ef3ef0830e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the cell below, we provide you with a viewer where you can play around with the `rotate_n` function to get a feeling for why a good interpolation is so important.\n",
    "<div class = 'alert alert-success'>\n",
    "    \n",
    "**Note**: If you want to see some cool artifacts from nearest neighbor interpolation, try very small angles of rotation. This will also show the improvement from the other interpolators. An example to start trying: $\\alpha=4.5^{\\circ}$, $n=10$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33319f5a343a79e1070857527e8af008",
     "grade": false,
     "grade_id": "cell-299ce91068a89d30",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "584d58e2bcf64aeab5528b2d153d4d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the sliders and button\n",
    "alpha_slider = widgets.FloatSlider(value=0, min=-90, max=90, step=0.5, description='α')\n",
    "n_slider = widgets.IntSlider(value=5, min=1, max=10, description='n')\n",
    "order_dropdown = widgets.Dropdown(options=['0: Nearest neighbor', '1: Linear', '3: Cubic'], value='1: Linear', description='order:', disabled=False)\n",
    "order_dictionary = {'0: Nearest neighbor':0, '1: Linear':1, '3: Cubic':3}\n",
    "button = widgets.Button(description='Apply rotations')\n",
    "\n",
    "# Rotate and scale callback function \n",
    "def rotate_n_callback(img):\n",
    "    # retreive slider values for angle, scale and center\n",
    "    alpha = alpha_slider.value\n",
    "    n = n_slider.value\n",
    "    order = order_dictionary[order_dropdown.value]\n",
    "    # Perform n rotations by alpha\n",
    "    return rotate_n(img, alpha, n, order)\n",
    "\n",
    "# Visualize angle and scale effect during transformation\n",
    "plt.close(\"all\")\n",
    "view = viewer([alsace], title = 'Alsace', new_widgets = [order_dropdown, alpha_slider, n_slider, button], \n",
    "              callbacks = [rotate_n_callback], widgets = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "891c9f30c31969c3ffcd7f429092e102",
     "grade": false,
     "grade_id": "cell-95ea9728b7c8f6c3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In case you still haven't been convinced by the cubic interpolation, let us now plot the signal to noise ratio of the three interpolators when rotating an image $n$ times by $35^{\\circ}$ and then $n$ times by $-35^{\\circ}$. Run the next cell to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d55e036185f7951ca4a49866ef2a487",
     "grade": false,
     "grade_id": "cell-e3172c82236e2c6f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca7699aada44068a52b0a1d8b4e0100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Pan', 'Pan axes with left…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function that computes the signal to noise ratio between two images\n",
    "def SNR(img, img_ref):\n",
    "    return 10*np.log10(np.sum(img.astype(np.float64)**2)/np.sum((img_ref.astype(np.float64)-img.astype(np.float64))**2))\n",
    "# Rotate images up to 10 times by 35 degrees and back\n",
    "alpha = 35\n",
    "ns = np.arange(1, 11, dtype=int)\n",
    "snr_nn  = [SNR(rotate_n(rotate_n(alsace, alpha, n, 0), -alpha, n, 0), alsace) for n in ns]\n",
    "snr_lin = [SNR(rotate_n(rotate_n(alsace, alpha, n, 1), -alpha, n, 1), alsace) for n in ns]\n",
    "snr_cub = [SNR(rotate_n(rotate_n(alsace, alpha, n, 3), -alpha, n, 3), alsace) for n in ns]\n",
    "# Display graphs\n",
    "plt.close('all'); plt.figure()\n",
    "plt.plot(ns, snr_nn,  label='nn')\n",
    "plt.plot(ns, snr_lin, label='linear')\n",
    "plt.plot(ns, snr_cub, label='cubic')\n",
    "plt.legend(); plt.title('SNR of images rotated n times by $35^{\\circ}$ and back')\n",
    "plt.grid()\n",
    "plt.ylabel('SNR [dB]'); plt.xlabel('n'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Image registration\n",
    "[Back to index](#Index)\n",
    "\n",
    "In this section you will use your newly gained knowledge in image transformation to align two images in terms of rotation and zoom. In our example, we will use a map and a satellite image of Sicily. Since these two images are not aligned, one of the two images should be transformed to match the other one using the `transform()` function defined in the first part. Let's define the satellite image as the **original** image and the map image as the **target** image, so we want to align the satellite to the map image.\n",
    "\n",
    "<table><tr>\n",
    "<td>\n",
    "  <p align=\"center\" style=\"padding: 10px\">\n",
    "    <img alt=\"Routing\" src=\"images/sicilia_photo.png\" width=\"220\"><br>\n",
    "    <em style=\"color: grey\">Satellite image of Sicily</em>\n",
    "  </p> \n",
    "</td>\n",
    "<td> \n",
    "  <p align=\"center\">\n",
    "    <img src=\"images/sicilia_map.png\" alt=\"Drawing\" style=\"width: 220px;\"/><br>\n",
    "    <em style=\"color: grey\">Map of Sicily</em>\n",
    "  </p> \n",
    "</td>\n",
    "</tr></table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "979bf41ffbb13fe63abf4cd4e81511e2",
     "grade": false,
     "grade_id": "cell-8ca478440385c9b6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.A. Implementation (3 points)\n",
    "[Back to index](#Index)\n",
    "\n",
    "In order to correctly transform the original image, we need to know the angle, the scaling and the center point of the transformation. To determine these parameters, we first need to identify at least two features that are present in each image. In our case, for example, the island of Malta and the city of Messina are good candidates. Having identified those two features in both images, we can calculate the vector going from the first to the second feature in both images. Let's denote this vector in the original image by $\\mathbf{u}=[u_x, u_y]^T$ and the one in the target image by $\\mathbf{v}=[v_x, v_y]^T$. From these two vectors, we can then calculate the angle and the scale of the transformation needed to match them.\n",
    "\n",
    "The center point can be calculated by re-arranging the transformation equation\n",
    "\n",
    "$$\n",
    "(\\mathbf{v}-\\mathbf{c}) = \\mathbf{A}(\\mathbf{u} - \\mathbf{c}) \\mbox{ to obtain }\n",
    "\\mathbf{c} = (\\mathbf{A} - \\mathbf{I})^{-1}(\\mathbf{A}\\mathbf{u} - \\mathbf{v} )\\,,\n",
    "$$\n",
    "\n",
    "where $\\mathbf{A}$ is the rotation matrix.\n",
    "\n",
    "Remember that in the `transform()` function, we used `cv.getRotationMatrix2D(center, angle, scale)` with `center=(cy, cx)` and `scale=1/scaling` to obtain the **inverse** transformation matrix of size $2 \\times 3$, with the last column being the translational component. Similarly you can obtain the simple $2 \\times 2$ rotation matrix $\\mathbf{A}$ by **only keeping the first two columns** of the result of this same function, when called with `center=(0, 0)` and `scale=scaling` (remember that in *NumPy*, you can use `array = array[:,:-1]` to drop the last column of an array). \n",
    "\n",
    "For **3 points**, complete the `register()` function below, which performs the image registration explained above when given two vectors $\\mathbf{u}$ and $\\mathbf{v}$.  The function takes as input parameters\n",
    "\n",
    " * `img`): the original image, \n",
    " * `u1`: a $1 \\times 2$ NumPy array containing the (x,y) coordinates of the first point in the original image, \n",
    " * `u2`: a $1 \\times 2$ NumPy array containing the (x,y) coordinates of the second point in the original image,\n",
    " * `v1`: a $1 \\times 2$ NumPy array containing the (x,y) coordinates of the first point in the target image, \n",
    " * `v2`: a $1 \\times 2$ NumPy array containing the (x,y) coordinates of the second point in the target image,\n",
    " \n",
    "and outputs\n",
    "\n",
    " * `out`: the registered image.\n",
    "\n",
    "You will have to compute the `scaling`, `angle`, and `center` of rotation, to be used as parameters for the function `transform()`. When calling `transform()`, make sure to use cubic interpolation.\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "**Hint:** You might want to use the following functions: [`np.linalg.norm`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html), [`np.arctan2`](https://numpy.org/doc/stable/reference/generated/numpy.arctan2.html), [`np.dot`](https://numpy.org/doc/stable/reference/generated/numpy.dot.html), [`np.linalg.inv`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.inv.html) and [`np.identity`](https://numpy.org/doc/stable/reference/generated/numpy.identity.html). Check their documentation (click on their names here) if you are not familiar with them.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bba69e632ad07393e1259112259a288f",
     "grade": false,
     "grade_id": "cell-cd538ed31b6dead8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def register(img, u1, v1, u2, v2):\n",
    "    # You will have to recompute these parameters\n",
    "    angle = 0\n",
    "    scaling = 1\n",
    "    center = [0,0]\n",
    "    \n",
    "    # Compute vectors from points\n",
    "    # Vector in the original image\n",
    "    u = u2 - u1\n",
    "    # Vector in the target image\n",
    "    v = v2 - v1\n",
    "    \n",
    "    # Compute angle, scaling and center\n",
    "    # YOUR CODE HERE\n",
    "    scaling = np.linalg.norm(v)/np.linalg.norm(u)\n",
    "    angle = -(np.arctan2(v[1], v[0]) - np.arctan2(u[1], u[0]))*180/np.pi\n",
    "\n",
    "    A = cv.getRotationMatrix2D(center=(0,0), angle=angle, scale=scaling)[:,:-1] \n",
    "    center = np.linalg.inv(A - np.identity(A.shape[0])) @ (A @ u1 - v1)\n",
    "    \n",
    "    # Call the transform function with the calculated paremeters\n",
    "    return transform(img, angle=angle, scaling=scaling, center=(center[1], center[0]), order=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "03ae7484b92211a583963491969e5677",
     "grade": false,
     "grade_id": "cell-4e923ce4c4dcb720",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the cell below for a quick sanity check. The two reference points in the test image are the leftmost and rightmost points of the long line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e07768a63948fdd6fd7e5eef44acccc5",
     "grade": true,
     "grade_id": "cell-292a8bafba09f8a2",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congrats! Your register function seems correct!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5998ee3bcfc74e899c0cd6e9877e56ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01f88607a56444cb5a8631717625d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define test image target\n",
    "test_img_target = np.zeros((101,101)) \n",
    "test_img_target[50, 10:90] = 1\n",
    "test_img_target[20:50, 50] = 1\n",
    "# Transform target to create original\n",
    "test_img_original = transform(test_img_target, angle=-60, scaling=0.6, center=(70, 30), order=3)\n",
    "# Define points\n",
    "u1, u2 = np.array((35, 54)), np.array((58, 94))\n",
    "v1, v2 = np.array((10, 50)), np.array((90, 50))\n",
    "# Register image\n",
    "test_img_registered = register(test_img_original, u1, v1, u2, v2)\n",
    "# Generate correctly registered image by back-transforming the original image (with the parameters from the ref vectors)\n",
    "test_img_reg_corr = transform(test_img_original, angle=60.1011, scaling=1.7338, center=(70.2598, 30.8703), order=3)\n",
    "try:\n",
    "    np.testing.assert_array_almost_equal(test_img_registered, test_img_reg_corr, decimal=3)\n",
    "    print('Congrats! Your register function seems correct!')\n",
    "except:\n",
    "    warnings.warn('\\nThe registration function is not yet correct. Look at the images below to see the differences.')\n",
    "plt.close('all')\n",
    "view = viewer([test_img_original, test_img_target, test_img_registered, test_img_reg_corr],\n",
    "              title=['Original test image', 'Target test image', 'Your registered image', 'Correctly registered image'], \n",
    "              subplots=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec6b451da639ccbcc134da21631e4ab6",
     "grade": false,
     "grade_id": "cell-1f1909ad7c78cf1a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.B. Experimentation\n",
    "[Back to index](#Index)\n",
    "\n",
    "In this section, we are going to make direct use of your previous implementations to map the `sicilia_map` and `EPFL_map` images to `sicilia_photo` and `EPFL_photo`, respectively. For this purpose, we provide you with a viewer that allows you to select the mapping points and perform the transformations. Make sure that the reference points you select in the original image correspond to the same reference points in the target image.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "**Note:** The vectors $\\mathbf{u}=(u_1, u_2)^T$ and $\\mathbf{v}=(v_1, v_2)^T$ are specified using the viewer with `clickable=True`. Two images will displayed side by side, and you will have to click with your mouse to\n",
    "    \n",
    "1. select $u_1$ on the first image,\n",
    "2. select $v_1$ on the second image,\n",
    "3. select $u_2$ on the first image,\n",
    "4. select $v_2$ on the second image,\n",
    "\n",
    "in that order. In case you get it wrong and want to start again, you can 1) finish the selection and click again on the first image to start again, 2) click on the button *Reset* (loosing any zoom and pan you may have done), or 3) run the cell again to get a fresh new viewer. \n",
    "\n",
    "Marks will appear at the clicked point location on the selected image as well as the following display in the statistics pannel ``['click:i,x=***, y=***']``. Once the four points are selected, go to the menu `Extra Widgets` and use the button `Register Image` to perform the registration.\n",
    "\n",
    "</div>\n",
    "    \n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "**Hint:** You can also use `Options` $\\rightarrow$ `Enable Joint Zoom` to either select the points more acurately or check the results after registration!\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b13dbc41419d40652b01a301f63f6d4",
     "grade": false,
     "grade_id": "cell-2b68db4380062e31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e8412438bf4a5c8ed79608b3c13d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "button = widgets.Button(description = 'Register Image')\n",
    "\n",
    "def save_points(img, coords): \n",
    "    if len(coords) == 4: \n",
    "        u1 = np.array([coords[0]['x'],coords[0]['y']])\n",
    "        v1 = np.array([coords[1]['x'],coords[1]['y']])\n",
    "        u2 = np.array([coords[2]['x'],coords[2]['y']])\n",
    "        v2 = np.array([coords[3]['x'],coords[3]['y']])\n",
    "        #print(u1, v1, u2, v2)\n",
    "        return register(img, u1, v1, u2, v2)\n",
    "    else: \n",
    "        print('Select ', 4 - len(coords), 'points more.')\n",
    "        return img\n",
    "\n",
    "plt.close('all')\n",
    "sicily_view = viewer([sicilia_photo, sicilia_map], title = ['Sicilia map','Sicilia photo'], new_widgets=[button],\n",
    "                        callbacks=[save_points], widgets = True, subplots=(1,2), clickable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16cbf0b0089f75e24358d6dff38e0613",
     "grade": false,
     "grade_id": "cell-f555caee299a57ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's try it with the EPFL campus images. This time we align the map to the satellite image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77a3e40edcf27536cc8e059f6b23ced3",
     "grade": false,
     "grade_id": "cell-81210308b673c24c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57fd4f7f5b46429bbabdc84b9ab96b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "epfl_viewer = viewer([EPFL_map,EPFL_photo], title = ['EPFL map', 'EPFL photo'], new_widgets=[button],\n",
    "                        callbacks=[save_points], widgets = True, subplots=(1,2), clickable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Image distortion\n",
    "[Back to index](#Index)\n",
    "\n",
    "<table><tr>\n",
    "<td> \n",
    "  <p align=\"center\" style=\"padding: 10px\">\n",
    "    <img alt=\"Forwarding\" src=\"images/distort1.png\" width=\"220\">\n",
    "    <br>\n",
    "    <em style=\"color: grey\">Eiffel tower </em>\n",
    "  </p> \n",
    "</td>\n",
    "<td> \n",
    "  <p align=\"center\">\n",
    "    <img alt=\"Routing\" src=\"images/distort2.png\" width=\"220\">\n",
    "    <br>\n",
    "    <em style=\"color: grey\">Distorted Eiffel tower</em>\n",
    "  </p> \n",
    "</td>\n",
    "</tr></table>\n",
    "\n",
    "In this section, your job is to complete the function `distortion()`. This function distorts an image by setting the value in the target image position $\\mathbf{x_1}=(i_1, j_1)$ that was in position $\\mathbf{x_2}=(i_2, j_2)$ in the original image, with the pixel-wise relation\n",
    "\n",
    "$$\n",
    "i_2 = i_1 + \\delta(i_1,j_1)(u_i - v_i) \\mbox{, and }j_2 = j_1 + \\delta(i_1,j_1) (u_j - v_j)\\,.\n",
    "$$\n",
    "\n",
    "Here, two points $\\mathbf{u} = (u_i, u_j)$ and $\\mathbf{v} = (v_i, v_j)$ specify the direction of the displacement, while the magnitude is regulated by $\\delta(i_1,j_1)$ as\n",
    "\n",
    "$$\n",
    "\\delta(i_1,j_1) = \\exp\\left(-\\frac{(i_1 - v_i)^2 + (j_1 - v_j)^2}{k^2}\\right)\\,.\n",
    "$$\n",
    "\n",
    "Note that in the particular case where $\\mathbf{x_1}=\\mathbf{v}$ in the target image, the resulting value in the original image is taken from $\\mathbf{x_2}=\\mathbf{u}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ad71ab48944788cb3bc6446d585ed63e",
     "grade": false,
     "grade_id": "cell-775c3075098584ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.A. Implementation (3 points)\n",
    "[Back to index](#Index)\n",
    "\n",
    "Make sure to understand the proposed operation before starting to code, and **for 1 point** answer the following MCQ:\n",
    "\n",
    "* Q1: What happens when we **increase** the parameter $k$?\n",
    "\n",
    "    1. The direction of the distortion will be more horizontal,\n",
    "    2. the direction of the distortion will be more vertical,\n",
    "    3. a larger area of the image will be affected by the distortion, or\n",
    "    4. a smaller area of the image will be affected by the distortion.\n",
    "\n",
    "<div class=\" alert alert-info\">\n",
    "\n",
    "**Note:** To answer, change the variable `answer` in the cell below to the number corresponding to your choice. Then run the cell below to check that your answer is valid. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48c2b4b69f00af67328e24157507d03d",
     "grade": false,
     "grade_id": "cell-2cd9b76cc1aeb1aa",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Modify the variable answer\n",
    "answer = 3\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d82d81c562dec987d09d45a7c27e2ab",
     "grade": true,
     "grade_id": "cell-d2ccf681162b855b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "assert answer in [1, 2, 3, 4], 'Valid answers are 1, 2, 3 and 4.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87b8f9dad4ceea1c4fb8a4a59441ecbc",
     "grade": false,
     "grade_id": "cell-5b7ec3a51a3e14d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**For 2 points**, complete the function `distort` in the next cell. The function `distort(i, j, u_i, u_j, v_i, v_j, k)` takes as input parameters\n",
    "\n",
    "* `i`: $i_1$,\n",
    "* `j`: $j_1$,\n",
    "* `u_i`: $u_i$,\n",
    "* `u_j`: $u_j$,\n",
    "* `v_i`: $v_i$,\n",
    "* `v_j`: $v_j$, and\n",
    "* `k`: $k$,\n",
    "    \n",
    "and returns\n",
    "\n",
    "* `i_new`, `j_new`: $i_2$, $j_2$.\n",
    "\n",
    "<div class = 'alert alert-info'>\n",
    "\n",
    "**Hint**: For the exponential function, use [`np.exp`](https://numpy.org/doc/stable/reference/generated/numpy.exp.html).\n",
    "</div>\n",
    "<div class = 'alert alert-warning'>\n",
    "\n",
    "**Beware**: Make sure to calculate `i_new` and `j_new` separately (don't perform any vector calculations). We will call the `distort()` function passing two-dimensional arrays in `i` and `j`, so putting them together in a vector would probably fail and/or complicate the implementation unnecessarily.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e7ab5d15273a642c5c8bd317b280a2d8",
     "grade": false,
     "grade_id": "cell-6bf7b6777cd2fd8f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Function that distorts an image along the vector (v_i, v_j) - (u_i, u_j)\n",
    "def distort(i, j, u_i, u_j, v_i, v_j, k):\n",
    "    # Initialize new indices i_new and j_new of the distorted image\n",
    "    i_new = i\n",
    "    j_new = j\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    d = np.exp(-((i-v_i)**2 + (j-v_j)**2) / k**2)\n",
    "    i_new = i + d*(u_i - v_i)\n",
    "    j_new = j + d*(u_j - v_j)\n",
    "    \n",
    "    return i_new, j_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a485a32e096971748ea9d685345a6b3",
     "grade": false,
     "grade_id": "cell-f7b9e869f65f5381",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let us perform a sanity check on the `distort` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6aad13c8cf8b1908c7dab3bc3b583818",
     "grade": true,
     "grade_id": "cell-b00af28241ddffda",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your distorted i-coordinates:\n",
      "[[1.711 1.85  1.938 1.969 1.938]\n",
      " [2.738 2.879 2.969 3.    2.969]\n",
      " [3.711 3.85  3.938 3.969 3.938]\n",
      " [4.632 4.765 4.85  4.879 4.85 ]\n",
      " [5.51  5.632 5.711 5.738 5.711]]\n",
      "\n",
      "Your distorted j-coordinates:\n",
      "[[-1.711 -0.85   0.062  1.031  2.062]\n",
      " [-1.738 -0.879  0.031  1.     2.031]\n",
      " [-1.711 -0.85   0.062  1.031  2.062]\n",
      " [-1.632 -0.765  0.15   1.121  2.15 ]\n",
      " [-1.51  -0.632  0.289  1.262  2.289]]\n",
      "\n",
      "Well done! Your distort function passed the sanity check.\n"
     ]
    }
   ],
   "source": [
    "# Define correct distorted indices\n",
    "i_corr = np.array([[ 1.711,  1.85 ,  1.938,  1.969,  1.938], [ 2.738,  2.879,  2.969,  3.   ,  2.969],\n",
    "                   [ 3.711,  3.85 ,  3.938,  3.969,  3.938], [ 4.632,  4.765,  4.85 ,  4.879,  4.85 ],\n",
    "                   [ 5.51 ,  5.632,  5.711,  5.738,  5.711]])\n",
    "j_corr = np.array([[-1.711, -0.85 ,  0.062,  1.031,  2.062], [-1.738, -0.879,  0.031,  1.   ,  2.031],\n",
    "                   [-1.711, -0.85 ,  0.062,  1.031,  2.062], [-1.632, -0.765,  0.15 ,  1.121,  2.15 ],\n",
    "                   [-1.51 , -0.632,  0.289,  1.262,  2.289]])\n",
    "# Define the distortion parameters\n",
    "u = [3, 1]\n",
    "v = [1, 3]\n",
    "k = 8\n",
    "# Call the distortion function on the indices of a 5x5 image\n",
    "idxs = np.round(np.fromfunction(lambda i, j: distort(i, j, u[0], u[1], v[0], v[1], k), shape=(5,5)), 3)\n",
    "print(f'Your distorted i-coordinates:\\n{idxs[0]}\\n\\nYour distorted j-coordinates:\\n{idxs[1]}\\n')\n",
    "# Compare the result\n",
    "check_error = False\n",
    "try:\n",
    "    np.testing.assert_array_almost_equal(i_corr, idxs[0], decimal=3)\n",
    "except:\n",
    "    warnings.warn(f'\\nYour distorted i-coordinates are not yet correct.\\n\\nCorrectly distorted i-coordinates:\\n{i_corr}\\n')\n",
    "    check_error = True\n",
    "try:\n",
    "    np.testing.assert_array_almost_equal(j_corr, idxs[1], decimal=3)\n",
    "except:\n",
    "    warnings.warn(f'\\nYour distorted j-coordinates are not yet correct.\\n\\nCorrectly distorted j-coordinates:\\n{j_corr}\\n')\n",
    "    check_error = True\n",
    "if not check_error:\n",
    "    print('Well done! Your distort function passed the sanity check.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a1e2e62f4a062330f30e5970d12a4ce3",
     "grade": false,
     "grade_id": "cell-a287dc129bf2975f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.B. Experimentation\n",
    "[Back to index](#Index)\n",
    "\n",
    "Now we will again create an interactive viewer so that you can play around with the `distort()` function. Like in in the `register()` experimentation, you can click on the image to define the points $\\mathbf{u}$ and $\\mathbf{v}$ and then click on `Distort` to apply the distortion. Additionally you can choose the value for the parameter $k$ with the slider. You will need to click on the `Distort` button again to apply any new value for $k$.\n",
    "\n",
    "If you look at the code below, you can see that we apply your distort function to all pixel locations of the eiffel image, using [`np.fromfunction`](https://numpy.org/doc/stable/reference/generated/numpy.fromfunction.html). This gives us all the distorted pixel indices for the entire image, which we can then interpolate with a cubic spline interpolation by using the function [`ndimage.map_coordinates`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.map_coordinates.html). If you're interested, you can go check out their documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df4e54788dad6f82563d453cbb061826",
     "grade": false,
     "grade_id": "cell-59f5ca5f5e4db16b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a177f2c979480fa9c63e458e8d773a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create slider for k and distort button\n",
    "k_slider = widgets.IntSlider(value=64, min=1, max=256, description='k')\n",
    "button = widgets.Button(description = 'Distort')\n",
    "# Callback function\n",
    "def distort_callback(img, coords): \n",
    "    if len(coords) == 2: \n",
    "        # Get distortion parameters\n",
    "        k = k_slider.value\n",
    "        u = (coords[0]['y'], coords[0]['x'])\n",
    "        v = (coords[1]['y'], coords[1]['x'])\n",
    "        # Calculate new indices using the distort funciton\n",
    "        idxs = np.fromfunction(lambda i, j: distort(i, j, u[0], u[1], v[0], v[1], k=k), shape=img.shape)\n",
    "        # Cubic interpolation with map_coordinates\n",
    "        return ndimage.map_coordinates(img, idxs, order=3, mode='constant').reshape(img.shape)\n",
    "    else:\n",
    "        print('Select ', 2- len(coords), 'points more.')\n",
    "        return img\n",
    "\n",
    "# Create viewer\n",
    "plt.close('all')\n",
    "distort_view = viewer(eiffel, widgets = True, new_widgets=[k_slider, button], callbacks=[distort_callback], clickable=True, line=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43e4ee011699c7e126863ba90c6c14df",
     "grade": false,
     "grade_id": "cell-4c02d6ed2df2aa9c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "<p><b>Congratulations on finishing the second part of the geometric transformation lab!</b></p>\n",
    "<p>\n",
    "Make sure to save your notebook (you might want to keep a copy on your personal computer) and upload it to <a href=\"https://moodle.epfl.ch/mod/assign/view.php?id=1146081\">Moodle</a>, in a zip file with other notebooks of this lab.\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "* Name the notebook: *SCIPER_2_GT_Applications.ipynb* (e.g. *123456_2_GT_Applications.ipynb*),\n",
    "* Name the zip file: *SCIPER_Geometric_Transformation_Lab.zip* (e.g. *123456_Geometric_Transformation_Lab.zip*).\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<h4>Feedback</h4>\n",
    "    <p style=\"margin:4px;\">\n",
    "    This is the first edition of the image-processing laboratories using Jupyter Notebooks running on Noto. Do not leave before giving us your <a href=\"https://moodle.epfl.ch/mod/feedback/view.php?id=1146079\">feedback here!</a></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
