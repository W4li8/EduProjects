{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d2146253b160e73b4b72428be1bf9448",
     "grade": false,
     "grade_id": "cell-da500ff8cea1b918",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src=\"https://www.epfl.ch/about/overview/wp-content/uploads/2020/07/logo-epfl-1024x576.png\" style=\"padding-right:10px;width:140px;float:left\"></td>\n",
    "<h2 style=\"white-space: nowrap\">Image Processing Laboratory Notebooks</h2>\n",
    "<hr style=\"clear:both\">\n",
    "<p style=\"font-size:0.85em; margin:2px; text-align:justify\">\n",
    "This Juypter notebook is part of a series of computer laboratories which are designed\n",
    "to teach image-processing programming; they are running on the EPFL's Noto server. They are the practical complement of the theoretical lectures of the EPFL's Master course <b>Image Processing II</b> \n",
    "(<a href=\"https://moodle.epfl.ch/course/view.php?id=463\">MICRO-512</a>) taught by Dr. D. Sage, Dr. M. Liebling, Prof. M. Unser and Prof. D. Van de Ville.\n",
    "</p>\n",
    "<p style=\"font-size:0.85em; margin:2px; text-align:justify\">\n",
    "The project is funded by the Center for Digital Education and the School of Engineering. It is owned by the <a href=\"http://bigwww.epfl.ch/\">Biomedical Imaging Group</a>. \n",
    "The distribution or the reproduction of the notebook is strictly prohibited without the written consent of the authors.  &copy; EPFL 2021.\n",
    "</p>\n",
    "<p style=\"font-size:0.85em; margin:0px\"><b>Authors</b>: \n",
    "    <a href=\"mailto:pol.delaguilapla@epfl.ch\">Pol del Aguila Pla</a>, \n",
    "    <a href=\"mailto:kay.lachler@epfl.ch\">Kay Lächler</a>,\n",
    "    <a href=\"mailto:alejandro.nogueronaramburu@epfl.ch\">Alejandro Noguerón Arámburu</a>,\n",
    "    <a href=\"mailto:daniel.sage@epfl.ch\">Daniel Sage</a>, and\n",
    "    <a href=\"mailto:kamil.seghrouchni@epfl.ch\">Kamil Seghrouchni</a>.\n",
    "     \n",
    "</p>\n",
    "<hr style=\"clear:both\">\n",
    "<h1>Lab 6.1: The wavelet transform</h1>\n",
    "<div style=\"background-color:#F0F0F0;padding:4px\">\n",
    "    <p style=\"margin:4px;\"><b>Released</b>: Thursday April 22, 2021</p>\n",
    "    <p style=\"margin:4px;\"><b>Submission</b>: <span style=\"color:red\">Friday April 30, 2021</span> (before 11:59PM) on <a href=\"https://moodle.epfl.ch/course/view.php?id=463\">Moodle</a></p>\n",
    "    <p style=\"margin:4px;\"><b>Grade weigth</b> (Lab 6, 17 points): 7.5 % of the overall grade</p>\n",
    "    <p style=\"margin:4px;\"><b>Remote help</b>: Monday 26 and Thursday 29 of April, 2021 on Zoom (see Moodle for link)</p>    \n",
    "    <p style=\"margin:4px;\"><b>Related lectures</b>: Chapter 8</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Student Name: \n",
    "\n",
    "### SCIPER: \n",
    "\n",
    "Double-click on this cell and fill your name and SCIPER number. Then, run the cell below to verify your identity in Noto and set the seed for random results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d921adbb001e935ddc50d99baeaf024",
     "grade": true,
     "grade_id": "cell-fe844979884903ce",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCIPER: 286557\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "# This line recovers your camipro number to mark the images with your ID\n",
    "uid = int(getpass.getuser().split('-')[2]) if len(getpass.getuser().split('-')) > 2 else ord(getpass.getuser()[0])\n",
    "print(f'SCIPER: {uid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "35a34d5c12c7ddc1e3254f66c435a792",
     "grade": false,
     "grade_id": "cell-b49b50603d5e20e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## <a name=\"imports_\"></a> Imports\n",
    "In the next cell we import standard Python libraries that we will use throughout the lab, as well as the following libraries that are required for the exercises:\n",
    "\n",
    "* [`matplotlib.pyplot`](https://matplotlib.org/3.2.2/api/_as_gen/matplotlib.pyplot.html), to display images,\n",
    "* [`ipywidgets`](https://ipywidgets.readthedocs.io/en/latest/), to make the image display interactive,\n",
    "* [`numpy`](https://numpy.org/doc/stable/reference/index.html), for mathematical operations on arrays,\n",
    "* [openCV (`cv2`)](https://docs.opencv.org/2.4/index.html), for image processing tasks,\n",
    "* [`scipy.ndimage`](https://docs.scipy.org/doc/scipy/reference/ndimage.html), for more image processing tasks,\n",
    "* [PyWavelets (`pywt`)](https://pywavelets.readthedocs.io/en/latest/), to calculate wavelet transforms.\n",
    "\n",
    "Moreover, we will import the `IPLabViewer()` class (see documentation [here](https://github.com/Biomedical-Imaging-Group/IPLabImageViewer/wiki/Python-IPLabViewer()-Class), or run the python command `help(ImageViewer)` after loading the class), created specifically for this course, which provides interactive image visualization based on the `ipywidgets` library.\n",
    "\n",
    "As you can see, in this lab we will make an exception and import one library specific to the use of the wavelet transform, [PyWavelets](https://pywavelets.readthedocs.io/en/latest/). This is because this library gives us the most flexibility to work with the wavelet transform.\n",
    "\n",
    "Run the following cell to import all of these libraries and load the images we will use throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6cc5a58a6e8662296aa559c24f240609",
     "grade": false,
     "grade_id": "cell-e5e11f3d1fda5bfe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Configure plotting as dynamic\n",
    "%matplotlib widget\n",
    "\n",
    "# Import standard required packages for this exercise\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import ipywidgets as widgets\n",
    "import scipy.ndimage as ndi\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import cv2 as cv \n",
    "import pywt\n",
    "import time\n",
    "\n",
    "# Standard general Python libraries\n",
    "from scipy import stats\n",
    "import math\n",
    "import sys\n",
    "\n",
    "# IPLabViewer\n",
    "sys.path.insert(0, 'lib')\n",
    "from iplabs import IPLabViewer as viewer\n",
    "\n",
    "# Load images to be used in this exercise \n",
    "doisneau = cv.imread('images/doisneau.tif', cv.IMREAD_UNCHANGED).astype('float64')\n",
    "doisneau_noise = cv.imread('images/doisneau-noise.tif', cv.IMREAD_UNCHANGED).astype('float64')\n",
    "lowlight = cv.imread('images/lowlight.tif', cv.IMREAD_UNCHANGED).astype('float64')\n",
    "mer_de_glace = cv.imread('images/mer-de-glace.tif', cv.IMREAD_UNCHANGED).astype('float64')\n",
    "lighthouse = cv.imread('images/lighthouse.tif', cv.IMREAD_UNCHANGED).astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "acbc8ac52911f4ff3330ce1f3ce2b138",
     "grade": false,
     "grade_id": "cell-4b72a2bcfd3b306d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# The wavelet transform (9 points)\n",
    "\n",
    "In this laboratory we propose to study a simple *wavelet transform*, the Haar wavelet transform, and experiment with its applications. Moreover, you will develop the understanding and tools to experiment with any discrete wavelet transform you want. Note that the wavelet transform is itself an application of filtering and downsampling. While we expect you to be familiar and comfortable implementing the fundamental blocks in a low-level language, the lab will be completely in Python to simplify most tasks and allow you to focus on the _new_ content. If you would like to review the low-level implementations of filtering and downsampling, feel free to have a look at [Lab 2: Filtering](Filtering.ipynb#-1.B.-Separable-version-(2-points)) and [Lab 1: Introductory](Introductory.ipynb(#-2.A.a.-NumPy)).\n",
    "\n",
    "## Index\n",
    "1. [The Haar wavelet transform](#1.-The-Haar-wavelet-transform)\n",
    "    1. [Boundary conditions](#1.A.-Boundary-conditions)\n",
    "2. [Analysis](#2.-Analysis-(6-points))\n",
    "    1. [Filterbank implementation - Analysis](#2.A.-Filterbank-implementation---Analysis-(3-points)) **(3 points)**\n",
    "    2. [A note on the visualization of wavelet coefficients](#2.B.-A-note-on-the-visualization-of-wavelet-coefficients-(1-point)) **(1 point)**\n",
    "    3. [Polyphase implementation of the Haar wavelet transform - Analysis](#2.C.-Polyphase-implementation-of-the-Haar-wavelet-transform---Analysis-(1-point)) **(1 point)**\n",
    "    4. [PyWavelets - Analysis](#2.D.-PyWavelets---Analysis-(1-point)) **(1 point)**\n",
    "3. [Synthesis](#3.-Synthesis-(3-points)) \n",
    "    1. [Filterbank implementation - Synthesis](#3.A.-Filterbank-implementation---Synthesis-(2-points)) **(2 points)**\n",
    "    2. [Polyphase implementation of the Haar wavelet transform - Synthesis](#3.B-Polyphase-implementation-of-the-Haar-wavelet-transform---Synthesis-(1-point)) **(1 points)**\n",
    "    4. [Synthesis with PyWavelets](#3.C.-Synthesis-with-PyWavelets)\n",
    "    \n",
    "The overall algorithmic structure of the wavelet transform's filtebank implementation for scale $n=2$ is shown in the following figure.\n",
    "\n",
    "<img src=\"images/wavelet.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7ce4732257f97da39fe65551feb8be6",
     "grade": false,
     "grade_id": "cell-f3c9e0bd7846351c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Visualize Images\n",
    "Feel free to get familiar now with the images you are going to be using. Run the next cell and use `Next` / `Prev` to cycle through the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1428db7bf1208c82d14eb18d29a6923b",
     "grade": false,
     "grade_id": "cell-7b2d0ecc9f20cfc6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381e6c3495634222bd2b4210f8de28ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display images\n",
    "image_list = [doisneau, doisneau_noise, lighthouse, mer_de_glace, lowlight]\n",
    "\n",
    "plt.close('all')\n",
    "imgs_viewer = viewer(image_list, widgets = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "712b06cd08b26b504b493caa81697270",
     "grade": false,
     "grade_id": "cell-a71e1b7af7131d8b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 1. The Haar wavelet transform\n",
    "[Back to index](#Index)\n",
    "\n",
    "In this section we propose to study the Haar wavelet transform. As the following figure illustrates, this transform approximates a signal as a sum of alternating-sign piece-wise constant functions at different shifts and scales.\n",
    "\n",
    "<img src=\"images/haar_showcase.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "Mathematically, this is just an example of what you have studied, where from a wavelet function $\\psi(x)$, a collection of basis functions is obtained as\n",
    "\n",
    "$$\\psi_{i,k}(x) = 2^{-\\frac{i}{2}}\\psi\\left(\\frac{x}{2^i}-k\\right)\\,, \\forall i \\in \\mathbb{N}, \\forall k \\in \\mathbb{Z}\\,,$$\n",
    "\n",
    "and any signal $f(x)$ is expanded as\n",
    "\n",
    "$$ f = \\sum_{i \\in \\mathbb{N}}\\sum_{k\\in\\mathbb{Z}} \\left\\langle f, \\psi_{i,k}\\right\\rangle \\psi_{i,k}\\,.$$\n",
    "\n",
    "In practical, discrete terms, this expansion is only applied up to a scale $i=n$, and for the shifts that are within the signal of interest.\n",
    "\n",
    "The discrete transformation splits a discrete signal of size $m$ into two parts of size $m/2$ (say, for example, $1$ and $1'$). When applied iteratively, the low frequency signal ($1'$) is further split in into two parts (for example, $2$ and $2'$) of size $m/4$ and so on and so forth, as exemplified in the figure below for $n=3$.\n",
    "\n",
    "<img src=\"images/split_2.png\" alt=\"Drawing\" style=\"width: 1200px;\"/>\n",
    "\n",
    "Here, the frequency division is an idealized drawing to convey the concept, while in practice wavelet functions are not necessarily very sharp in the frequency domain. \n",
    "\n",
    "In the case of images (2 dimensional signals), the wavelet transform can be applied in a separable way. To review the concept of separability, please refer to [Lab 2: Filtering](Filtering.ipynb#-1.B.-Separable-version-(2-points)) or to the [IP1](https://moodle.epfl.ch/course/view.php?id=522) course notes. Because the wavelet transform does decompose the signal in low and high frequency content as seen above, a separable application results in four different regions on the wavelet coefficients for each scale, referred to as \n",
    " * *LL* for the low-frequency coefficients in both directions (typically placed in the upper-left corner),\n",
    " * *HL* for the high-frequency coefficients in the horizontal direction and low-frequency coefficients in the vertical direction (typically placed in the upper-right corner),\n",
    " * *LH* for the opposite of *HL* (typically placed in the lower-left corner), and\n",
    " * *HH* for the high-frequency coefficients in both directions (typically placed in the lower-right corner).\n",
    " \n",
    "When several iterations of the wavelet are applied, each iteration has its associated regions (there is only one LL region, however). These regions are subscripted according to the iteration they belong to, as shown in the image below.\n",
    "\n",
    "<img src=\"images/wavelet_orders.png\" alt=\"Drawing\" style=\"width: 250px;\"/>\n",
    "\n",
    "If `nx` and `ny` correspond to the size of the image in the $x$ and $y$ directions, respectively, each of the four regions are of size `nx/2`$\\times$`ny/2`. Together, they form an image of the same size as the original, as exemplified by the figure below.\n",
    "\n",
    "<img src=\"images/2dwt.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c41ee7f1f68ffb839e55e53a0a4ecaf4",
     "grade": false,
     "grade_id": "cell-2f91b9a6e5e55e4f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.A. Boundary conditions\n",
    "[Back to index](#Index)\n",
    "\n",
    "In all the previous labs, we have used (and strongly recommended) *mirror* boundary conditions for applications in filtering (e.g., Gaussian smoothing or edge detection), which generally reduces boundary artifacts and results in images that are more pleasant to look at. However, when you apply a convolution with mirror or constant boundary conditions and you clip the output to have the same length as the input, some information about the original signal is lost. This does not matter in most filtering applications - for example, in Gaussian filtering for denoising or edge detection, you do not usually want to recover the original image. \n",
    "\n",
    "In contrast, in image transforms the inverse transform has a well defined meaning, and it is key to applications to be able to go back to the original domain without losing information. We do not care about how the signal looks **in the transform domain**, and we  absolutely do not want any loss of information to ocurr, so that the original signal can be recovered. This is why we use **periodic boundary conditions**. Intuitively, information *lost* in one boundary of an image is stored *on the other side of it*, and we can keep transforms of the same size as the original without loosing any information. As a curiosity, using periodic boundary conditions (i.e., using circular convolutions), is exactly the same as filtering with the FFT of the same length of the signal. \n",
    "\n",
    "Look at the following example of a one-dimensional wavelet transform taken with a full mode convolution (i.e. keeping all the coefficients of the convolution). Note how, on one hand, when the boundary conditions are set to constant, we need the values from outside the region of the original signal (limited by the vertical red lines) for the reconstruction. While, on the other hand, when the boundary conditions are set to periodic, these values can be recovered from the other side of the signal, so we can have a wavelet transform of the exact same size as the signal. \n",
    "\n",
    "<table><tr>\n",
    "<td>\n",
    "  <p align=\"center\" style=\"padding: 10px\">\n",
    "    <img alt=\"Routing\" src=\"images/const_bound_wt.png\" width=\"400\"><br>\n",
    "    <em style=\"color: grey\">WT with full mode convolution and <b>constant</b> boundary conditions.</em>\n",
    "  </p> \n",
    "</td>\n",
    "<td> \n",
    "  <p align=\"center\">\n",
    "    <img src=\"images/wrap_bound_wt.png\" alt=\"Drawing\" style=\"width: 400px;\"/><br>\n",
    "    <em style=\"color: grey\">WT with full mode convolution and <b>periodic</b> boundary conditions.</em>\n",
    "  </p> \n",
    "</td>\n",
    "</tr></table>\n",
    "\n",
    "In the following sections, you will first implement the general wavelet transform in its filterbank formulation, using standard *NumPy* and *SciPy* functions. The resulting functions will be parametrized so that by simply providing the correct filters, you can evaluate any wavelet transform. After that, you will also implement the Haar wavelet trasform using the *polyphase implementation*, which is more efficient, but less general. Finally, we will test your implementations with respect to the library *PyWavelets*, and teach you how to use it.\n",
    "\n",
    "<div class = 'alert alert-success'>\n",
    "    \n",
    "<b>Notes:</b> To get a completely correct implementation fo the direct and inverse wavelet transforms, you will have to go through several steps:\n",
    "<ul>\n",
    "<li> you will have to get 4 filters right,</li>\n",
    "<li> you will have to implement two analysis functions (independent of each other, and only one of them dependent of the filters),</li>\n",
    "<li> you will have to implement two synthesis functions, similar to the analysis. </li>\n",
    "</ul>    \n",
    "This is basically to say that the wavelet transform is a complex topic. However, we have designed <b>each section of the lab to be independent of the others</b>. For example, if you don't get the analysis function right, you will still be able to test the correctness of your synthesis, and we will grade them separately. \n",
    "    \n",
    "So, do not get stuck too long in a single exercise, as you will always be able to continue with the lab.\n",
    "\n",
    "</div>\n",
    "    \n",
    "<div class = 'alert alert-warning'>\n",
    "\n",
    "<b>Hint:</b> A very common bug in this kind of lab is mixing up <code>nx</code> and <code>ny</code>. Some tests will be run in rectangular images, so you will catch the bug right away. However, some tests will also be done on square images, and you might miss this bug! Make sure to always make your own tests by creating cells wherever needed.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b373b8de1559a2f00c05279fd400706d",
     "grade": false,
     "grade_id": "cell-220a76c72e41210c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 2. Analysis (6 points) \n",
    "[Back to index](#Index)\n",
    "\n",
    "The analysis or direct wavelet transform is equivalent to obtaining the coefficients $\\left\\langle f, \\psi_{i,k}\\right\\rangle$ to express a signal $f$ in terms of the basis functions $\\psi_{i,k}$. As you can see in the [block diagram](#Index) of the filterbank implementation (not in the notation of the course), the analysis is carried out by applying two filters, which in the notation of the course are\n",
    " * $\\tilde{H}(z)$ for the low-pass filter, and \n",
    " * $\\tilde{G}(z)$ for the high-pass filter.\n",
    " \n",
    "In this section you will first implement the analysis using the filterbank implementation. Then we will make a short parenthesis to study how one can best visualize the wavelet transform coefficients. You will then proceed to the polyphase implementation of the Haar wavelet transform. Finally, you will test both your implementations against the implementation of *PyWavelets*. \n",
    "\n",
    "## 2.A. Filterbank implementation - Analysis (3 points)\n",
    "[Back to index](#Index)\n",
    "\n",
    "The filterbank implementation, during the analysis, uses two filters corresponding to a specific wavelet (highpass and lowpass filter), and consecutively applies the filtering and downsampling operations. Because this can be implemented very generically, the function you will now prepare will allow us to later experiment with different wavelets beyond Haar's. \n",
    "\n",
    "To begin this section, and **for 1 point,  write the impulse response of the four filters of the Haar filterbank (two for the analysis and two for the synthesis) in spatial domain (worth 0.25 each)**. As a hint, remember from the course notes that the filters to use for the Haar wavelet transform can be deduced from the following $\\mathcal{Z}$-transform expression\n",
    "\n",
    "$$H(z) = \\frac{1 + z^{-1}}{\\sqrt{2}}\\,.$$\n",
    "\n",
    "To answer, change the value of the variables `analysis_hp`, `analysis_lp`, `synthesis_hp` and `synthesis_lp`. If in doubt, go to your course notes (Chapter 8, 8-51). **Give your answer with the minimum odd support necessary to clearly show the center of the filter**, considering that the value in the center is always assigned to $n=0$. \n",
    "\n",
    "As an example, the variable `example` has been filled to implement the filter $E(z)=z-z^{-1}$, according to the reasoning in the table below, where $\\uparrow$ indicates the coefficient corresponding to $n=0$.\n",
    "\n",
    "| $E(z)$ | $e[n]$ | $\\lbrace \\dots, \\underset{\\uparrow}{\\cdot}, \\dots \\rbrace$ | `example` | \n",
    "|--------|--------|-----------------------------------------------------|-----------|\n",
    "| $z - z^{-1} $ | $\\delta[n+1] -\\delta[n-1]$ | $\\lbrace \\dots,0,1,\\underset{\\uparrow}{0},-1,0,\\dots\\rbrace$ | `np.array([1, 0, -1])` |\n",
    "\n",
    "Here, $\\delta[n]$ is the Kronecker delta centered at $0$. \n",
    "\n",
    "Run the cells below the next one to check that your answers are valid.\n",
    "\n",
    "<div class = 'alert alert-danger'>\n",
    "    \n",
    "<b>Notes:</b> \n",
    "<ol>\n",
    "<li> Give exact answers using NumPy functions or attributes (e.g., `np.pi` instead of 3.14159),</li>\n",
    "<li> Give your answer as a NumPy Array (see `example` in the table above and in the next cell).</li>\n",
    "</ol>\n",
    "Both notes are meant to avoid problems with the precision of the calculation.   \n",
    "</div>\n",
    "<div class = 'alert alert-info'>\n",
    "    \n",
    "<b>Hint:</b> Which of the 4 filters corresponds to the one we just gave you? From $H(z)$ and your course notes you should be able to derive the other three.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71516a97cd1e800272cc3a74142f922a",
     "grade": false,
     "grade_id": "cell-9b5ce10714c2a5a6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# As an example:\n",
    "example = np.array([1, 0, -1])\n",
    "# YOUR CODE HERE\n",
    "analysis_lp = 1/np.sqrt(2)*np.array([ 1, 1, 0])\n",
    "analysis_hp = 1/np.sqrt(2)*np.array([-1, 1, 0])\n",
    "synthesis_lp = 1/np.sqrt(2)*np.array([ 0, 1, 1])\n",
    "synthesis_hp = 1/np.sqrt(2)*np.array([ 0, 1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a8df59b0aabe7dd80f1d613045f8941",
     "grade": true,
     "grade_id": "cell-76572217079cd10b",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(analysis_lp) == np.ndarray, 'Make sure that you provide a NumPy array.'\n",
    "assert analysis_lp.size == 3, 'Hint: Even though the filters of the Haar wavelet have a support of 2 elements,\\\n",
    "                                    you need 3 elements to specify the center of the filter'\n",
    "assert np.isclose(np.linalg.norm(analysis_lp), 1), 'Hint: all wavelet filters have a norm of 1.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa26f3702b72f7b4f8a912f0d9884586",
     "grade": true,
     "grade_id": "cell-594245d2d47cd84b",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(analysis_hp) == np.ndarray, 'Make sure that you provide a NumPy array.'\n",
    "assert analysis_hp.size == 3, 'Hint: Even though the filters of the Haar wavelet have a support of 2 elements,\\\n",
    "                                    you need 3 elements to specify the center of the filter'\n",
    "assert np.isclose(np.linalg.norm(analysis_hp), 1), 'Hint: all wavelet filters have a norm of 1.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58b912bd59cfd391fe4b0a51a889b8f1",
     "grade": true,
     "grade_id": "cell-6443de4936d1444a",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(synthesis_lp) == np.ndarray, 'Make sure that you provide a NumPy array.'\n",
    "assert synthesis_lp.size == 3, 'Hint: Even though the filters of the Haar wavelet have a support of 2 elements,\\\n",
    "                                    you need 3 elements to specify the center of the filter'\n",
    "assert np.isclose(np.linalg.norm(synthesis_lp), 1), 'Hint: all wavelet filters have a norm of 1.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b3d4f634803e8014d4ac0e9de77b20a",
     "grade": true,
     "grade_id": "cell-ea048dd0d058f183",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(synthesis_hp) == np.ndarray, 'Make sure that you provide a NumPy Array.'\n",
    "assert synthesis_hp.size == 3, 'Hint: Even though the filters of the Haar wavelet have a support of 2 elements,\\\n",
    "                                    you need 3 elements to specify the center of the filter'\n",
    "assert np.isclose(np.linalg.norm(synthesis_hp), 1), 'Hint: all wavelet filters have a norm of 1.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "623ea71596e34eb6007c1e26a246445a",
     "grade": false,
     "grade_id": "cell-8233f1b48a61b6b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, **for 2 points**, we suggest you complete the filterbank implementation of the analysis part of the wavelet transform in Python. For that, you will complete the function `analysis` below, which takes as parameters\n",
    "\n",
    "* `data`: the original image,\n",
    "* `lp`: the low-pass analysis filter,\n",
    "* `hp`: the high-pass analysis filter,\n",
    "* `n`: the number of iterations of the analysis filterbank to perform, i.e., the maximum _scale_ to be used.\n",
    "\n",
    "The output is the wavelet transform, a 2D NumPy array of the same size as the original image.\n",
    "\n",
    "Read the following hints **very carefully** to help you during the implementation.\n",
    " \n",
    "<div class = 'alert alert-success'>\n",
    "    \n",
    "<b>Hints:</b>\n",
    "    \n",
    "<ol>\n",
    "The structure of the function <code>analysis</code> is the following:\n",
    " <li>. We get information about the image size, and preallocate space for the output. </li>\n",
    " <li>. We repeat, a total of $n$ times:</li>\n",
    "    <ol>\n",
    "     <li>. Select the appropriate region of the image (initially the complete image, thereafter the *LL* coefficients of the previous iteration),</li>\n",
    "     <li>. apply the low-pass filter horizontally,</li>\n",
    "     <li>. apply the high-pass filter horizontally,</li>\n",
    "     <li>. downsample both results,</li>\n",
    "     <li>. construct the wavelet transform coefficients in the horizontal direction,</li>\n",
    "     <li>. repeat steps B to E for the vertical direction on the wavelet coefficients that resulted from the horizontal analysis.</li>\n",
    "</ol></ol>\n",
    "     \n",
    "Steps 1. and 2A. are already implemented for you. \n",
    "    \n",
    "For steps 2.B and 2.C, <b>use the function <code>ndi.convolve1d</code></b>, implemented by SciPy in its multidimensional image processing module ([see documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.convolve1d.html#scipy.ndimage.convolve1d)) - this function applies a horizontal/vertical 1D convolution to all the rows/columns of an image simultaneously, which is why we use it instead of [<code>scipy.signal.convolve2d</code>](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve2d.html) (<b>which we will not accept</b>) as in [section 1.A](#1.A.-Boundary-conditions). Moreover, `ndi.convolve1d` gives the result of the same size as the input, so you will not have to worry about the mode of the convolution.   \n",
    "    \n",
    "Some extra tips are:\n",
    "\n",
    "<ul>\n",
    "<li> <b>use the periodic boundary conditions, i.e., (<code>mode = 'wrap'</code>)</b>,</li>\n",
    "<li> to downsample, use [NumPy slicing](https://numpy.org/doc/stable/reference/arrays.indexing.html). In particular, you might want to use the <code>[start:stop:step]</code> notation. In the next cell you will see an example where we downsample a $10\\times 10$ array,</li>\n",
    "<li> to <i>construct</i> the wavelet transform coefficients (i.e., join <i>L</i> and <i>H</i> coefficients as shown in the images in <a href=\"#1.-The-Haar-wavelet-transform\" >Section 1</a>, use the [<code>np.concatenate</code>](https://numpy.org/doc/stable/reference/generated/numpy.concatenate.html) function.</li>\n",
    "<li> when calling each of these functions, be very careful with the <code>axis</code> parameter.</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "Run the next cell to see the example of downsampling, and complete the function `analysis` in the cell after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f27cfccae34d9c6f92503261bb767c0",
     "grade": false,
     "grade_id": "cell-220369de2f0ce6c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original array: \n",
      " [[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [10 11 12 13 14 15 16 17 18 19]\n",
      " [20 21 22 23 24 25 26 27 28 29]\n",
      " [30 31 32 33 34 35 36 37 38 39]\n",
      " [40 41 42 43 44 45 46 47 48 49]\n",
      " [50 51 52 53 54 55 56 57 58 59]\n",
      " [60 61 62 63 64 65 66 67 68 69]\n",
      " [70 71 72 73 74 75 76 77 78 79]\n",
      " [80 81 82 83 84 85 86 87 88 89]\n",
      " [90 91 92 93 94 95 96 97 98 99]]\n",
      "\n",
      " Horizontally downsampled array: \n",
      " [[ 0  2  4  6  8]\n",
      " [10 12 14 16 18]\n",
      " [20 22 24 26 28]\n",
      " [30 32 34 36 38]\n",
      " [40 42 44 46 48]\n",
      " [50 52 54 56 58]\n",
      " [60 62 64 66 68]\n",
      " [70 72 74 76 78]\n",
      " [80 82 84 86 88]\n",
      " [90 92 94 96 98]]\n"
     ]
    }
   ],
   "source": [
    "# Declare test image\n",
    "test = np.arange(100).reshape((10,10))\n",
    "print('Original array: \\n', test)\n",
    "# Downsampling in the horizontal direction\n",
    "print('\\n Horizontally downsampled array: \\n', test[:, ::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "498a300a480d4d216bf1df1d06ad86b9",
     "grade": false,
     "grade_id": "cell-e5bdc88960ba293c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Function that performs n iterations of the analysis part of the wavelet transform on img\n",
    "def analysis(img, lp, hp, n):\n",
    "    # Get dimensions of the original image\n",
    "    ny, nx = img.shape\n",
    "    # Declare output\n",
    "    output = np.copy(img)\n",
    "    for i in range(n):\n",
    "        # Get LL (will select the whole image the first time, and \n",
    "        # the LL part of the previous iteration the next times)\n",
    "        sub = output[0:ny, 0:nx]\n",
    "        \n",
    "        # Store your result in the variable sub, which is incorporated\n",
    "        # into output at the end of each iteration\n",
    "        \n",
    "        ## Horizontal transform\n",
    "        # Apply filters to create the two horizontal components\n",
    "        # YOUR CODE HERE\n",
    "        hzl = ndi.convolve1d(sub, lp, axis=1, mode='wrap')\n",
    "        hzh = ndi.convolve1d(sub, hp, axis=1, mode='wrap')\n",
    "        # Downsample\n",
    "        # YOUR CODE HERE\n",
    "        hzl = hzl[:,::2]\n",
    "        hzh = hzh[:,::2]\n",
    "        # Concatenate results to construct horizontal wavelet structure\n",
    "        # YOUR CODE HERE\n",
    "        sub = np.concatenate((hzl, hzh), axis=1)\n",
    "        ## Vertical transform\n",
    "        # Repeat all the steps above for the vertical transform\n",
    "        # YOUR CODE HERE\n",
    "        vtl = ndi.convolve1d(sub, lp, axis=0, mode='wrap')\n",
    "        vth = ndi.convolve1d(sub, hp, axis=0, mode='wrap')   \n",
    "        \n",
    "        vtl = vtl[::2,:]\n",
    "        vth = vth[::2,:]\n",
    "        \n",
    "        sub = np.concatenate((vtl, vth), axis=0)\n",
    "        # Insert sub to replace the old LL coefficients\n",
    "        output[0:ny, 0:nx] = sub\n",
    "        # Adjust dimensions to represent the new LL coefficient\n",
    "        nx = nx//2\n",
    "        ny = ny//2\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3af040032033d1f42e3f7592a1b2a809",
     "grade": false,
     "grade_id": "cell-7de1fe9dc5d9572d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we will apply your function to the image `lowlight` with $n = 1$ and wth $n = 4$. Make sure that the results make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fb73df715a15df0e712acf1f86bd7bb",
     "grade": true,
     "grade_id": "cell-88eed0df4f0a5d3c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "568bc9c250e9406fb3c7b4f7f0e8d295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now we apply the wavelet transform to the image lowlight\n",
    "lowlight_wt_1 = analysis(lowlight, analysis_lp, analysis_hp, 1)\n",
    "lowlight_wt_3 = analysis(lowlight, analysis_lp, analysis_hp, 3)\n",
    "# Display the results\n",
    "plt.close('all')\n",
    "view = viewer([lowlight_wt_1, lowlight_wt_3], title = ['n = 1', 'n = 3'], widgets = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c131a5b6d590a0fa00ef621ea47e757f",
     "grade": false,
     "grade_id": "cell-98dd1ff20104866b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "What do you think about the result? Let's apply your function to a rectangular image now. We will test on `mer_de_glace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38e66c40966d650acce2e1a2c94b775c",
     "grade": true,
     "grade_id": "cell-63c61dfffae18ed0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055e1a0519c54b50a1603fc06eae207e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mer_de_glace_wt_1 = analysis(mer_de_glace, analysis_lp, analysis_hp, 1)\n",
    "mer_de_glace_wt_3 = analysis(mer_de_glace, analysis_lp, analysis_hp, 3)\n",
    "\n",
    "rect_viewer = viewer([mer_de_glace_wt_1, mer_de_glace_wt_3], title = ['n = 1', 'n = 3'], widgets = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1efd79800881681a6fa2cc2eb28b491e",
     "grade": false,
     "grade_id": "cell-0895e42800e0d1f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As you know we usually provide numerical tests for you to check your functions. We will do that after implementing the polyphase formulation later in the lab. In the meantime, let's move on to the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6041cfeaa24922cc76258219f873ef3b",
     "grade": false,
     "grade_id": "cell-fcf1d97402752832",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.B. A note on the visualization of wavelet coefficients (1 point)\n",
    "[Back to index](#Index)\n",
    "\n",
    "As you probably just noticed, the contrast obtained when displaying the wavelet transform is not ideal. This is because the low frequency coefficients are almost always much larger than the high frequency coefficients. Many colormaps have been proposed to enhance the visualization of the wavelet transform. These colormaps, in general,\n",
    "\n",
    "* treat the different regions of the wavelet transform (*LL*, *HL*, *LH*, *HH*) as independent images, and\n",
    "* keep the $0$ value of the coefficients at the same level throughout the image.\n",
    "\n",
    "In this section we will see two possible visualization techniques:\n",
    "\n",
    "1. *Non-uniform mapping*: The negative values are linearly mapped to the range $[0, 127.5]$, and the positive values to $[127.5, 255]$. $0$ is mapped to $127.5$. This implies that positive and negative numbers are not treated equally (they go through different linear transformations).\n",
    "2. *Normalized standard deviation mapping*: The image (or region) is normalized (scaled) so that it has a standard deviation of $1$. Because there is no translation, only a scaling factor, the $0$ of the original coefficients stays at the same level. Moreover, all pixels are clipped to the range $[\\overline{x}-3\\sigma, \\overline{x}+3\\sigma]$ (where $\\overline{x}$ represents the sample mean of the data, and $\\sigma$ its sample standard deviation) to avoid outliers that reduce overall contrast (note that this step can be implemented before or after normalization, to the same effect with the corresponding $\\sigma$ values). Note that the mean is most probably not $0$, and will therefore change after applying this colormap.\n",
    "\n",
    "<div class = 'alert alert-danger'>\n",
    "    \n",
    "<b>Important:</b> These colormaps are only for visualization purposes. Be careful not to confuse their output with the output of the wavelet transform. \n",
    "</div>\n",
    "\n",
    "In the next cell, we provide the first colormap, `non_uniform_map`. For **1 point**, you will have to implement the second one, `norm_std_map`. \n",
    "\n",
    "<div class = 'alert alert-warning'>\n",
    "\n",
    "<b>Note:</b> Remember to take advantage of vectorization in Python (i.e., <b>we do not take answers with nested loops iterating through every element of a NumPy Array as correct</b>). If you have any doubts, refer to [Lab 0: Introductory](Introductory.ipynb) and [Lab 1: Pixel-wise operations and the Fourier transform](Pixel_Fourier.ipynb) from <a href=\"https://moodle.epfl.ch/course/view.php?id=522\" >IP1</a>.\n",
    "    \n",
    "<b>Hint:</b> In some later applications of the wavelet transform, you might at some point need to apply these colormaps to problematic cases, as, for example, a constant image. Because that image will have an equal minimum and maximum, and a sample standard devation of $0$, it could result in errors from trying to divide by $0$. To avoid potential problems, <b>treat such problematic cases with <code>if</code> statements</b> (if this is the case, the image should remain unaffected).\n",
    "    \n",
    "<b>Hint:</b> To limit the values of the final image to the range $[\\overline{x}-3\\sigma, \\overline{x}+3\\sigma]$, you might find the function [np.clip](https://numpy.org/doc/stable/reference/generated/numpy.clip.html) useful. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b34eaaffd5d3a031d61495241e316b67",
     "grade": false,
     "grade_id": "cell-304f7e89e114ae8d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Non-uniform color-map\n",
    "def non_uniform_map(img):\n",
    "    # Initialize with a copy of the input image\n",
    "    output = np.copy(img)    \n",
    "    # Avoid the case in which the minimum of the image is 0 \n",
    "    # (in which case the negative mapping is not necessary, as it would not be applied anywhere)\n",
    "    img_min = np.min(img)\n",
    "    if img_min < 0:\n",
    "        # Min maps to 0, 0 maps to 127.5\n",
    "        output[img<0] = 127.5/(-img_min) * (img[img<0] - img_min)\n",
    "    # Avoid the case in which the maximum of the image is 0 \n",
    "    # (in which case the positive mapping is not necessary, as it would not be applied anywhere)\n",
    "    img_max = np.max(img)\n",
    "    if img_max > 0:\n",
    "        # 0 maps to 127.5, max maps to 255\n",
    "        output[img>0] = 127.5 + 127.5*img[img>0]/img_max\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Normalize std color-map\n",
    "def norm_std_map(img):\n",
    "    # Initialize with a copy of the input image\n",
    "    output = np.copy(img)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    img_mean = output.mean()\n",
    "    img_std = output.std() if output.std() > 0 else 1\n",
    "    output = np.clip(output/img_std, img_mean - 3*img_std, img_mean + 3*img_std)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f176c4b410816152e9da3d78f5d19c5",
     "grade": false,
     "grade_id": "cell-4a4cc3bd613268a0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Before we go any further, let's design a small test for you to make sure that your function `norm_std_map` is correct. We will create $10^4$ points sampled from a [normal distributtion](https://en.wikipedia.org/wiki/Normal_distribution), using your *SCIPER* to determine the parameters of the distribution. For the purpose, we will use the function [numpy.random.randn](https://en.wikipedia.org/wiki/Normal_distribution). \n",
    "\n",
    "Then we will apply your function `norm_std_map`, and show you the histograms, means, and standard deviations of both arrays in a plot. Moreover, we will print the first indexes where the original and mapped arrays are fairly close to $0$. \n",
    "    \n",
    "Use this plot to try to verify that everything is right. \n",
    "\n",
    "<div class = 'alert alert-danger'>\n",
    "    \n",
    "<b>Note:</b> Remember that these tests by no means guarantee the points.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76f47f0fe7b5c85957c5882fda691ee7",
     "grade": true,
     "grade_id": "cell-5ce37360b5719f10",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The near-zero-level of the original array is found first at index 1083.\n",
      "\n",
      "The near-zero-level of the colormapped array is found first at index 1083.\n",
      "\n",
      "\tUse this information carefully, remember that this is a random process.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed37a39fa59746948cfd2d0bf1623229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Pan', 'Pan axes with left…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the seed and distribution parameters using your SCIPER\n",
    "np.random.seed(uid)\n",
    "mean = uid % 3 + 2 \n",
    "std = uid % 5 + 3\n",
    "\n",
    "# Generate random array and apply your function\n",
    "# if it fails, it is likely because the code has not been vectorized\n",
    "rand_arr = mean + std * np.random.randn(10000)\n",
    "try:\n",
    "    arr_mapped = norm_std_map(rand_arr)\n",
    "except TypeError:\n",
    "    raise Exception('Be sure to avoid nested loops in your answers! These are considered incorrect.')\n",
    "\n",
    "print(f'The near-zero-level of the original array is found first at index \\\n",
    "{np.where(np.abs(rand_arr) == np.min(np.abs(rand_arr)))[0][0]}.\\n')\n",
    "print(f'The near-zero-level of the colormapped array is found first at index \\\n",
    "{np.where(np.abs(arr_mapped) == np.min(np.abs(arr_mapped)))[0][0]}.\\n\\n\\\n",
    "\\tUse this information carefully, remember that this is a random process.')\n",
    "\n",
    "# Extract statistics from both arrays\n",
    "rand_arr_mean = rand_arr.mean(); rand_arr_std = rand_arr.std()\n",
    "arr_mapped_mean = arr_mapped.mean(); arr_mapped_std = arr_mapped.std()\n",
    "# Plot\n",
    "plt.close('all')\n",
    "# Define bins\n",
    "bins = np.linspace(mean - 3 * std , mean + 3 * std, 100)\n",
    "# Plot original array and statistics\n",
    "plt.figure(figsize = (9, 4))\n",
    "plt.hist(rand_arr, bins, alpha=0.5, color='aquamarine', label=r'Original array $\\mathbf{x}$')\n",
    "xticks = plt.xticks()[0]; plt.xticks(np.sort(np.hstack((xticks,[-2,-1,0,1,2]))))\n",
    "plt.axvline(rand_arr_mean, color='g', linestyle='-.', alpha=0.5, linewidth=2, label=r'$\\hat{\\mu}_x = \\sum x_i / N$')\n",
    "plt.axvline(rand_arr_mean + rand_arr_std, color='g', linestyle='-.', linewidth=0.8, label=r'$\\pm\\hat{\\sigma}_x$')\n",
    "plt.axvline(rand_arr_mean - rand_arr_std, color='g', linestyle='-.', linewidth=0.8)\n",
    "# Plot transformed array and statistics\n",
    "plt.hist(arr_mapped, bins, alpha=0.5, color='gray', label=r'Normalized array $\\mathbf{y}$')\n",
    "plt.axvline(arr_mapped_mean, color='k', linestyle='dashed', alpha=0.5, linewidth=2, label=r'$\\hat{\\mu}_y = \\sum y_i /N$')\n",
    "plt.axvline(arr_mapped_mean + arr_mapped_std, color='k', linestyle='dashed', linewidth=0.8, label=r'$\\pm\\hat{\\sigma}_y$')\n",
    "plt.axvline(arr_mapped_mean - arr_mapped_std, color='k', linestyle='dashed', linewidth=0.8)\n",
    "plt.legend(loc='upper right'); plt.title('Normalizated standard deviation colormap')\n",
    "plt.xlabel('Values'); plt.ylabel('Count'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "479c3ea14fdb3a4b9ef6d4371ff65af0",
     "grade": false,
     "grade_id": "cell-a125a72268ec0bc4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Does the histogram above make sense? Make sure that the your transformation matches what we described and that everything seems to work. Now, run the next cell for some sanity tests. We will check that\n",
    "\n",
    " * the standard deviation of the result is $1$, and \n",
    " * that you treated the case of a constant array (`std=0`) properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19d8c5f0de2634e0671601d7205f6b9e",
     "grade": false,
     "grade_id": "cell-01e9c3fbb9044527",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice, your function passed the sanity check!\n"
     ]
    }
   ],
   "source": [
    "# Test if std=1\n",
    "np.testing.assert_almost_equal(1, arr_mapped_std, decimal = 2,\n",
    "                               err_msg = 'The standard deviation of the second array is not 1!')\n",
    "# Test zero std image \n",
    "z_arr_mapped = norm_std_map(np.ones((1000)))\n",
    "assert not np.any(z_arr_mapped == np.inf) or np.all(z_arr_mapped == 0.), 'You did not treat the case where the std is 0 correctly.'\n",
    "print('Nice, your function passed the sanity check!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce152ad39f49937c37084edab58022c3",
     "grade": false,
     "grade_id": "cell-522ead00c6be77cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In order to apply your color-map to each coefficient of the Haar wavelet transform separately, we define the function `map_color()`, which takes as input a transformed image, the number of iterations $n$ of the transform and the color-map. Run the next cell to declare this function.\n",
    "\n",
    "<div class = 'alert alert-info'>\n",
    "    \n",
    "<b>Hint:</b> Even though you do not have to code anything in the following cell, you should take a look at how we extract the regions of the wavelet transform. It might prove useful later...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b1adb7647b240ff1a0700cc92143b28",
     "grade": true,
     "grade_id": "cell-6d4b80bf419ae3da",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Applies the color_map to the wavelet transform img with n iterations\n",
    "def map_color(img, n = 0, color_map = np.array):\n",
    "    # This first block is to determine whether we have a raw image or the color_map\n",
    "    div = 2**(n)\n",
    "    # ny and nx represent the size of the LL coefficient of the last iteration of analysis\n",
    "    ny, nx = np.array(img.shape) // div\n",
    "    \n",
    "    # Generate output array to work on\n",
    "    output = np.copy(img)\n",
    "    \n",
    "    # First we apply the color-map to LL coefficients\n",
    "    # if n = 0, we're applying the colormap to the whole image\n",
    "    output[0:ny, 0:nx] = color_map(output[0:ny, 0:nx])\n",
    "    # Now we will iterate through the number of WT iterations and process the other three regions for each scale\n",
    "    # if n = 0, the loop will not start\n",
    "    for i in range(n):\n",
    "        # Apply color_map to high-frequency components\n",
    "        output[0:ny, nx:2*nx] = color_map(output[0:ny, nx:2*nx])\n",
    "        output[ny:2*ny, nx:2*nx] = color_map(output[ny:2*ny, nx:2*nx])\n",
    "        output[ny:2*ny, 0:nx] = color_map(output[ny:2*ny, 0:nx])\n",
    "        \n",
    "        # Update dimensions\n",
    "        nx = nx * 2\n",
    "        ny = ny * 2\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5985354b4ef31776e6c2ed3796bbfd14",
     "grade": false,
     "grade_id": "cell-dea2b66c268672fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the next cell to visualize your results again, this time applying the colormap of your choice.\n",
    "<div class = 'alert alert-success'>\n",
    "\n",
    "<b>Note:</b> In the next cell, you can choose which mapping you want to use by assigning one of the color-map functions to the variable <code>color_map</code>. If you select <code>color_map = np.array</code>, no color-map will be applied. If you feel creative, you can even define your own color-map! The color-map you choose here will be used throughout the lab, but you can always come back and change it. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed939ff2f2b0434ea36e3ac141800daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose one of the colormap functions\n",
    "# color_map = norm_std_map\n",
    "color_map = non_uniform_map\n",
    "# color_map = np.array \n",
    "\n",
    "# Apply the wavelet transform to the image lowlight\n",
    "lowlight_wt_1 = analysis(lowlight, analysis_lp, analysis_hp, 1)\n",
    "lowlight_wt_3 = analysis(lowlight, analysis_lp, analysis_hp, 3)\n",
    "# Apply the color-map\n",
    "mapped_wt_1 = map_color(lowlight_wt_1, n = 1, color_map = color_map)\n",
    "mapped_wt_3 = map_color(lowlight_wt_3, n = 3, color_map = color_map)\n",
    "# Define parameters of viewer\n",
    "image_list = [lowlight, mapped_wt_1, mapped_wt_3]\n",
    "title_list = ['Original', 'Wavelet transform (n = 1)', 'Wavelet transform (n = 3)']\n",
    "# Display the result\n",
    "plt.close('all')\n",
    "analysis_viewer = viewer(image_list, title = title_list, widgets = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "241ca5b8f12e3833a6bcffad814b0ac4",
     "grade": false,
     "grade_id": "cell-2dcd52d4661a6b95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Which one did you prefer? As you can see, both make the presence of noise more evident than using a colormap proportional to the raw wavelet transform. Remember that you can choose which one to use by assigning the function you want to the variable `color_map`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2aefce5ad0a531edb95839b83a8e8bc4",
     "grade": false,
     "grade_id": "cell-611a276920e54420",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.C. Polyphase implementation of the Haar wavelet transform - Analysis (1 point) \n",
    "[Back to index](#Index)\n",
    "\n",
    "In this section you will implement a fast version of the Haar wavelet transform. The key insight here is that in the filterbank implementation, half the computations made in the convolutions are thrown away immediately after by downsampling. \n",
    "\n",
    "In a polyphase implementation, we save computations by downsampling copies of the signal with different shifts first and then applying equivalent filters. For the Haar wavelet transform, this results in the following formula (see page 8-52 in the course notes) for the one-dimensional transform\n",
    "\n",
    "$$ \n",
    "\\begin{bmatrix} \n",
    "    y_1[k] \\\\ y_2[k] \n",
    "\\end{bmatrix} = \\frac{1}{\\sqrt{2}}\n",
    "\\begin{bmatrix}\n",
    "    1 & 1 \\\\\n",
    "    1 & -1 \n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix} \n",
    "    x[2k] \\\\\n",
    "    x[2k+1] \n",
    "\\end{bmatrix}\\,.$$\n",
    "\n",
    "Here, $y_1[k]$ and $y_2[k]$ represent the low-pass and high-pass wavelet coefficients, and $x[k]$ represents the one-dimensional signal (a row/column of the image when doing our horizontal/vertical pass).  \n",
    "\n",
    "This will save both code complexity and computation time.  **For 1 point**, complete the function `poly_analysis` in the next cell. The structure is very similar to the one described in the filterbank implementation ([Section 2.A](#2.A.-Filterbank-implementation-(3-points))).\n",
    "\n",
    "<div class = 'alert alert-info'>\n",
    "    \n",
    "<b>Hint:</b> Note that the expression above does not necessarily need to be implemented as a matrix multiplication. \n",
    "    \n",
    "<b>Hint:</b> Remember that looping through rows/columns/pixels is not allowed. As every implementation we ask you to do in Python, your implementation below should be <a href=\"https://en.wikipedia.org/wiki/Array_programming\" >vectorized</a>.\n",
    "</div>\n",
    "<div class = 'alert alert-danger'>\n",
    "    \n",
    "<b>Note:</b> Do not use <code>ndi.convolve1d</code> here.\n",
    "</div>\n",
    "<div class = 'alert alert-warning'>\n",
    "    \n",
    "<b>Hint:</b> Depending of your implementation, you might come up across several bugs. A known one is due to Python copying mechanisms (if you assign a NumPy Array to another NumPy Array, and apply an operation to the former, the latter one will also be modified). Try wrapping suspicious assignments with <code>np.copy()</code>. For the curious, this happens because internally, NumPy mostly <a href=\"https://realpython.com/python-pass-by-reference/\">assigns by reference instead of assigning by value</a>. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0db7d8172e2f156190dd896f8d690752",
     "grade": false,
     "grade_id": "cell-4ba8bcf7d6994449",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def poly_analysis(img, n):\n",
    "    # Get dimensions of original\n",
    "    ny, nx = img.shape\n",
    "    # Declare output\n",
    "    output = np.copy(img)\n",
    "    for i in range(n):\n",
    "        # Get LL (will select the whole image the first time, and\n",
    "        # the LL part of the previous iteration the next times)\n",
    "        sub = np.copy(output[0:ny, 0:nx])\n",
    "        \n",
    "        # Store your result in the variable sub, which is incorporated\n",
    "        # into output at the end of each iteration\n",
    "        \n",
    "        ## Horizontal transform\n",
    "        # Separate even and odd horizontal coefficients\n",
    "        # YOUR CODE HERE\n",
    "        hze = sub[:,0::2]\n",
    "        hzo = sub[:,1::2]\n",
    "        # Compute y_1[k] and y_2[k] from the expression above \n",
    "        # YOUR CODE HERE\n",
    "        hzl = 1/np.sqrt(2)*(hze + hzo)\n",
    "        hzh = 1/np.sqrt(2)*(hze - hzo)  # np.array([[1, 1],[]])@hzo)\n",
    "        # Concatenate results to create horizontal wavelet transfrom\n",
    "        # YOUR CODE HERE\n",
    "        sub = np.concatenate((hzl, hzh), axis=1)\n",
    "        ## Vertical transform\n",
    "        # Repeat all the steps above for the vertical transform\n",
    "        # YOUR CODE HERE\n",
    "        vte = sub[0::2,:]\n",
    "        vto = sub[1::2,:]\n",
    "\n",
    "        vtl = 1/np.sqrt(2)*(vte + vto)\n",
    "        vth = 1/np.sqrt(2)*(vte - vto)  # np.array([[1, 1],[]])@hzo)\n",
    "\n",
    "        sub = np.concatenate((vtl, vth), axis=0)        \n",
    "        \n",
    "        output[0:ny, 0:nx] = sub \n",
    "        # Adjust dimensions of LL coefficient\n",
    "        nx = nx//2\n",
    "        ny = ny//2\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "60872323026f32012e8369bd077e97cc",
     "grade": false,
     "grade_id": "cell-93260646237ee86e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You are really becoming an expert on wavelet transforms! As an initial visual test, we will almost copy-paste the cell you had right after the filterbank implementation (*spoiler:* the result should be the same, except that now we are using the visualization you selected). Then, as promised, we will run numerical tests in the next section. \n",
    "\n",
    "Run the next cell to plot the result of the function `poly_analysis` applied to the image lowlight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4646b774eb12018a418880ee2392dfc",
     "grade": true,
     "grade_id": "cell-09879518045f5eff",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ece3c5719c34e5c91feac78d91bb16e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now we apply the Wavelet Transform to the image lowlight\n",
    "lowlight_wt_1 = poly_analysis(lowlight, 1)\n",
    "lowlight_wt_3 = poly_analysis(lowlight, 3)\n",
    "# Apply the color-map\n",
    "mapped_wt_1 = map_color(lowlight_wt_1, n = 1, color_map = color_map)\n",
    "mapped_wt_3 = map_color(lowlight_wt_3, n = 3, color_map = color_map)\n",
    "# Display the results\n",
    "plt.close('all')\n",
    "view = viewer([mapped_wt_1, mapped_wt_3], title = ['Wavelet transform - Polyphase (n = 1)', 'Wavelet transform - Polyphase (n = 3)'], widgets = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3fe1268713d772f3026d33bd0a5e057a",
     "grade": false,
     "grade_id": "cell-f4074df175d4aeb4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If you feel confident about both your implementations, we have a test to check that the polyphase formulation is in fact faster than the filterbank implementation.\n",
    "\n",
    "Run the next cell to see the difference averaged over $10$ runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef809bc3ad52046edde989b222de27d2",
     "grade": false,
     "grade_id": "cell-32e18866b43f2c1e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fbb1d97de544acc9c017f4e9b9eebcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Pan', 'Pan axes with left…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On average, the polyphase implementation is 1.62 times faster than the standard filterbank across the different scales.\n"
     ]
    }
   ],
   "source": [
    "scales = np.arange(1,10,dtype=np.float32)\n",
    "time_poly = np.zeros_like(scales); time_filterbank = np.zeros_like(scales)\n",
    "reps = 10\n",
    "# Run test\n",
    "for n in scales:\n",
    "    for i in range(reps):\n",
    "        # Measure polyphase time\n",
    "        start = time.time()\n",
    "        poly = poly_analysis(doisneau, int(n))\n",
    "        end = time.time()\n",
    "        time_poly_run = end - start\n",
    "        # Measure filterbank time\n",
    "        start = time.time()\n",
    "        filterbank = analysis(doisneau, analysis_lp, analysis_hp, int(n))\n",
    "        end = time.time()\n",
    "        time_filterbank_run = end - start\n",
    "        # Update times\n",
    "        time_poly[int(n)-1] += time_poly_run/reps\n",
    "        time_filterbank[int(n)-1] += time_filterbank_run/reps\n",
    "\n",
    "plt.close(\"all\")\n",
    "plt.figure(figsize=[8,5])\n",
    "plt.plot(scales, 1000*time_filterbank, label=\"Standard implementation [ms]\")\n",
    "plt.plot(scales, 1000*time_poly, label=\"Polyphase implementation [ms]\")\n",
    "plt.xlabel(r\"Scale $n$\"); plt.ylabel(r\"ms\")\n",
    "plt.legend();\n",
    "\n",
    "print(f\"On average, the polyphase implementation is {np.mean(time_filterbank)/np.mean(time_poly):.2f} times faster \\\n",
    "than the standard filterbank across the different scales.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "159de2ae8ed53d57f914c692f97dfc70",
     "grade": false,
     "grade_id": "cell-10c4e7d4f7909385",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.D. PyWavelets - Analysis (1 point)\n",
    "[Back to index](#Index)\n",
    "\n",
    "To finish this section, we will show you how to do this step with PyWavelets (please refer to the [documentation](https://pywavelets.readthedocs.io/en/latest/) for a complete reference) and provide numerical tests for both your implementations.  The functions we will be using are [`pywt.dwt2`](https://pywavelets.readthedocs.io/en/latest/ref/2d-dwt-and-idwt.html#single-level-dwt2) and [`pywt.idwt2`](https://pywavelets.readthedocs.io/en/latest/ref/2d-dwt-and-idwt.html#single-level-idwt2), which stand for discrete wavelet transform and inverse discrete wavelet transform in 2D. The basic syntax of `pywt.dwt2` is\n",
    "\n",
    "```python\n",
    "cA, (cV, cH, cD) = pywt.dwt2(data, wavelet = 'haar', mode = 'periodization')\n",
    "```\n",
    "\n",
    "The parameters are\n",
    "* `data`: the image,\n",
    "* `wavelet` (a string): which wavelet to use (find [here](https://pywavelets.readthedocs.io/en/latest/ref/wavelets.html#wavelet-families) a list of the available wavelets),\n",
    "* `mode`: we will use `'periodization'` (which corresponds to `'wrap'` in `ndi.convolve1d` as explained in [Section 1](#1.-The-Haar-wavelet-transform)). This is the only mode that ensures that we can have a perfect synthesis (see [options](https://pywavelets.readthedocs.io/en/latest/ref/signal-extension-modes.html#ref-modes)). The default `mode` is `'symmetric'`, so make sure to always change it.\n",
    "\n",
    "The output is the four components of the image, split in two objects,\n",
    "* `cA`: \"approximation\", the low frequencies in both directions (which we call *LL*), and\n",
    "* `(cV, cH, cD)`, a length-3 tuple that contains three images,\n",
    "    * `cH`: \"horizontal component\", the high frequencies in the horizontal axis (which we call *HL*),\n",
    "    * `cV`: \"vertical component\", the high frequencies in the vertical axis (which we call *LH*),\n",
    "    * `cD`: \"diagonal component\", the high frequencies on both axis (which we call *HH*).\n",
    "\n",
    "Note that the correct way to extract the individual sections of the coefficients is as written in the \"basic syntax\" of `pywt.dwt2`. In order to match the results of your functions `analysis()` and `poly_analysis()`, one needs to construct the array\n",
    "\n",
    "$$ \\begin{bmatrix} \\mathrm{cA} & \\mathrm{cH} \\\\ \\mathrm{cV} & \\mathrm{cD} \\end{bmatrix}\\,.$$\n",
    "\n",
    "In the next cell, we will provide the function `pywt_analysis(img, n, wavelet)` which will perform $n$ iterations of the wavelet transform using PyWavelets and outputs a single image consistent with your previous results. Thus, the parameters are\n",
    "\n",
    "* `data`: the image,\n",
    "* `n`: order of the wavelet transform,\n",
    "* `wavelet` (string): which wavelet to use (find [here](https://pywavelets.readthedocs.io/en/latest/ref/wavelets.html#wavelet-families) a list of the available wavelets).\n",
    "\n",
    "Run the next cell to declare this function and apply it to the image `lowlight` for $n = 1$, and $n = 3$.  Explore the results visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "698af4524c9a6fb0bb54ce9981cee77d",
     "grade": false,
     "grade_id": "cell-d819170d40f5324a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513d33b873184b1e878a63ce8fc76847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function that performs n iterations of the wavelet transform on img using PyWavelets\n",
    "def pywt_analysis(img, n, wavelet):\n",
    "    # Extract image shape\n",
    "    ny, nx = img.shape\n",
    "    output = np.copy(img)\n",
    "    for i in range(n):\n",
    "        # Extract image or LL coefficients\n",
    "        sub = output[0:ny, 0:nx]\n",
    "        # Get analysis coefficients with PyWavelets\n",
    "        cA, (cV, cH, cD) = pywt.dwt2(sub, wavelet=wavelet, mode='periodization')\n",
    "        # Update size of LL coefficients\n",
    "        nx = nx//2\n",
    "        ny = ny//2\n",
    "        # Fill output with results\n",
    "        output[0:ny, 0:nx] = cA\n",
    "        output[ny:2*ny, 0:nx] = cV\n",
    "        output[0:ny, nx:2*nx] = cH\n",
    "        output[ny:2*ny, nx:2*nx] = cD\n",
    "    return output\n",
    "\n",
    "# Apply the analysis and color-map\n",
    "lowlight_wt_1 = pywt_analysis(lowlight, 1, 'haar')\n",
    "lowlight_wt_1 = map_color(lowlight_wt_1, n = 1, color_map = color_map)\n",
    "lowlight_wt_3 = pywt_analysis(lowlight, 3, 'haar')\n",
    "lowlight_wt_3 = map_color(lowlight_wt_3, n = 3, color_map = color_map)\n",
    "\n",
    "# Display the results\n",
    "plt.close('all')\n",
    "view = viewer([lowlight_wt_1, lowlight_wt_3], title = ['Wavelet transform - PyWavelets (n = 1)', 'Wavelet transform - PyWavelets (n = 3)'], widgets = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b0390f3a245be00b74ab1ccb1e68162c",
     "grade": false,
     "grade_id": "cell-6fd953cc3d427b94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, you will get the final test for both implementations, an element-wise comparison of the output of `analysis`, `poly_analysis` and `pywt_analysis`, up to the $10^{th}$ decimal (so yeah, equal). Moreover, the filterbank implementation will also be tested on the Daubechies 2 wavelet (DB2) - we define the appropriate filters in the same cell. If the following cell runs without any error, congratulations, your implementations match the results of PyWavelets!\n",
    "\n",
    "In case your implementation is not correct, the next cell will also plot the wrong results. To get a hint on where you went wrong, we are using the *compare* function of IPLabViewer. Look for the red regions in the images for details (these regions are where your results and PyWavelets' differ). Note that you can activate the comparison again after changing images by clicking on `Options` $\\rightarrow$ `Compare`.\n",
    "\n",
    "<div class = 'alert alert-danger'>\n",
    "    \n",
    "<b>Note:</b> As usual, the fact that this cell runs does not guarantee the points.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d41dbd1db7c19b52971b51c1938de34",
     "grade": false,
     "grade_id": "cell-a76aacda7a0c154d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations! You are as good as the most accepted wavelet library in Python.\n"
     ]
    }
   ],
   "source": [
    "# Define n\n",
    "n = 2\n",
    "\n",
    "## Test Haar\n",
    "# Get the results of the three wavelet transform implementations\n",
    "lighthouse_pywt = pywt_analysis(lighthouse, n, 'haar')\n",
    "lighthouse_poly = poly_analysis(lighthouse, n)\n",
    "lighthouse_filt = analysis(lighthouse, analysis_lp, analysis_hp, n)\n",
    "\n",
    "# Test polyphase implementation\n",
    "error_haar = False\n",
    "try:\n",
    "    np.testing.assert_array_almost_equal(lighthouse_pywt, lighthouse_poly, decimal = 10)\n",
    "except Exception as e:\n",
    "    print('Your polyphase implementation is not correct. Look at the following message for details.\\n')\n",
    "    print(e)\n",
    "    error_haar = True\n",
    "    plt.close('all')\n",
    "    viewer([lighthouse_poly,lighthouse_pywt],\n",
    "           title = [\"Polyphase\", \"PyWavelets (Ground truth)\"], compare = True, widgets = True)\n",
    "\n",
    "# Test standard filterbank implementation\n",
    "try:\n",
    "    np.testing.assert_array_almost_equal(lighthouse_pywt, lighthouse_filt, decimal = 10)\n",
    "except Exception as e:\n",
    "    print('Either your filterbank implementation is not correct, or your Haar filters are not correct (check the \\\n",
    "           test with DB2 filters to know for sure). Look at the following message for details.\\n')\n",
    "    error_haar = True\n",
    "    print(e)\n",
    "    viewer([lighthouse_filt, lighthouse_pywt],\n",
    "           title = [\"Filterbank Implementation\", \"PyWavelets (Ground truth)\"], compare = True, widgets = True)\n",
    "        \n",
    "## Test DB2\n",
    "# Set the coefficients \n",
    "a = (1 + np.sqrt(3))/(4*np.sqrt(2)); b = (3 + np.sqrt(3))/(4*np.sqrt(2))\n",
    "c = (3 - np.sqrt(3))/(4*np.sqrt(2)); d = (1 - np.sqrt(3))/(4*np.sqrt(2))\n",
    "# Define the filters\n",
    "analysis_lp_db2  = np.array([d, c, b, a, 0]);  analysis_hp_db2 = np.array([-a, b, -c, d, 0])\n",
    "synthesis_lp_db2 = np.array([0, a, b, c, d]); synthesis_hp_db2 = np.array([0, d, -c, b, -a])\n",
    "\n",
    "# Test\n",
    "error_db = False\n",
    "lighthouse_filt_db2 = analysis(lighthouse, analysis_lp_db2, analysis_hp_db2, n = n)\n",
    "lighthouse_pywt_db2 = pywt_analysis(lighthouse, n, 'db2')\n",
    "try:\n",
    "    np.testing.assert_array_almost_equal(lighthouse_filt_db2, lighthouse_pywt_db2, decimal = 10)\n",
    "    if error_haar:\n",
    "        print('Your filterbank implementation is correct, but you should check your Haar filters.')        \n",
    "except Exception as e:\n",
    "    print('Your filterbank implementation is not correct. Look at the following message for details.\\n')\n",
    "    print(e)\n",
    "    error_db = True\n",
    "    viewer([lighthouse_filt_db2,lighthouse_pywt_db2], title = [\"Filterbank (DB2)\", \"PyWavelets (Ground truth)\"], \n",
    "           compare = True)\n",
    "\n",
    "if not(error_db or error_haar):\n",
    "    print('Congratulations! You are as good as the most accepted wavelet library in Python.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7dd676bf88f18b004761d98e96885190",
     "grade": false,
     "grade_id": "cell-9536b99b641d0a8f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To finish this section, we want you to play with the maximum scale $n$, the colormap applied, and the selection of wavelet used in the analysis. We will use the function we defined previously, `pywt_analysis()`, and extra widgets in the **IPLabViewer** to do this.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "<b>Note:</b> We didn't list all the available wavelets, of course! To get a detailed description of the wavelets available by PyWavelets, you can go to <a href=\"http://wavelets.pybytes.com/wavelet/db4/\">this site</a> of the PyWavelets documentation. Note that we didn't cover every one of them in the course! Moreover, the site by PyWavelets can be overwhelming. For a quick overview of each of the families, Mathworks has <a href=\"https://www.mathworks.com/help/wavelet/gs/introduction-to-the-wavelet-families.html\">this</a> very good introduction, and <a href=\"https://www.mathworks.com/help/wavelet/ug/wavelet-families-additional-discussion.html\">this</a> also very good additional discussion. \n",
    "    \n",
    "If you are interested in exploring the wavelet transform for time series and other one-dimensional data, you can also look at <a href=\"http://ataspinar.com/2018/12/21/a-guide-for-using-the-wavelet-transform-in-machine-learning/\">this post</a> for a practically-oriented introduction to wavelets with Python. \n",
    "    \n",
    "Finally, if you want to go further into the topic, your course notes have a lot of academic material. Furthermore, you can check out the series of <a href=\"http://bigwww.epfl.ch/tutorials/index.html?k=wavelets\">books, talks and tutorials</a> by the Biomedical Imaging Group, which cover from the theory of wavelets to numerous applications in image denoising (that you will also do in the second part of the lab) and reconstruction.\n",
    "</div>\n",
    "\n",
    "In particular, we have added\n",
    "* the *n* slider: a slider to choose the number of scales,\n",
    "* the wavelet dropdown menu: a menu to choose among several wavelet transforms to apply,\n",
    "* the `Mapping` dropdown menu: a dropdown menu to choose whether (and which) colormap to use to enhance the visualization of the coefficients, and\n",
    "* the button `Analysis` to apply your selection.\n",
    "\n",
    "Remember to go the the menu `Extra Widgets` to access the options described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e4798e64f618dc70a5ef3ff64fe845db",
     "grade": false,
     "grade_id": "cell-d7628145a7b77664",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ba43ad4be04446a92e0e91b94e78a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_slider = widgets.IntSlider(value = 1, min = 0, max = 5, step = 1, description = 'n') \n",
    "wt_menu = widgets.Dropdown(options = ['haar', 'db2', 'db10', 'bior1.3', 'bior6.8', 'rbio1.3', 'dmey'], \n",
    "                                value = 'haar', description = 'WT:')\n",
    "mapping_menu = widgets.Dropdown(options = ['None', 'Normalize std', 'Non-uniform map'], \n",
    "                                value = 'None', description = 'Mapping:')\n",
    "button = widgets.Button(description = 'Analysis')\n",
    "\n",
    "def wavelet_callback(img):\n",
    "    n = n_slider.value\n",
    "    wt = wt_menu.value\n",
    "    output = pywt_analysis(img, n, wt)\n",
    "    if mapping_menu.value == 'None':\n",
    "        output = map_color(output, n = n, color_map = np.array)\n",
    "    elif mapping_menu.value == 'Normalize std':\n",
    "        output = map_color(output, n = n, color_map = norm_std_map)\n",
    "    else:\n",
    "        output = map_color(output, n = n, color_map = non_uniform_map)\n",
    "    return output\n",
    "\n",
    "wavelet_viewer = viewer(mer_de_glace, title = \"WT Analysis\", \n",
    "                        new_widgets = [n_slider, wt_menu, mapping_menu, button], \n",
    "                        callbacks = [wavelet_callback], widgets = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87762d6912a66b76d5cfa83296b2303c",
     "grade": false,
     "grade_id": "cell-0684a05795e13e00",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If you want to experiment with different images, orders, etc., use the next cell and recycle any code you want! This may also help you answer the multiple choice question below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e39587ea6e8ca3b1e55319d89a6b75c",
     "grade": false,
     "grade_id": "cell-22fc3d0ca14efea8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Multiple choice question\n",
    "\n",
    "To finish this section, answer the next *MCQ*, **worth 1 point**.\n",
    "\n",
    "* Q1: After experimenting with these wavelets on different images, you probably have a pretty good idea of how the typical wavelet coefficients look. How does the wavelet transform of a white noise image look?\n",
    "    \n",
    "    1. The LL coefficients have much higher values than all the others, as usual.\n",
    "    2. The HH coefficients have much higher values than all the others, because uncorrelated random noise contains extremely high frequencies.\n",
    "    3. The LL, LH, HL, and HH coefficients have similar values because white noise is spread equally across frequencies.\n",
    "    4. The LH and HL coefficients have lower values than the LL and HH coefficients, because random diagonal frequency components (high or low frequency) are very unlikely.\n",
    "    \n",
    "In the next cell, modify the variable `answer` to reflect your answers. The following cells is for you to check that your answer is valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf6f4e52265175e4a4fba37bea9a2c4f",
     "grade": false,
     "grade_id": "cell-6f6fc7cf27e68da6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Modify the variable answer\n",
    "answer = 3\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b727f0dad48e15ccf65051bcad50210b",
     "grade": true,
     "grade_id": "cell-1876cdadf4184d24",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "assert answer in [1, 2, 3, 4], 'Choose one of 1, 2, 3, or 4.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "014efcf9be93d3570c77d83050d0effd",
     "grade": false,
     "grade_id": "cell-8efc7ccfffa63ee5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 3. Synthesis (3 points)\n",
    "[Back to index](#Index)\n",
    "\n",
    "Now that you know how to implement the analysis or direct wavelet transform, it is time to get to the synthesis or inverse wavelet transform. In this section, you will first complete the standard filterbank implementation (upsampling followed by filtering), then you will complete the polyphase implementation of the Haar wavelet transform, and finally we will test both implementations against the implementation included in PyWavelets.\n",
    "\n",
    "## 3.A. Filterbank implementation - Synthesis (2 points)\n",
    "[Back to index](#Index)\n",
    "\n",
    "Now, **for 2 points** you will have to complete the function `synthesis` in Python. The parameters are\n",
    "* `coeffs`: a wavelet transform,\n",
    "* `lp`: the low-pass synthesis filter,\n",
    "* `hp`: the high-pass synthesis filter,\n",
    "* `n`: the number of iterations required to reconstruct the original image,\n",
    "\n",
    "and the output is\n",
    "* `image`: the synthesis of an image from its wavelet coefficients.\n",
    "\n",
    "<div class = 'alert alert-success'>\n",
    "    \n",
    "<b>Hints:</b>\n",
    "    \n",
    "The structure of the `synthesis` function is very similar to the `analysis` one:\n",
    "<ol>\n",
    " <li> First we get information about the size of the <i>LL</i> coefficient, and preallocate space for the output. </li>\n",
    " <li> We repeat, a total of $n$ times</li>\n",
    "    <ol>\n",
    "     <li> Select the appropriate region of the image (the wavelet transform coefficients for the last scale, thereafter the next scales),</li>\n",
    "     <li> split the image horizontally and upsample each piece,</li>\n",
    "     <li> apply the corresponding horizontal filter to each piece using `ndi.convolve1d`, </li>\n",
    "     <li> add up the results to get the horizontal synthesis,</li>\n",
    "     <li> repeat steps B to D for the vertical direction.</li>\n",
    "</ol></ol>\n",
    "     \n",
    "For upsampling, you can again take advantage of advanced indexing in NumPy: you create a new array of the right size, and you fill every other of its positions with the image you want to upsample. You can look at the images in [Section 1.A](#1.A.-Boundary-conditions) for an idea on how the upsampling should work. Make sure to verify your ideas on a small, separate example before you move on.\n",
    "    \n",
    "<b>As usual, we do not accept answers that use loops to iterate through images</b>. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53528cd06f1a7ab3b1c07a36844c4a96",
     "grade": false,
     "grade_id": "cell-af03fc46168d85df",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Function that performs n iterations of the inverse wavelet transform on coeffs\n",
    "def synthesis(coeffs, lp, hp, n):\n",
    "    # Get dimensions of the last wavelet transform\n",
    "    div = 2**(n-1)\n",
    "    ny, nx = np.array(coeffs.shape) // div\n",
    "    # Declare output\n",
    "    output = np.copy(coeffs)\n",
    "    for i in range(n):\n",
    "        # Extract wavelet coefficients (the smallest transform at first, then \n",
    "        # incorporating more and more coefficients)\n",
    "        wt_iter = output[0:ny, 0:nx]\n",
    "        \n",
    "        # Store your result in the variable wt_iter, which is incorporated into\n",
    "        # output at the end of each iteration    \n",
    "        \n",
    "        ## Horizontal inverse transfrom\n",
    "        # Split wt_iter into its two horizontal components        \n",
    "        # YOUR CODE HERE\n",
    "        hz1, hz2 = np.split(wt_iter, 2, axis=0)\n",
    "        # Upsample each component (zeros between samples)\n",
    "        # YOUR CODE HERE\n",
    "        hzl = np.zeros((2*hz1.shape[0], hz1.shape[1])) \n",
    "        hzl[::2,:] = hz1        \n",
    "        hzh = np.zeros((2*hz2.shape[0], hz2.shape[1])) \n",
    "        hzh[::2,:] = hz2\n",
    "        \n",
    "        # Filter each component with the corresponding filter\n",
    "        # YOUR CODE HERE\n",
    "        hzl = ndi.convolve1d(hzl, lp, axis=0, mode='wrap')\n",
    "        hzh = ndi.convolve1d(hzh, hp, axis=0, mode='wrap')\n",
    "        \n",
    "        # Combine the results into one component\n",
    "        # YOUR CODE HERE\n",
    "        wt_iter = hzl + hzh  # np.concatenate((hzl, hzh), axis=0)\n",
    "        ## Vertical inverse transform\n",
    "        # Repeat all the steps above for the vertical components (on the output\n",
    "        # of the inverse horizontal transform)\n",
    "        # YOUR CODE HERE\n",
    "        vt1, vt2 = np.split(wt_iter, 2, axis=1)\n",
    "\n",
    "        vtl = np.zeros((vt1.shape[0], 2*vt1.shape[1]))         \n",
    "        vtl[:,::2] = vt1        \n",
    "        vth = np.zeros((vt2.shape[0], 2*vt2.shape[1]))        \n",
    "        vth[:,::2] = vt2\n",
    "\n",
    "        vtl = ndi.convolve1d(vtl, lp, axis=1, mode='wrap')\n",
    "        vth = ndi.convolve1d(vth, hp, axis=1, mode='wrap')\n",
    "        \n",
    "        wt_iter = vtl + vth \n",
    "\n",
    "        # Replace synthesis of corresponding iteration\n",
    "        output[0:ny, 0:nx] = wt_iter\n",
    "        # Update dimensions for next scale\n",
    "        nx = nx * 2\n",
    "        ny = ny * 2  \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fec047fce20f810ec3b0aed65d3dec44",
     "grade": false,
     "grade_id": "cell-42ea381bd8fa49d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "First of all, as a preliminary test on your implementation, run the next cell to reconstruct the image `lowlight`. We will first decompose it using the function `pywt_analysis`, so that we only test your implementation of `synthesis`. We will plot the original and the synthesis. You can inspect them visually and look at the statistics to decide if it is correct.\n",
    "\n",
    "Run the next cell to see this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f51cafe4727fab5f6cc770824d060189",
     "grade": true,
     "grade_id": "cell-3057e07bedc88fba",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177e5fc9af7744eca0853034d90af5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<iplabs.IPLabViewer at 0x7f47b4aa3208>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply synthesis to doisneau_wt_1py (output from analysis()))\n",
    "lowlight_coef = pywt_analysis(lowlight, 4, 'haar')\n",
    "lowlight_rec = synthesis(lowlight_coef, synthesis_lp, synthesis_hp, 4)\n",
    "\n",
    "plt.close('all')\n",
    "viewer([lowlight_rec, lowlight], title = ['Synthesis', 'Original'], widgets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "399c7a0de426be37f1d09c402fcf7488",
     "grade": false,
     "grade_id": "cell-00d036960a110e27",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.B Polyphase implementation of the Haar wavelet transform - Synthesis (1 point)\n",
    "[Back to index](#Index)\n",
    "\n",
    "In this section you will implement a fast version of the inverse Haar wavelet transform based on the polyphase idea. The key insight is again that in the filterbank implementation, many of the computations made in the convolutions are multiplications by $0$. \n",
    "\n",
    "In a polyphase implementation, we save computations by first applying equivalent filters to the different coefficients, and then creating the output signal by upsampling and shifting them differently before adding them up. For the Haar wavelet transform, this results in the following formula (see page 8-52 in the course notes) for the one-dimensional transform\n",
    "\n",
    "$$ \\begin{bmatrix} x[2k] \\\\ x[2k + 1] \\end{bmatrix} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1 \\\\ 1 & -1 \\end{bmatrix}  \\begin{bmatrix} y_1[k] \\\\ y_2[k] \\end{bmatrix}\\,.$$\n",
    "\n",
    "The parameters of the function are\n",
    "\n",
    "* `coeffs`: the coefficients of a wavelet transform, and\n",
    "* `n`: the number of iterations required to reconstruct the original image,\n",
    "\n",
    "and the output is\n",
    "* `image`: the resulting image.\n",
    "\n",
    "<div class = 'alert alert-danger'>\n",
    "    \n",
    "<b>Note</b> Do not use <code>ndi.convolve1d</code> here.\n",
    "</div>\n",
    "<div class = 'alert alert-warning'>\n",
    "    \n",
    "<b>Hint</b> Depending of your implementation, you might come up across several bugs, such as confusing <code>nx</code> and <code>ny</code>, or getting tricked by NumPy's copying mechanisms, as we mentioned in <a href=\"#2.C.-Polyphase-implementation-of-the-Haar-wavelet-transform---Analysis-(1-point)\">Section 2.C.</a>. Try wrapping suspicious assignments with <code>np.copy()</code>.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce412ee67efd18c5b087d991711a56c6",
     "grade": false,
     "grade_id": "cell-4c589d9ed1b43363",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Function that performs n iterations of the inverse wavelet transform on img\n",
    "def poly_synthesis(coeffs, n):\n",
    "    # Get information about the transform (size of the last Wavelet Transform)\n",
    "    div = 2**(n-1)\n",
    "    ny, nx = np.array(coeffs.shape) // div\n",
    "    # Generate output array to work on\n",
    "    output = np.copy(coeffs)\n",
    "    for i in range(n):\n",
    "        # Extract wavelet coefficients (the smallest transform at first, then \n",
    "        # incorporating more and more coefficients)\n",
    "        wt_iter = output[0:ny, 0:nx]\n",
    "        \n",
    "        # Store your result in the variable wt_iter, which is incorporated into\n",
    "        # output at the end of each iteration\n",
    "        \n",
    "        ## Horizontal inverse transfrom\n",
    "        # Split wt_iter into its two horizontal components\n",
    "        # YOUR CODE HERE\n",
    "        hzl, hzh = np.split(wt_iter, 2, axis=0)\n",
    "        # Apply filterbank matrix (calculate even and odd samples)\n",
    "        # YOUR CODE HERE\n",
    "        hze = 1/np.sqrt(2)*(hzl + hzh)\n",
    "        hzo = 1/np.sqrt(2)*(hzl - hzh)\n",
    "        \n",
    "        wt_iter[0::2,:] = hze\n",
    "        wt_iter[1::2,:] = hzo\n",
    "        ## Vertical inverse transform\n",
    "        # Repeat the steps above for the vertical components\n",
    "        # YOUR CODE HERE\n",
    "        vtl, vth = np.split(wt_iter, 2, axis=1)\n",
    "\n",
    "        vte = 1/np.sqrt(2)*(vtl + vth)\n",
    "        vto = 1/np.sqrt(2)*(vtl - vth)\n",
    "        \n",
    "        wt_iter[:,0::2] = vte\n",
    "        wt_iter[:,1::2] = vto\n",
    "\n",
    "        # Replace synthesis of corresponding iteration\n",
    "        output[0:ny, 0:nx] = wt_iter\n",
    "        # Update dimensions for next scale\n",
    "        nx = nx * 2\n",
    "        ny = ny * 2\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e07711fa25ffcea2e96c9d3c6fe8a49",
     "grade": false,
     "grade_id": "cell-80f677ce71802cf5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the next cell for a quick test on your polyphase implementation of the synthesis part of the Haar wavelet transform. We will test with the image `mer_de_glace`, and use the function `pywt_analysis` for the analysis so that we are only testing your `poly_synthesis` function, not your analysis function. We will plot the original and the synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c7b9a51a0faa3352ca05c67360aabf6",
     "grade": true,
     "grade_id": "cell-b54f7837096c4442",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8cb738a95c840e6af7f8c1fbf4e007d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get synthesis\n",
    "mer_de_glace_wt_4 = pywt_analysis(mer_de_glace, 4, 'haar')\n",
    "mer_de_glace_rec_4 = poly_synthesis(mer_de_glace_wt_4,  4)\n",
    "\n",
    "# Display the results\n",
    "plt.close('all')\n",
    "view = viewer([mer_de_glace_rec_4, mer_de_glace], title = ['Synthesis (n = 4)', 'Original'], widgets = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1378ad16452718a5a6123ffa8ba79a38",
     "grade": false,
     "grade_id": "cell-1f23474e61da22aa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3.C. Synthesis with PyWavelets\n",
    "[Back to index](#Index)\n",
    "\n",
    "To finish this section, we will show you how to do this step with PyWavelets and provide numerical tests for both your synthesis  implementations. The basic syntax of `pywt.idwt2` is\n",
    "```python\n",
    "image = pywt.idwt2(coeffs, wavelet = 'haar', mode = 'periodization')\n",
    "```\n",
    "\n",
    "The parameters are\n",
    "* `coeffs`: the exact output of `pywt.dwt2`, i.e.,  `(cA, (cV, cH, cD))` (see [Section 2.D.](#2.D.-Analysis-with-PyWavelets-(1-point))),\n",
    "* `wavelet` (a string): which wavelet to use (see the options [here](https://pywavelets.readthedocs.io/en/latest/ref/signal-extension-modes.html#ref-modes)). Clearly, to obtain the correct synthesis, you will need to apply the synthesis with the same wavelet you used for the analysis.\n",
    "* `mode`: as explained before, we will use `'periodization'` (which corresponds to 'wrap' in `ndi.convolve1d`),\n",
    "\n",
    "and the output is\n",
    "* `image`: the resulting image.\n",
    "\n",
    "In the next cell we will provide the function `pywt_synthesis(img, n, wavelet)`, which will perform $n$ iterations of the inverse wavelet transform. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<b>Note</b> To be consistent with the course format, and in a similar way as we did in the function <code>pywt_analysis</code>, the function <code>pywt_synthesis</code> will take as input the coefficients arranged in an <i>image of the same size as the original</i>, i.e., it will be compatible with the output from one of the analysis functions you implemented. We will take care of splitting the image in its coefficients inside the function.   \n",
    "</div> \n",
    "\n",
    "Run the next cell to declare this function and apply it to the image `lowlight` for $n = 1$, and $n = 4$.  Explore the results visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa0a04035a016dd5a2e5c930674bc6ea",
     "grade": false,
     "grade_id": "cell-7158f3e6e87376e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50da9766d32c4cbfa2f5e04ece4e022f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function that performs n iterations of the inverse wavelet transform on img\n",
    "def pywt_synthesis(img, n, wavelet):\n",
    "    # Get information about the transform (size of the last wavelet transform)\n",
    "    div = 2**(n-1)\n",
    "    ny, nx = np.array(img.shape) // div\n",
    "    # Generate output array to work on\n",
    "    output = np.copy(img)\n",
    "        \n",
    "    # Iterate through n\n",
    "    for i in range(n):\n",
    "        # Extract coefficients\n",
    "        cA = output[0:ny//2, 0:nx//2]\n",
    "        cH = output[0:ny//2, nx//2:nx]\n",
    "        cV = output[ny//2:ny, 0:nx//2]\n",
    "        cD = output[ny//2:ny, nx//2:nx]\n",
    "        # Apply inverse transform\n",
    "        sub = pywt.idwt2((cA, (cV, cH, cD)), mode = 'periodization', wavelet = wavelet)\n",
    "        # Replace inverse transform in image\n",
    "        output[0:ny, 0:nx] = sub\n",
    "        # Update dimensions\n",
    "        nx = nx * 2\n",
    "        ny = ny * 2\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Apply the python analysis and color-map\n",
    "lowlight_wt_1 = pywt_analysis(lowlight, 1, 'haar')\n",
    "lowlight_rec_1 = pywt_synthesis(lowlight_wt_1, 1, 'haar')\n",
    "lowlight_wt_4 = pywt_analysis(lowlight, 4, 'haar')\n",
    "lowlight_rec_4 = pywt_synthesis(lowlight_wt_4, 4, 'haar')\n",
    "\n",
    "# Display the results\n",
    "plt.close('all')\n",
    "title_list = [\"Original\", \"Reconstruction (n=1)\", \"Reconstruction (n=4)\"]\n",
    "view = viewer([lowlight_rec_1, lowlight_rec_4, lowlight], title = title_list, widgets = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b376907ef889253b91a777af1457ee95",
     "grade": false,
     "grade_id": "cell-0214a158dcd4cc7e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Great! You are pretty much done with this first notebook of the lab. Now that we have all the tools, you will get the final test for both of your implementations, an element-wise comparison of the output from `synthesis`, `poly_synthesis` and `pywt_synthesis` up to the $10^{th}$ decimal with $n = 3$. Of course, the analysis will be done using `pywt_analysis`, so that we only test the synthesis, and not the analysis. Moreover, the filterbank implementation will also be tested with the Daubechies 2 wavelet (DB2), so that in case of mistakes you can see whether your mistake is in the filters or in the synthesis functions. If the following cell runs without any error, congratulations!\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<b>Note:</b> If there is any mistake, the next cell will also show you where the results are wrong. We will use the tool <i>compare</i> of IPLabImageViewer. Look for the red areas in the images to get a hint of where you might have gone wrong  (these areas are where your implementation and PyWavelets' differ). Note that you can activate the comparison again after changing images by clicking on <code>Options</code> $\\rightarrow$ <code>Compare</code>.\n",
    "</div>\n",
    "\n",
    "If your implementations are correct, we will calculate the *signal-to-noise ratio (SNR)* (in $\\mathrm{dB}$) of the synthesis with respect to the original and include it in the title. This metric measures the ratio of the power of a signal to the power of the noise (or error). The power of the signal is measured from the original image (for example, $x[l,k]$), and the noise can be measured from the difference between the original image and the reconstruction (for example, $\\hat{x}[l,k]$). Therefore, the SNR is computed using the following expression\n",
    "\n",
    "$$\\operatorname{SNR}(x, \\hat{x}) = \\frac{\\operatorname{P}_{signal}}{\\operatorname{P}_{noise}} = \\frac{ \\sum_{l,k} x^2[l,k]}{\\sum_{l,k} (x[l,k] - \\hat{x}[l,k])^2} \\mbox{, and } \\operatorname{SNR}(x, \\hat{x})~[\\mathrm{dB}] = 10 \\log_{10}\\left(\\operatorname{SNR}(x, \\hat{x})\\right)\\,,$$\n",
    "\n",
    "where the summation is done over all pixels. In $\\mathrm{dB}$, a value of $0$ means that we have more signal than noise, and the higher the SNR the better. Pay attention to it!\n",
    "\n",
    "<div class = 'alert alert-danger'>\n",
    "\n",
    "<b>Note:</b> As usual, the fact that this cell runs does not guarantee the points.\n",
    "</div>\n",
    "\n",
    "Run the next cell to apply the tests with the image `lighthouse`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e8ba4c68f258b56c69c334ce94d35c7",
     "grade": false,
     "grade_id": "cell-ec043f50c41e150c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations! You are as good as the most accepted wavelet library in Python. Now, let's look at the quality of the synthesis for the different methods using the SNR.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe1848059df4556b750c62e60de32dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define n\n",
    "n = 3\n",
    "\n",
    "## Checking results for Haar wavelet transform\n",
    "# Get Haar wavelet transform\n",
    "lighthouse_wt = pywt_analysis(lighthouse, n, 'haar')\n",
    "\n",
    "# Get the three reconstructions (PyWavelets, generic filterbank, polyphase)\n",
    "lighthouse_rec_pywt = pywt_synthesis(lighthouse_wt, n, 'haar')\n",
    "lighthouse_rec_poly = poly_synthesis(lighthouse_wt, n)\n",
    "lighthouse_rec_filt = synthesis(lighthouse_wt, synthesis_lp, synthesis_hp, n)\n",
    "\n",
    "# Close all viewers\n",
    "plt.close('all')\n",
    "\n",
    "# Initialize flag to see if there are problems with the Haar wavelet results\n",
    "error_haar = False; error_haar_filt = False\n",
    "# Check polyphase implementation of Haar wavelet transform\n",
    "try:\n",
    "    np.testing.assert_array_almost_equal(lighthouse_rec_poly, lighthouse_rec_pywt, decimal = 10)\n",
    "except Exception as e:\n",
    "    print('Your polyphase implementation is not correct. Look at the following message for details.\\n')\n",
    "    print(e)\n",
    "    error_haar = True\n",
    "    viewer([lighthouse_rec_poly, lighthouse_rec_pywt], \n",
    "           title = [\"Polyphase (Haar)\", \"PyWavelets (Ground truth)\"], compare = True, widgets = True)\n",
    "    \n",
    "# Check generic filterbank implementation of Haar wavelet transform     \n",
    "try:\n",
    "    np.testing.assert_array_almost_equal(lighthouse_rec_filt, lighthouse_rec_pywt, decimal = 10)\n",
    "except Exception as e:\n",
    "    print('Either your filterbank implementation is not correct, or your Haar filters are not (check the test with \\\n",
    "            DB2 filters to know for sure). Look at the following message for details.\\n')\n",
    "    print(e)\n",
    "    error_haar = True; error_haar_filt = True\n",
    "    viewer([lighthouse_rec_filt, lighthouse_rec_pywt], \n",
    "           title = [\"Filterbank (Haar)\", \"PyWavelets (Ground truth)\"], compare = True, widgets = True)\n",
    "    \n",
    "## Checking results for DB2 wavelet transform\n",
    "# Set the coefficients \n",
    "a = (1 + np.sqrt(3))/(4*np.sqrt(2)); b = (3 + np.sqrt(3))/(4*np.sqrt(2))\n",
    "c = (3 - np.sqrt(3))/(4*np.sqrt(2)); d = (1 - np.sqrt(3))/(4*np.sqrt(2))\n",
    "# Define the filters\n",
    "analysis_lp_db2  = np.array([d, c, b, a, 0]);  analysis_hp_db2 = np.array([-a, b, -c, d, 0])\n",
    "synthesis_lp_db2 = np.array([0, a, b, c, d]); synthesis_hp_db2 = np.array([0, d, -c, b, -a])\n",
    "\n",
    "# Get DB2 wavelet transform\n",
    "lighthouse_wt = pywt_analysis(lighthouse, n, 'db2')\n",
    "\n",
    "# Get the two reconstructions (PyWavelets, generic filterbank)\n",
    "lighthouse_rec_filt_db2 = synthesis(lighthouse_wt, synthesis_lp_db2, synthesis_hp_db2, n)\n",
    "lighthouse_rec_pywt_db2 = pywt_synthesis(lighthouse_wt, n, 'db2')\n",
    "\n",
    "# Initialize flag to see if there are problems with the DB2 wavelet results\n",
    "error_db = False\n",
    "# Check generic filterbank implementation of DB2 wavelet transform\n",
    "try:\n",
    "    np.testing.assert_array_almost_equal(lighthouse_rec_filt_db2, lighthouse_rec_pywt_db2, decimal = 10)\n",
    "    if error_haar_filt:\n",
    "        print('Your filterbank implementation is correct, but you should check your Haar filters.')\n",
    "except Exception as e:\n",
    "    print('Your filterbank implementation is not correct. Look at the following message for details.\\n')\n",
    "    print(e)\n",
    "    error_db = True\n",
    "    viewer([lighthouse_rec_filt_db2, lighthouse_rec_pywt_db2], \n",
    "           title = [\"Filterbank (DB2)\", \"PyWavelets (Ground truth)\"], compare = True, widgets = True)\n",
    "\n",
    "# If everything is correct, we want the SNR in the title of each image\n",
    "def snr_db(orig, img):\n",
    "    snr = 10*np.log10(np.sum(orig**2)/np.sum((img - orig)**2))\n",
    "    return snr \n",
    "\n",
    "if not(error_db or error_haar):\n",
    "    print('Congratulations! You are as good as the most accepted wavelet library in Python. Now, let\\'s look \\\n",
    "at the quality of the synthesis for the different methods using the SNR.')\n",
    "    image_list = [lighthouse_rec_pywt, \n",
    "                  lighthouse_rec_poly, \n",
    "                  lighthouse_rec_filt, \n",
    "                  lighthouse_rec_pywt_db2,\n",
    "                  lighthouse_rec_filt_db2,\n",
    "                  lighthouse]\n",
    "\n",
    "    titles = [f'PyWT (Haar, SNR = {np.round_(snr_db(lighthouse, lighthouse_rec_pywt), decimals=2)} dB)', \n",
    "              f'Polyphase (Haar, SNR = {np.round_(snr_db(lighthouse, lighthouse_rec_poly), decimals=2)} dB)',\n",
    "              f'Filterbank (Haar, SNR = {np.round_(snr_db(lighthouse, lighthouse_rec_filt), decimals=2)} dB)',\n",
    "              f'PyWT (DB2, SNR = {np.round_(snr_db(lighthouse, lighthouse_rec_filt_db2), decimals=2)}) dB', \n",
    "              f'Filterbank (DB2, SNR = {np.round_(snr_db(lighthouse, lighthouse_rec_pywt_db2), decimals=2)} dB)',\n",
    "              'Original']\n",
    "\n",
    "    plt.close('all')\n",
    "    wavelet_viewer = viewer(image_list, title = titles, widgets = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3db09d9ed644568adeaed20608e91fd6",
     "grade": false,
     "grade_id": "cell-4d73d2a7a9c5c5d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Did you reflect on the values of the SNR? As an experiment, we will start eliminating a fixed percentage of the smallest elements of the wavelet coefficients. As you will see later in the course, each image transform has a different curve of the *SNR vs the precentage of coefficients kept* for every type of image.    \n",
    "\n",
    "We will plot this curve for your functions and the PyWavelets implementation. If your implementation is completely correct, the curves should be almost indistinguishable. Look at the comments in the next cell for a thorough explanation. We will use the image `doisneau` and $n = 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1437ee9076161e604db68ba1d0b03d86",
     "grade": false,
     "grade_id": "cell-0c1d0c312c2cda58",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bdcb61318404642b6546cfb6bdaccec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Pan', 'Pan axes with left…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define compression rates to test\n",
    "compression_rates = [0.1, 0.3, 0.5,  1, 3, 5, 10, 20, 30, 50, 60]\n",
    "\n",
    "# Define compression function \n",
    "def compress(img, per):\n",
    "    output = np.copy(img)\n",
    "    # Get the value of  the threshold\n",
    "    T = np.percentile(np.abs(output), 100-per)\n",
    "    # Set to zero all the pixels below the threshold\n",
    "    output[np.abs(output) < T] = 0\n",
    "    return output\n",
    "\n",
    "# Initialize varible to store SNRs\n",
    "snrs_poly = np.empty_like(compression_rates)\n",
    "snrs_filt = np.empty_like(compression_rates)\n",
    "snrs_pywt = np.empty_like(compression_rates)\n",
    "# Pre-compute wavelet transforms\n",
    "wt_poly = poly_analysis(doisneau, 1)\n",
    "wt_filt = analysis(doisneau, analysis_lp, analysis_hp, 1)\n",
    "wt_pywt = pywt_analysis(doisneau, 1, 'haar')\n",
    "# Iterate through compression rates\n",
    "for idx, per in enumerate(compression_rates):\n",
    "    # compress and reconstruct with polyphase formulation. Get SNR\n",
    "    comp_poly = compress(wt_poly, per)\n",
    "    rec_poly = poly_synthesis(comp_poly,1)\n",
    "    snrs_poly[idx] = snr_db(doisneau, rec_poly)\n",
    "    # compress and reconstruct with filterbanks. Get SNR\n",
    "    comp_filt = compress(wt_filt, per)\n",
    "    rec_filt = synthesis(comp_filt, synthesis_lp, synthesis_hp, 1)\n",
    "    snrs_filt[idx] = snr_db(doisneau, rec_filt)\n",
    "    # compress and reconstruct with pywt. Get SNR\n",
    "    comp_pywt = compress(wt_pywt, per)\n",
    "    rec_pywt = pywt_synthesis(comp_pywt, 1, 'haar')\n",
    "    snrs_pywt[idx] = snr_db(doisneau, rec_pywt)\n",
    "\n",
    "# Close existing figures and initialize a new one\n",
    "plt.close('all')\n",
    "plt.figure(figsize = [10, 7])\n",
    "ax = plt.gca()\n",
    "# Declare lines. Store in variable p to add legends later\n",
    "p = plt.plot(compression_rates, snrs_poly, 'r-o', \n",
    "             compression_rates, snrs_filt, 'b--o', \n",
    "             compression_rates, snrs_pywt, 'g:o')\n",
    "\n",
    "# Make log scale\n",
    "plt.xscale('log')\n",
    "plt.xticks([0.1, 0.5, 1, 5, 10, 50, 100])\n",
    "plt.xlabel('% of coefficients kept')\n",
    "plt.ylabel('SNR [dB]')\n",
    "plt.title('SNR [dB] vs % of coefficients kept')\n",
    "ax.grid(which = 'both')\n",
    "ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "plt.legend(p, ['Polyphase', 'Filterbank', 'PyWT (Ground truth)'], fontsize =  10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e98d1c4c7412e6998a14b04fa0508563",
     "grade": false,
     "grade_id": "cell-bc4dedb3070c5b3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "<b>Note:</b> If you really enjoyed this notebook, you love wavelets and want to keep exploring the topic, use the following cell to play around! We have included a widget with several functionalities (visualizing both the wavelet transform and the reconstruction with different colormaps, values of $n$, and different wavelet families), all using PyWavelets. Feel free to change or add any code! \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479e14f4bc634f25828a14c241942e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_slider = widgets.IntSlider(value = 1, min = 0, max = 4, step = 1, description = 'n') \n",
    "wt_menu = widgets.Dropdown(options = ['haar', 'db2', 'db10', 'bior1.3', 'bior6.8', 'rbio1.3', 'dmey'], \n",
    "                                value = 'haar', description = 'WT:')\n",
    "mapping_menu = widgets.Dropdown(options = ['None', 'Normalize Std Dev', 'Non-Uniform Mapping'], \n",
    "                                value = 'None', description = 'Mapping:')\n",
    "mode_menu = widgets.Dropdown(options = ['WT', 'iWT'], \n",
    "                                value = 'WT', description = 'Mode')\n",
    "button = widgets.Button(description = 'Apply')\n",
    "\n",
    "def wavelet_callback(img):\n",
    "    n = n_slider.value\n",
    "    wt = wt_menu.value\n",
    "    output = pywt_analysis(img, n, wt)\n",
    "    if mode_menu.value == 'WT':\n",
    "        if mapping_menu.value == 'None':\n",
    "            output = map_color(output, n = n, color_map = np.array)\n",
    "        elif mapping_menu.value == 'Normalize Std Dev':\n",
    "            output = map_color(output, n = n, color_map = norm_std_map)\n",
    "        else:\n",
    "            output = map_color(output, n = n, color_map = non_uniform_map)\n",
    "    else:\n",
    "        output = pywt_synthesis(output, n, wt)\n",
    "    return output\n",
    "\n",
    "\n",
    "plt.close('all')\n",
    "wavelet_viewer = viewer(lighthouse, title = \"WT Analysis\", \n",
    "                        new_widgets = [n_slider, wt_menu, mapping_menu, mode_menu, button], \n",
    "                        callbacks = [wavelet_callback], widgets = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7ada169bb3d6f755ee4ac50326a0977",
     "grade": false,
     "grade_id": "cell-6b7bfa65608a203d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "<p><b>Congratulations on finishing the first part of the Wavelets lab!</b></p>\n",
    "<p>\n",
    "Make sure to save your notebook (you might want to keep a copy on your personal computer) and upload it to <a href=\"https://moodle.epfl.ch/mod/assign/view.php?id=1148687\">Moodle</a>, in a zip file with other notebooks of this lab.\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "* Name the notebook: *SCIPER_1_Wavelet_transform.ipynb* (e.g. *123456_1_Wavelet_transform.ipynb*)\n",
    "* Name the zip file: *SCIPER_Wavelets_Lab.zip* (e.g. *123456_Wavelets_Lab.zip*).\n",
    "\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<h4>Feedback</h4>\n",
    "    <p style=\"margin:4px;\">\n",
    "    This is the first edition of the image-processing laboratories using Jupyter Notebooks running on Noto. Do not leave before giving us your <a href=\"https://moodle.epfl.ch/mod/feedback/view.php?id=1148686\">feedback here!</a></p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "sos": {
   "kernels": [
    [
     "JavaScript",
     "javascript",
     "JavaScript",
     "#c8e1ae",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "panel": {
    "displayed": false,
    "height": 0
   },
   "version": "0.21.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "375.152px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
