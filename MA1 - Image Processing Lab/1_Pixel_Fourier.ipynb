{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "365f982cd66787ac0f50aee246f71fb7",
     "grade": false,
     "grade_id": "cell-87ef5277e6904d04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src=\"https://www.epfl.ch/about/overview/wp-content/uploads/2020/07/logo-epfl-1024x576.png\" style=\"padding-right:10px;width:140px;float:left\"></td>\n",
    "<h2 style=\"white-space: nowrap\">Image Processing Laboratory Notebooks</h2>\n",
    "<hr style=\"clear:both\">\n",
    "<p style=\"font-size:0.85em; margin:2px; text-align:justify\">\n",
    "This Juypter notebook is part of a series of computer laboratories which are designed\n",
    "to teach image-processing programming; they are running on the EPFL's Noto server. They are the practical complement of the theoretical lectures of the EPFL's Master course <b>Image Processing I</b> \n",
    "(<a href=\"https://moodle.epfl.ch/course/view.php?id=522\">MICRO-511</a>) taught by Prof. M. Unser and Prof. D. Van de Ville.\n",
    "</p>\n",
    "<p style=\"font-size:0.85em; margin:2px; text-align:justify\">\n",
    "The project is funded by the Center for Digital Education and the School of Engineering. It is owned by the <a href=\"http://bigwww.epfl.ch/\">Biomedical Imaging Group</a>. \n",
    "The distribution or the reproduction of the notebook is strictly prohibited without the written consent of the authors.  &copy; EPFL 2020.\n",
    "</p>\n",
    "<p style=\"font-size:0.85em; margin:0px\"><b>Authors</b>: \n",
    "    <a href=\"mailto:pol.delaguilapla@epfl.ch\">Pol del Aguila Pla</a>, \n",
    "    <a href=\"mailto:kay.lachler@epfl.ch\">Kay Lächler</a>,\n",
    "    <a href=\"mailto:alejandro.nogueronaramburu@epfl.ch\">Alejandro Noguerón Arámburu</a>, and\n",
    "    <a href=\"mailto:daniel.sage@epfl.ch\">Daniel Sage</a>.\n",
    "</p>\n",
    "<hr style=\"clear:both\">\n",
    "<h1>Lab 1: Pixel-wise operations and the Fourier transform</h1>\n",
    "<div style=\"background-color:#F0F0F0;padding:4px\">\n",
    "    <p style=\"margin:4px;\"><b>Released</b>: Thursday October 1, 2020</p>\n",
    "    <p style=\"margin:4px;\"><b>Submission</b>: <span style=\"color:red\">Friday October 9, 2020</span> (before 11:59PM) on <a href=\"https://moodle.epfl.ch/course/view.php?id=522\">Moodle</a></p>\n",
    "    <p style=\"margin:4px;\"><b>Grade weigth</b>: 9% of the overall grade</p>\n",
    "    <p style=\"margin:4px;\"><b>Remote help</b>: Monday October 5, on Zoom (see Moodle for link and time)</p>    \n",
    "    <p style=\"margin:4px;\"><b>Related lectures</b>: Chapters 1 and 2</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Student Name: Filip Slezak\n",
    "### SCIPER: 286557\n",
    "\n",
    "Double-click on this cell and fill your name and SCIPER number. Then, run the cell below to verify your identity in Noto and set the seed for random results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52dd58a50e79b44edfb758cae861a3cd",
     "grade": false,
     "grade_id": "cell-2f6633932108c60f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCIPER: 286557\n"
     ]
    }
   ],
   "source": [
    "%use sos\n",
    "import getpass\n",
    "# This line recovers your camipro number to mark the images with your ID\n",
    "uid = int(getpass.getuser().split('-')[2]) if len(getpass.getuser().split('-')) > 2 else ord(getpass.getuser()[0])\n",
    "print(f'SCIPER: {uid}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "744e862dd69d20e3b3cd9c8f1aea6a5f",
     "grade": false,
     "grade_id": "cell-9f52138bd6524e0b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <a name=\"imports_\"></a> Imports\n",
    "In the next cell we import the python libraries that we will use throughout the lab, as well as the `IPLabViewer()` class (see documentation [here](https://github.com/Biomedical-Imaging-Group/IPLabImageViewer/wiki/Python-IPLabViewer()-Class), or run the python command `help(viewer)` after loading the class):\n",
    "* [`matplotlib.pyplot`](https://matplotlib.org), to display images,\n",
    "* [`ipywidgets`](https://ipywidgets.readthedocs.io/en/latest/), to make the image display interactive, and\n",
    "* [`numpy`](https://numpy.org/doc/stable/reference/index.html), for mathematical operations on arrays.\n",
    "\n",
    "Finally, we load the images used in this lab.\n",
    "\n",
    "Run the cell to get your notebook ready.\n",
    "\n",
    "<div class=\" alert alert-danger\">\n",
    "    \n",
    "**Note:** Always run the two import cells below before starting to work on the notebook.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "170f7574df99f1ffc34d723c898eb36a",
     "grade": false,
     "grade_id": "cell-7ebcf2f0631aad5a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Configure plotting as dynamic\n",
    "%matplotlib widget\n",
    "\n",
    "# Import required packages for this lab\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "\n",
    "# Loading IPLabViewer \n",
    "from lib.iplabs import IPLabViewer as viewer\n",
    "\n",
    "# Loading images\n",
    "hrct = plt.imread( \"images/hrct.tif\" )\n",
    "joux = plt.imread( \"images/joux.tif\" )\n",
    "car = plt.imread( \"images/car_pad.tif\" )\n",
    "mandrill = plt.imread( \"images/mandrill.tif\")\n",
    "impulse = np.zeros((65,65)); impulse[32,32] = 1;\n",
    "pens = plt.imread( \"images/pens.tif\" )\n",
    "zebra = plt.imread(\"images/zebra.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b15a316e08214854d52b1624eeac7b7",
     "grade": false,
     "grade_id": "cell-c68b35dfa4eeaa5d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the following cell we import the `IPLabImageAccess` class. You can find the documentation of the class [here](https://github.com/Biomedical-Imaging-Group/IPLabImageAccess/wiki)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b655daf1e4a8b386e6e2b8ec2b441e1f",
     "grade": false,
     "grade_id": "cell-c6c746246d09f0e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "// import the IPLabImageAccess class as Image\n",
    "var Image = require('./lib/IPLabImageAccess.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c4b63b55d2f7215af2c6ac7dd8d3ee9",
     "grade": false,
     "grade_id": "cell-9584117c30781c3d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Pixel-wise operations and the Fourier transform (14 points)\n",
    "\n",
    "In the first part of this lab you will learn the basics of pixel-wise image processing by performing simple operations. For example, you will learn to use color to see more details in images. \n",
    "\n",
    "In the second part we will look at the 2D discrete Fourier transform, what it represents, and how an image can be reconstructed from its 2D discrete Fourier transform by using the inverse discrete Fourier transform.\n",
    "\n",
    "## <a class=\"anchor\"></a> Index\n",
    "1. [Pixel-wise operations](#-1.-Pixel-wise-operations-(8-Points))\n",
    "    1. [16-bit gray-scale images: Visualization and Colorization](#-1.A.-16-bit-gray-scale-images:-Visualization-and-Colorization-(3-Points)) **(3 points)**\n",
    "    2. [Image normalization](#-1.B.-Image-normalization-(6-Points)) **(6 points)**\n",
    "2. [Understanding the Fourier transform](#-2.-Understanding-the-Fourier-transform-(5-Points))\n",
    "    1. [The FT and its inverse](#-2.A.-The-FT-and-its-inverse-(3-Points)) **(3 points)**\n",
    "    2. [Reconstruction](#-2.B.-Reconstruction-(2-Points)) **(2 points)**\n",
    "    \n",
    "\n",
    "<div class=\" alert alert-danger\">\n",
    "    \n",
    "<b>Important:</b> Each cell that contains code begins with `%use sos` or `%use javascript`. This indicates if the code in this specific cell should be executed in Python or JavaScript. Do not change or remove any lines of code that begin with an %. They need to be on the first line of each cell!\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e36d9215908e3137ca0f5d7399fab7f2",
     "grade": false,
     "grade_id": "cell-8f718308c0429f7e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Take some time to explore the images you will be using. Run the next cell and look at the histograms, the range of values, etc.\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "**Hint:** Use the buttons `Prev`/`Next` to cycle through the images.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd7d6818a09504bd7015c041deeec674",
     "grade": false,
     "grade_id": "cell-40e70c87a9f21f8b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e168f72cca401e899a34a2bb86aeaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%use sos\n",
    "# Define the list of images\n",
    "image_list = [hrct, joux, car, mandrill, impulse, pens, zebra]\n",
    "# Display all images used in this lab\n",
    "initial_viewer = viewer(image_list, hist = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c04acd0aa05a4a4763090c2b486bfe14",
     "grade": false,
     "grade_id": "cell-5e2f118cc6a06a77",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# <a class=\"anchor\"></a> 1. Pixel-wise operations (8 Points) \n",
    "## <a class=\"anchor\"></a> 1.A. 16-bit gray-scale images: Visualization and Colorization (3 Points)\n",
    "[Back to index](#-Index)\n",
    "### Limitations in visualization\n",
    "\n",
    "Most standard screens use only 8 bits to visualize gray-level images, which allows for $2^8 = 256$ different gray-levels to be displayed at the same time. For day-to-day photography this is enough, but to store all the important information contained in medical images, a 16-bit representation is often necessary, which provides $2^{16} = 65536$ different gray-levels. This poses a problem because a standard screen cannot show all the gray-levels in a 16-bit image at the same time. To illustrate the problem we will look at the image `hrct`, which is encoded with 16 bits. The image shows the result of a [computed tomography](https://en.wikipedia.org/wiki/CT_scan) scan of a human thorax. These type of images can, for example, be used to diagnose or assess the developement of COVID-19 in patients ([see more here](https://radiologyassistant.nl/chest/covid-19/covid19-imaging-findings)). \n",
    "\n",
    "Run the next cell and explore the gray-level range. Try to find hidden content in the image that is not visible at first (at first you will only see the thorax). \n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "**Hint:** You can adjust the gray-level range of the image by adjusting the values (max / min) of the <i>Brightness & Contrast</i> slider.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1de4c1244768a7df4f2e5847b03b3a01",
     "grade": false,
     "grade_id": "cell-f4b0e4cd2ccf0077",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05bde9cd6dbf43be82e79ba7efdb121c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%use sos\n",
    "# Display the hrct image to find hidden information\n",
    "plt.close(\"all\")\n",
    "hrct_viewer = viewer(hrct, title = 'HRCT', widgets = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5cfe798441744a918b620f391f5d5e2d",
     "grade": false,
     "grade_id": "cell-0c90e6e39c1b2eb2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Multiple choice question\n",
    "For **1 point**, once you have explored the image, answer the next questions:\n",
    "\n",
    "* Q1: How many 8-bit grayscale images do we need to store the same information contained in a generic 16-bit image?\n",
    "    1. 2,\n",
    "    2. 8,\n",
    "    3. 256, or\n",
    "    4. 16.\n",
    "\n",
    "\n",
    "* Q2: As you will study below, using color is another option to see more of the information contained in a 16-bit image on screen. Now, choose `Options` and select the colormap `nipy_spectral` (make sure that the *Brightness & Contrast* slider spans the whole range). This view reveals wide-spread structures within the patient's lungs, which could be relevant to doctors. Which of the following ranges with a `gray` colormap show those details best?\n",
    "    1. $0\\%$ to $10\\%$,\n",
    "    2. $90\\%$ to $100\\%$, or\n",
    "    3. $50\\%$ to $60\\%$.\n",
    "\n",
    "Modify the variables `answer_one` and `answer_two` in the next cell to reflect your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9229488737260c9852a102a307248572",
     "grade": false,
     "grade_id": "ans-6b13c749168967dc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Assign your answer to this variable\n",
    "answer_one = 3\n",
    "answer_two = 1\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b81c1268af2432c34ad8cb2ce82fe807",
     "grade": true,
     "grade_id": "grad-448afa98ba9b0f69",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Check that the answer is in the correct range\n",
    "assert answer_one in [1,2,3,4], 'Possible values are 1, 2, 3 or 4.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9db8d185b93cd4cb0dc0ecb9e94d1187",
     "grade": true,
     "grade_id": "grad-1cde3c313304ad30",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Check that the answer is in the correct range\n",
    "assert answer_two in [1,2,3], 'Possible values are 1, 2, or 3.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "103c6a68c8e41576adfb9e38d802c276",
     "grade": false,
     "grade_id": "cell-ba4960a6f388a10f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### <a class=\"anchor\"></a> Colorization\n",
    "\n",
    "As we have seen, then, color is a powerful tool to overcome the representation limitations of 8-bit screens. The basic idea is to express the 16-bit range $[0,65535]$ using a combination of three 8-bit $[0, 255]$ channels to make a color (RGB) image. This exercise will guide you through this process.\n",
    "\n",
    "There are many alternatives to divide a range into sub-ranges (_a.k.a._ colormaps), but you will implement the one specified by the picture below:\n",
    "\n",
    "<img src=\"images/graylevel_divide_rgb.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "The three lines reflect the intensity values of each channel depending on the original graylevel intensity. $N$ is the maximum graylevel intensity for a 16-bit image, i.e., ($2^{16} - 1$).\n",
    "\n",
    "For **1 point**, modify the function `color_pixel_wise(img)` in the next cell to iterate through every pixel in the image and create a new colorized image. The three color channels should be defined according to the figure above.\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note:** You only need to modify the variables `r`, `g` and `b`. Everything else has already been prepared for you. Make sure you understand the code and fill in the blanks.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "deletable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f812161d75f4d5360edbe6b619e83048",
     "grade": false,
     "grade_id": "ans-ee93a8c0f1746b2a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "// function that divides a 16 bit graylevel image into a rgb image with 8 bits per channel\n",
    "function color_pixel_wise(img){\n",
    "    // the max value of the original image (16 bits)\n",
    "    var N = Math.pow(2,16) - 1;\n",
    "    // the max value of each channel of the new image (8 bits)\n",
    "    var new_N = 255;\n",
    "    // initialize output image (color image)\n",
    "    options = {}; options.rgb = true;\n",
    "    var output = new Image(img.ny, img.nx, options);\n",
    "    // Iterate through each pixel\n",
    "    for(var x = 0; x < img.nx; x++){\n",
    "        for(var y = 0; y < img.ny; y++){\n",
    "            // initialize the red, green and blue channels to 0\n",
    "            var r = 0, g = 0, b = 0;\n",
    "            // get the pixel value at the current location\n",
    "            var value = img.getPixel(x, y);\n",
    "            \n",
    "            // assign the correct values to the red, green and blue channels according to the proposed mapping\n",
    "            // YOUR CODE HERE\n",
    "            if(value < 0.25*N) {\n",
    "                r = 1020/N*value;\n",
    "            } else if(value < 0.50*N) {\n",
    "                g = 1020/N*(value - 0.25*N);\n",
    "                r = 255 - g;\n",
    "            } else if(value < 0.75*N) {\n",
    "                b = 1020/N*(value - 0.50*N);\n",
    "                g = 255 - b;\n",
    "            } else {\n",
    "                b = 255 - 1020/N*(value - 0.75*N);\n",
    "            }\n",
    "            // set the three color channels in the output image (convert them to integers using Math.round)\n",
    "            output.setPixel(x, y, [Math.round(r), Math.round(g), Math.round(b)])\n",
    "        }\n",
    "    }\n",
    "    return output;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d1aaf0ab7d4026a288ab7011090b8d98",
     "grade": false,
     "grade_id": "cell-1416bf10fe3e0039",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Great, using the two cells below we are going to visualize your image. If everything went well, you should see most of the hidden details in red (blood vessels and details inside the lungs), the middle values in green (soft tissues, fat, etc.) and the higher values in blue (aorta, bone tissue, etc.). \n",
    "\n",
    "In the next cell, we are first going to get the image `hrct` from the Python kernel, and then apply your function to it. Finally, we put the result (`hrct_colorized_js`) back into the Python kernel for visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0e2947685f7f3517a905e28ea263b15",
     "grade": false,
     "grade_id": "cell-ce224e861be6abd1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "%get hrct\n",
    "%put hrct_colorized_js\n",
    "\n",
    "var hrct_img = new Image(hrct);\n",
    "var hrct_colorized_js = color_pixel_wise(hrct_img).toArray();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e20f096b8a7c75f1a1beafdc912258e4",
     "grade": false,
     "grade_id": "cell-9c30e30bb733d166",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that your result is stored in Python, run the next cell to visualize it.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<b>Note: </b> SoS translates JS arrays as Python lists. However, `IPLabViewer` (and every major IP library) works with NumPy arrays, so we have to explicitly call the method <code>np.array()</code> on the result from JS.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "26d5fce863fef2bab33f60695b5f058a",
     "grade": false,
     "grade_id": "cell-5ee440935eada122",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d349394562d41ad878bdb78ef90d6a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6759d5c814054ec6a9947a324ea8add3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%use sos\n",
    "# Convert to NumPy array\n",
    "hrct_colorized_js = np.array(hrct_colorized_js)\n",
    "# Visualize\n",
    "plt.close('all')\n",
    "hrct_colorized_viewer = viewer(hrct_colorized_js, title='HRTC colorized JS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5a8a2e797b987d88bcfdf02775bb7f64",
     "grade": false,
     "grade_id": "cell-cb5a2a94f1aed1e3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Is your result correct? At the top of the image you should see the color bar transition **smoothly** from black to red, from red to green, from green to blue, and back to black again.\n",
    "\n",
    "Let's make some sanity tests to check that the image is really a color image and that the maximum and minimum value of each channel are $0$ and $255$ respectively. We will constantly be making these kinds of tests to ensure the correct behaviour of any code you write."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e07458de5c3b6da2c30a19b832839255",
     "grade": false,
     "grade_id": "cell-4d6f9c50702ecda0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congrats, your function passed the sanity checks. However, that does not necessarily mean that everything is correct.\n"
     ]
    }
   ],
   "source": [
    "%use sos\n",
    "# Check that the image has indeed 3 color channels\n",
    "assert hrct_colorized_js.shape[2] == 3, \"The resulting image doesn't have 3 color channels!\"\n",
    "# Check that the max and min of each channel are 0 and 255\n",
    "assert np.min(hrct_colorized_js[:,:,0]) == 0, f\"The minimum of the red color channel is {np.min(hrct_colorized_js[:,:,0])} and not 0!\"\n",
    "assert np.min(hrct_colorized_js[:,:,1]) == 0, f\"The minimum of the green color channel is {np.min(hrct_colorized_js[:,:,1])} and not 0!\"\n",
    "assert np.min(hrct_colorized_js[:,:,2]) == 0, f\"The minimum of the blue color channel is {np.min(hrct_colorized_js[:,:,2])} and not 0!\"\n",
    "assert np.max(hrct_colorized_js[:,:,0]) == 255, f\"The maximum of the red color channel is {np.max(hrct_colorized_js[:,:,0])} and not 255!\"\n",
    "assert np.max(hrct_colorized_js[:,:,1]) == 255, f\"The maximum of the green color channel is {np.max(hrct_colorized_js[:,:,1])} and not 255!\"\n",
    "assert np.max(hrct_colorized_js[:,:,2]) == 255, f\"The maximum of the blue color channel is {np.max(hrct_colorized_js[:,:,2])} and not 255!\"\n",
    "print(\"Congrats, your function passed the sanity checks. However, that does not necessarily mean that everything is correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "52d4059a7cc305ce77e2859989054fa1",
     "grade": false,
     "grade_id": "cell-208b89bc9642f0e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If we wanted to perform the same colorization in Python, we shouldn't do it pixel-wise as in JavaScript, since this will be extremely slow. As you saw in the introductory lab, languages that allow __[vectorization](https://en.wikipedia.org/wiki/Automatic_vectorization)__ like Python (through the NumPy library) and MATLAB allow operations to be performed on whole arrays. This is much simpler to code and as fast as a `for` loop in a low-level programming language. \n",
    "\n",
    "In the following cell, we show you how to colorize your image in Python, without the need to iterate through every pixel. This function is exactly like the one you created in JavaScript, but we added the parameters `peak1`, `peak2` and `peak3`, which will be useful in the next exercise. Make sure to fully understand the function. If you have any doubts, go back to the [Introductory lab](./Introductory.ipynb), or read about [boolean indexing in NumPy](https://numpy.org/devdocs/reference/arrays.indexing.html#boolean-array-indexing).\n",
    "\n",
    "When you run the next cell, you will generate and visualize the variable `hrct_colorized_python`. It should look exactly like the result you got from the JavaScript function above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2949e146a49859b42ae7543e8e7623f1",
     "grade": false,
     "grade_id": "cell-9f3c2d90af10ad23",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1eb6ee1bc14b77922b9261009712cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824586b48a0e4c8f92dd8f5ce6dabbc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%use sos\n",
    "# Function that divides a `bits` bit graylevel image into a rgb image with 8 bits per channel depending on the three specified limits (in %)\n",
    "def color_vectorized(img, peak1 = 25, peak2 = 50, peak3 = 75, bits = 16):     \n",
    "    # Initialize max value\n",
    "    N = 2**bits - 1\n",
    "    N_new = 2**8 - 1\n",
    "    \n",
    "    # Make sure that peak1 < peak2 < peak3\n",
    "    peak1, peak2, peak3 = np.sort([peak1, peak2, peak3])\n",
    "    \n",
    "    # Adjust limit values from percent to absolute value\n",
    "    peak1 = peak1 / 100 * N\n",
    "    peak2 = peak2 / 100 * N\n",
    "    peak3 = peak3 / 100 * N\n",
    "    \n",
    "    # Initialize 3 color channels with the appropriate dimensions\n",
    "    color_R = np.zeros(img.shape)\n",
    "    color_G = np.zeros(img.shape)\n",
    "    color_B = np.zeros(img.shape)\n",
    "    \n",
    "    # Generate boolean arrays corresponding to the 4 different sections. \n",
    "    section_1 = img < peak1\n",
    "    section_2 = np.logical_and(peak1 <= img, img < peak2)\n",
    "    section_3 = np.logical_and(peak2 <= img, img < peak3)\n",
    "    section_4 = peak3 <= img\n",
    "    \n",
    "    # Assign the pixel values of each channel depending on the section\n",
    "    color_R[section_1] = img[section_1] / peak1\n",
    "    color_R[section_2] = 1 - (img[section_2] - peak1) / (peak2 - peak1)\n",
    "    color_G[section_2] = (img[section_2] - peak1) / (peak2 - peak1)\n",
    "    color_G[section_3] = 1 - (img[section_3] - peak2) / (peak3 - peak2)\n",
    "    color_B[section_3] = (img[section_3] - peak2) / (peak3 - peak2)\n",
    "    color_B[section_4] = 1 - (img[section_4] - peak3) / (N - peak3)\n",
    "    \n",
    "    # Concatenate the three color channels into one color image    \n",
    "    color_img = np.dstack((color_R,color_G,color_B))\n",
    "    # Multiply by maximum and round to 8-bit integers\n",
    "    color_img = np.round(color_img * N_new).astype(np.uint8)\n",
    "\n",
    "    return(color_img)\n",
    "\n",
    "\n",
    "# Run the function for the same (evenly spaced) limits as in the JavaScript function\n",
    "hrct_colorized_python = color_vectorized(hrct)\n",
    "\n",
    "# Visualize results\n",
    "plt.close('all')\n",
    "hrct_colorized_python_viewer = viewer([hrct_colorized_js, hrct_colorized_python], \n",
    "                                      title=['JS colorization', 'Python colorizaiton'], subplots=(1,2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "84d6603796a7c7ffef72148fa67be108",
     "grade": false,
     "grade_id": "cell-626401e74f06d536",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Besides the visual test, you can use the next cell to compare your implementation to our function in Python. The results should be nearly identical. We use the function numpy [`assert_array_almost_equal`](https://numpy.org/doc/stable/reference/generated/numpy.testing.assert_array_almost_equal.html), and compare the two arrays up to the 4th decimal number. Run the next cell, if it runs smoothly, your implementation is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49c41bbfb5a76af483faa4abf377ddbb",
     "grade": true,
     "grade_id": "grad-e8ad92f1be35983c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good job! Your implementation in JS was correct.\n"
     ]
    }
   ],
   "source": [
    "%use sos\n",
    "# Test if the two images are almost the same\n",
    "np.testing.assert_array_almost_equal(hrct_colorized_python, hrct_colorized_js, decimal = 4, err_msg='Hint: Check your your range limits')\n",
    "print('Good job! Your implementation in JS was correct.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "67ad9c4fea952b6cfd814c818dc75d46",
     "grade": false,
     "grade_id": "cell-25f899a0b36fc40f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As you can see, this is already a much better representation than only using one gray-level channel. However, we can do even better: In the above image, we used evenly spaced peaks for the triangles in the color mapping. However, if we know that some intensity ranges of the image contain more information than others, we can adjust the peaks to increase the visibility of these intensity ranges.\n",
    "\n",
    "In the cell below we will add an extra functionality to the `viewer`: We will declare three sliders that will allow us to dynamically set the peaks of the triangles in our colorization, as well as the corresponding button and activation function (to review how this works, check the introductory lab). The activation function will get the value of the sliders, and call the method `color_vectorized()` on the input image.\n",
    "\n",
    "Below the viewer, we will plot a histogram of the image, overlayed with the triangles implemented by `color_vectorized()` for each slider selection. In this histogram the peaks will update in real time as you move the sliders in the viewer. This is meant for you to get a better idea of which ranges of values in the image enclose more information, and how one should design a colorization to reveal this information. **You do not need to understand this code-block**, however, if you are curious about `matplotlib` and `ipywidgets`, take the time to understand what we are doing.\n",
    "\n",
    "Run the next cell and click on the button *Extra Widgets* to play with the three sliders. To show the effect of the current slider selection, click on `Apply Colorization`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c738dc6497b6242a410017967f6364a2",
     "grade": false,
     "grade_id": "cell-1bb15a7a12da6f41",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2feceec9eb934f98b26d3ab5d06cb1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022054c08c534673bc904fb49b9943b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Pan', 'Pan axes with left…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%use sos\n",
    "plt.close('all')\n",
    "\n",
    "# Defining the sliders and the button of the extra widget\n",
    "peak1_slider = widgets.IntSlider(value = 25, min = 0, max = 100, step = 1, description = 'Peak 1 (%)')\n",
    "peak2_slider = widgets.IntSlider(value = 50, min = 0, max = 100, step = 1, description = 'Peak 2 (%)')\n",
    "peak3_slider = widgets.IntSlider(value = 75, min = 0, max = 100, step = 1, description = 'Peak 3 (%)')\n",
    "activation_button = widgets.Button(description = 'Apply Colorization')\n",
    "\n",
    "# Sort sliders whenever a user crosses them\n",
    "def sort_sliders():\n",
    "    peak1_slider.value, peak2_slider.value, peak3_slider.value = np.sort([peak1_slider.value, \n",
    "                                                                          peak2_slider.value, \n",
    "                                                                          peak3_slider.value])\n",
    "# Defining the callback function of the button\n",
    "def activation_callback(img):\n",
    "    # Sort sliders (should not be necessary)\n",
    "    sort_sliders()\n",
    "    # Colorize image\n",
    "    output = color_vectorized(img, peak1_slider.value, peak2_slider.value, peak3_slider.value)\n",
    "    return output\n",
    "\n",
    "# Visualize the image with the extra widget functionality\n",
    "colorization_ranges_viewer = viewer(hrct, title = 'Personalizing your colormap', \n",
    "                                    new_widgets = [peak1_slider, peak2_slider, peak3_slider, activation_button], \n",
    "                                    callbacks = [activation_callback], widgets=True)\n",
    "\n",
    "## The code below plots the interactive histogram.\n",
    "## Feel free to explore it, but without any pressure.\n",
    "\n",
    "# Maximum value in image\n",
    "N = np.amax(hrct)\n",
    "# Compute the histogram\n",
    "hist, bins = np.histogram(hrct, bins = 70, range = (0, N))\n",
    "# 10% over maximum number of counts (arbitrary max value for triangles)\n",
    "Y = 1.1*np.amax(hist)\n",
    "# Declare a matplotlib figure, capture its axes, plot the histogram, select axis' limits, and set x ticks to %\n",
    "fig = plt.figure(num=f\"SCIPER: {uid}\",figsize = (4, 2.7)); ax = plt.gca()\n",
    "ax.bar(bins[:-1], hist, width = (bins[1] - bins[0]) / 1.2)\n",
    "ax.set_xlim(0, N); ax.set_ylim(0, Y); plt.yticks([],[])\n",
    "plt.xticks([0,.25*N,.5*N,.75*N,N],[r\"$0\\%$\",r\"$25\\%$\",r\"$50\\%$\",r\"$75\\%$\",r\"$100\\%$\"])\n",
    "plt.title(\"Image Histogram and Colorization\")\n",
    "# List to store the lines that will form the triangles\n",
    "lines = []\n",
    "# Function that generates the triangles based on the peaks' positions\n",
    "def generate_triangles(peak1, peak2, peak3):\n",
    "    peak1, peak2, peak3 = np.sort([peak1, peak2, peak3])\n",
    "    xdata = [[0, peak1], [peak1, peak2], [peak1, peak2], [peak2, peak3] , [peak2, peak3], [peak3, N]]\n",
    "    ydata = [[0, Y], [Y, 0], [0, Y], [Y, 0] , [0, Y], [Y, 0]]\n",
    "    return xdata, ydata\n",
    "\n",
    "# Initial plot of the lines that form the triangles (2 per triangle)\n",
    "color = 2*'r' + 2*'g'+ 2*'b' \n",
    "for i in range(6):\n",
    "    xdata, ydata = generate_triangles(N/4, N/2, 3*N/4)\n",
    "    lines.append(ax.plot(xdata[i], ydata[i], color[i]))\n",
    "    \n",
    "# Callback of sliders\n",
    "def update_histogram(change):\n",
    "    sort_sliders()  \n",
    "    # Get the data \n",
    "    xdata, _ = generate_triangles(N*peak1_slider.value/100, N*peak2_slider.value/100, N*peak3_slider.value/100)\n",
    "    # Update lines\n",
    "    count = 0    \n",
    "    for line in lines:\n",
    "        line[0].set_xdata(xdata[count])\n",
    "        count += 1\n",
    "        \n",
    "# Link sliders to callback (the three to the same callback)\n",
    "for slider in [peak1_slider, peak2_slider, peak3_slider]:\n",
    "    slider.observe(update_histogram, 'value') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5715c88e0b6764b671e7998e11cecddf",
     "grade": false,
     "grade_id": "cell-afc5006d54e9e9b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Multiple choice question\n",
    "For **1 point**, which of the following combination of peaks allows you to see the most information?\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<b>Tip:</b> If you do not see the sliders' values, slide right or set your browser's magnification to $100\\%$.\n",
    "</div>\n",
    "\n",
    "1. `Peak 1` = $10\\%$, `Peak 2` = $30\\%$, `Peak 3` = $60\\%$,\n",
    "2. `Peak 1` = $25\\%$, `Peak 2` = $50\\%$, `Peak 3` = $75\\%$, or\n",
    "3. `Peak 1` = $10\\%$, `Peak 2` = $60\\%$, `Peak 3` = $85\\%$.\n",
    "\n",
    "Modify the variable `answer` in the next cell to reflect your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33979ef184370e2b5e9b4e7fa7b1896e",
     "grade": false,
     "grade_id": "ans-3ed4f2305a16c6ac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Assign your answer to this variable\n",
    "answer = 3\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66916b223fd8ee17b3cbde4c327ecdc6",
     "grade": true,
     "grade_id": "grad-94621f1a3de541fc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Check that the answer is in the valid range\n",
    "assert answer in [1, 2, 3], 'Possible answers are 1, 2 or 3.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dc219ec87f338a3c89e7a946e629f4ab",
     "grade": false,
     "grade_id": "cell-d963c49ec94a8613",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "##  <a class=\"anchor\"></a> 1.B. Image normalization (6 Points)\n",
    "[Back to index](#-Index)\n",
    "\n",
    "In this section you will learn different ways to normalize an image.\n",
    "\n",
    "**For a total of 3 points**, your assignment is to complete the three functions below (**1 point each**), which output images normalized with respect to different statistics. In particular, you have to complete:\n",
    "* `makeZeroMean(img)`: Normalizes the image so that the sample mean of the pixel values is zero.\n",
    "* `stretchContrast(img)`: Normalizes the image so that the minimum value is $0$ and the maximum value is $1$. \n",
    "* `normalize2ndOrderStatistics(img)`: Normalizes the image so that the sample mean of the pixel values is zero and the sample standard deviation is $1$. \n",
    "\n",
    "JS, unlike Python, **does not** have a function to calculate the mean or the standard deviation. Thus, you will need to code them yourself explicitly.\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<b>Hint: </b> You can use `img.getMin()` and `img.getMax()` to get the min an max value of a JavaScript image `img`. Remeber also that you can access a wide range of mathematical functions through the Math library in JS (e.g., `Math.sqrt()`). You can read more about it [here](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math).\n",
    "</div>\n",
    "\n",
    "First, implement the method `makeZeroMean` in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "deletable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "438bae08f1a39178c8b12fc70eb8edf5",
     "grade": false,
     "grade_id": "ans-900a75999b25ebb5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "// function that normalizes the image so that the sample mean of the pixel values is zero.\n",
    "function makeZeroMean(img){\n",
    "    // declare the output image\n",
    "    var output = new Image(img.shape());\n",
    "    \n",
    "    // YOUR CODE HERE\n",
    "    var mean = 0;\n",
    "    for(var i = 0; i < img.nx; ++i) {\n",
    "        for(var j = 0; j < img.ny; ++j) {\n",
    "            mean += img.getPixel(i, j);\n",
    "        }\n",
    "    }\n",
    "    mean /= img.nx*img.ny;\n",
    "    for(var i = 0; i < img.nx; ++i) {\n",
    "        for(var j = 0; j < img.ny; ++j) {\n",
    "            output.setPixel(i, j, img.getPixel(i, j) - mean);\n",
    "        }\n",
    "    }    \n",
    "    // return the output image\n",
    "    return output;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3d3236fb55ff82b07f59768c642abca1",
     "grade": false,
     "grade_id": "cell-bd10a14dc73fc1fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Great! Now it's time to test your implementation. A partial test is to run the next cell, which will test your method on a simple $3\\times 3$ array. If an error is thrown, you implementation is not yet correct.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "411f8776761f45a890994e6c978f17f8",
     "grade": true,
     "grade_id": "grad-35f8575ea043e141",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice, the function seems to be correct!\n"
     ]
    }
   ],
   "source": [
    "%use javascript\n",
    "\n",
    "// declare the test image\n",
    "test_img = new Image([[0, 1, 2], [3, 4, 5], [6, 7, 8]]);\n",
    "\n",
    "// run the zero mean function\n",
    "var test_zero_mean = makeZeroMean(test_img);\n",
    "\n",
    "// check if the output is as expected \n",
    "if(!(test_zero_mean.imageCompare(new Image([[-4, -3, -2], [-1, 0, 1], [2, 3, 4]])))){\n",
    "        throw new Error(\"makeZeroMean() is not yet correct\");\n",
    "}\n",
    "// print victory message\n",
    "console.log('Nice, the function seems to be correct!');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "263133d1604e855128598897f5ece957",
     "grade": false,
     "grade_id": "cell-d6b3560707f58a30",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, implement `stretchContrast`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "deletable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02dabdb934c3ce07ef39f49103d4369a",
     "grade": false,
     "grade_id": "ans-00581def5a41cfb0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "\n",
    "// function that normalizes the image so that all pixels have values between 0 and 1.\n",
    "function stretchContrast(img){\n",
    "    // declare the output image\n",
    "    var output = new Image(img.shape());\n",
    "    \n",
    "    // YOUR CODE HERE\n",
    "    for(var i = 0; i < img.nx; ++i) {\n",
    "        for(var j = 0; j < img.ny; ++j) {\n",
    "            output.setPixel(i, j, (img.getPixel(i, j) - img.getMin())/(img.getMax() - img.getMin()));\n",
    "        }\n",
    "    }\n",
    "    // return the output image\n",
    "    return output;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0d0fcfc6302478954c9a1d86e904261",
     "grade": false,
     "grade_id": "cell-97589d90a96488fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the next cell to test the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "542a80ed82baf8d1b4ec1b1fb3416699",
     "grade": true,
     "grade_id": "grad-190f791354a73164",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice, the function seems to be correct!\n"
     ]
    }
   ],
   "source": [
    "%use javascript\n",
    "\n",
    "// run the stretch contrast function on the test image\n",
    "var test_stretch = stretchContrast(test_img);\n",
    "\n",
    "// compare the result to the correct result\n",
    "if(!(test_stretch.imageCompare(new Image([[0, 0.125, 0.25], [0.375, 0.5, 0.625], [0.75, 0.875, 1]])))){\n",
    "    throw new Error(\"Stretch Contrast not yet correct\");\n",
    "}\n",
    "// print victory message\n",
    "console.log('Nice, the function seems to be correct!');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e06102e83e485dbb88e3dfbb48fbba09",
     "grade": false,
     "grade_id": "cell-94ba3952742124b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Finally, implement the function `normalize2ndOrderStatistics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "deletable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01042d588dc42bcb30f45a447c04cb2e",
     "grade": false,
     "grade_id": "ans-47afab53a15e1b2b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "\n",
    "// function that normalizes the image so that the sample mean of the pixel values is 0 and the sample standard deviation is 1.\n",
    "function normalize2ndOrderStatistics(img){\n",
    "    // declare the output image\n",
    "    var output = new Image(img.shape());\n",
    "    \n",
    "    // YOUR CODE HERE\n",
    "    output = makeZeroMean(img);\n",
    "    //console.log(output);\n",
    "    var mean = 0;\n",
    "    for(var i = 0; i < img.nx; ++i) {\n",
    "        for(var j = 0; j < img.ny; ++j) {\n",
    "            mean += img.getPixel(i, j);\n",
    "        }\n",
    "    }\n",
    "    mean /= img.nx*img.ny;\n",
    "    var std = 0;\n",
    "    for(var i = 0; i < img.nx; ++i) {\n",
    "        for(var j = 0; j < img.ny; ++j) {\n",
    "            std += Math.pow(img.getPixel(i, j) - mean, 2);\n",
    "        }\n",
    "    }\n",
    "    std = Math.sqrt(std/(img.nx*img.ny));\n",
    "    for(var i = 0; i < img.nx; ++i) {\n",
    "        for(var j = 0; j < img.ny; ++j) {\n",
    "            output.setPixel(i, j, output.getPixel(i, j)/std);\n",
    "        }\n",
    "    }    \n",
    "    // return the output image\n",
    "    return output;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b5b433eafb00ba24606b54ae1b52fa5",
     "grade": false,
     "grade_id": "cell-008e6cfad20a7e48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "And run the next cell for a quick test again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b0ecc9a51aeff6b0a1b54f0b77d2453",
     "grade": true,
     "grade_id": "grad-6e5e2b291291267a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice, the function seems to be correct! You're using the biased estimator of the variance.\n"
     ]
    }
   ],
   "source": [
    "%use javascript\n",
    "\n",
    "// run the function on test_img\n",
    "var test_normalize = normalize2ndOrderStatistics(test_img).toArray();\n",
    "\n",
    "// compare the result to the correct result\n",
    "// test for unbiased estimator of variance\n",
    "if(!(Image.arrayCompare(test_normalize, [[ -1.4605934866804429, -1.0954451150103321, -0.7302967433402214 ],\n",
    "                                         [ -0.3651483716701107, 0, 0.3651483716701107 ],\n",
    "                                         [ 0.7302967433402214, 1.0954451150103321, 1.4605934866804429 ]]))){\n",
    "    // test for biased estimator of variance\n",
    "    if(!(Image.arrayCompare(test_normalize, [[ -1.5491933384829668, -1.161895003862225, -0.7745966692414834 ],\n",
    "                                             [ -0.3872983346207417, 0, 0.3872983346207417 ],\n",
    "                                             [ 0.7745966692414834, 1.161895003862225, 1.5491933384829668 ]]))){\n",
    "        throw new Error(\"Normalize 2nd Order Statistics not yet correct\");\n",
    "    }else{\n",
    "        // print victory message\n",
    "        console.log('Nice, the function seems to be correct! You\\'re using the biased estimator of the variance.');\n",
    "    }\n",
    "}else{\n",
    "    // print victory message\n",
    "    console.log('Nice, the function seems to be correct! You\\'re using the unbiased estimator of the variance.');\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c237c3c1ee12f1238455145196693395",
     "grade": false,
     "grade_id": "cell-a5b6fa8961824ffa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### In order for you to see the relevance of image normalization, we provide a sequence of fluorescence microscopy images (see more [here](https://en.wikipedia.org/wiki/Fluorescence_microscope)), named `c_elegans`. These are consecutive slices of the same 3D volume, but appear darker every time due to photobleaching (the loss of flourescence, read more [here](https://en.wikipedia.org/wiki/Photobleaching)). Of course, this is a huge problem for the application, and to solve it we absolutely need to normalize these images.\n",
    "\n",
    "Here, we will use the module [io](https://scikit-image.org/docs/0.8.0/api/skimage.io.html) of SciKit-Image, which allows us to read all the slices of a `.tif` file at once. Run the next cell to load the `c_elegans` images, display them, see a graph of the effect of photobleaching on their mean value, and pass them to JS so that we can use the functions you defined above. Make sure you explore the images and their histogram by clicking on the `Prev` and `Next` buttons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b236a53fd04358e7512a94a97166729b",
     "grade": false,
     "grade_id": "cell-cc6d8187de5feefb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f103ee86284affb02a2fb749c24e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499778e93fbf4822a78a898d17a2eb6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Pan', 'Pan axes with left…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%use sos\n",
    "%put c_elegans --to javascript\n",
    "\n",
    "# We import module io to import tif images as slices\n",
    "from skimage import io\n",
    "# The following cell loads the image c-elegans\n",
    "c_elegans = io.imread( \"images/c-elegans.tif\" ) \n",
    "# Show c_elegans images\\\n",
    "plt.close(\"all\")\n",
    "viewer([c_elegans[ind,:,:] for ind in range(12)], normalize = False, title=[f\"c_elegans {ind+1}\" for ind in range(12)], hist=True)\n",
    "# Show decay of the mean value through time due to photobleaching\n",
    "fig = plt.figure(num=f\"SCIPER: {uid}\",figsize = (6, 4))\n",
    "plt.plot([ind+1 for ind in range(12)], [np.mean(c_elegans[ind,:,:]) for ind in range(12)])\n",
    "plt.xticks([ind+1 for ind in range(12)]); plt.xlabel(\"Image number\"); plt.ylabel(\"Mean value\"); \n",
    "plt.grid('both'); plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b7b141213c83cee767cc97f339288c8",
     "grade": false,
     "grade_id": "cell-a9c5d66d7c677fe2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we are going to visualize the effect of each of your normalizing functions on the `c_elegans` images. For this purpose, we provide you the function `make_montage(img_arr, mode, cols)`, which takes as parameters:\n",
    "* `img_arr` (array): an array of `Image` objects, \n",
    "* `mode` (1, 2 or 3): the function to apply (1: zero mean, 2: stretch contrast, 3: normalize statistics), and\n",
    "* `cols` (int):, the number of columns to use in the montage. \n",
    "\n",
    "The function first creates an empy montage `out`. `out` has the dimensions to fit all the images given in `img_arr`. The method then performs the operation specified by `mode` on each image, placing the result in the right place inside the montage `out`. \n",
    "\n",
    "Now run the next cell to declare the function `makeMontage()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7bd8bdf4948267d29c6d30e50770f5f",
     "grade": false,
     "grade_id": "cell-bfcf756e6846fb2a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use javascript\n",
    "\n",
    "// function that creates a single image from multiple images (slices) and performs the specified function on the images\n",
    "function makeMontage(img_arr, mode, cols) {\n",
    "    // get dimensions of each image\n",
    "    var w = img_arr[0].nx;\n",
    "    var h = img_arr[0].ny;\n",
    "    // determine the number of rows \n",
    "    var rows = img_arr.length/cols;\n",
    "    // initialize output image \n",
    "    var out = new Image(h*rows, w*cols);    \n",
    "    // iterate through each image in img_arr\n",
    "    for(t=0; t<rows*cols; t++){\n",
    "        // extract the corresponding image \n",
    "        var img = img_arr[t].copy();\n",
    "        // check requested operation \n",
    "        //(note that any mode other than 1, 2 or 3 simply copies the original images in the montage)\n",
    "        if(mode == 1){ \n",
    "            img = makeZeroMean(img);\n",
    "        }             \n",
    "        if(mode == 2){\n",
    "            img = stretchContrast(img);\n",
    "        }\n",
    "        if(mode == 3){\n",
    "            img = normalize2ndOrderStatistics(img);\n",
    "        }            \n",
    "        // put result in the corresponding place\n",
    "        out.putSubImage(Math.floor(t%cols)*w, Math.floor(t/cols)*h, img);\n",
    "    }\n",
    "    // return output image\n",
    "    return out;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ad67f8210342294ffbc0d57664799d00",
     "grade": false,
     "grade_id": "cell-6cb32370ab6a4ede",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, we are going apply your methods to the image slices we just loaded. First, we convert each element in the array `c_elegans`  to an `Image` object. Then, we call the function on the array with each of the three modes to visualize the result of the functions that you implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "020693a4a4f4e3b9753481fa7dcdfd94",
     "grade": false,
     "grade_id": "cell-09e95f64e85124ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%use javascript\n",
    "%put montage_original montage_zero_mean_js montage_normalize_statistics_js montage_stretch_contrast_js \n",
    "\n",
    "// convert each element in the c_elegans array to an Image object\n",
    "var c_elegans_imgs = new Array();\n",
    "for(x = 0; x < c_elegans.length; x++){\n",
    "    c_elegans_imgs.push(new Image(c_elegans[x]));\n",
    "}\n",
    "\n",
    "// run makeMontage with all four functions (modes)\n",
    "var montage_original = makeMontage(c_elegans_imgs, 0, 3).toArray();\n",
    "var montage_zero_mean_js = makeMontage(c_elegans_imgs, 1, 3).toArray();\n",
    "var montage_stretch_contrast_js = makeMontage(c_elegans_imgs, 2, 3).toArray();\n",
    "var montage_normalize_statistics_js = makeMontage(c_elegans_imgs, 3, 3).toArray();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "JavaScript",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "68709e3e66c45251368f108a792c40c2",
     "grade": false,
     "grade_id": "cell-431ae3ac67dd5645",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that we have applied your functions and that we have the variables in Python, let's visualize them. Run the following cell to do so. Use the buttons `Next` and `Prev` to browse through the tree images. If your implementations passed the previous tests, you should see the correct result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29259b69ac5c5342188e7a74d1da45fb",
     "grade": false,
     "grade_id": "cell-884909364cd99acf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ea4257ac834fc090fb81b2cc49ad2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%use sos\n",
    "# Define the lists of images and titles\n",
    "image_list = [np.array(montage_original), np.array(montage_zero_mean_js), np.array(montage_stretch_contrast_js), np.array(montage_normalize_statistics_js)]\n",
    "title_list = ['Original c_elegans', 'Zero Mean c_elegans', 'Stretch Contrast c_elegans', 'Normalize Statistics c_elegans']\n",
    "\n",
    "# Display the montages\n",
    "plt.close('all')\n",
    "normalization_viewer = viewer(image_list, title = title_list, widgets=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0eefe7711b2d60ed48273353cc95b46d",
     "grade": false,
     "grade_id": "cell-d06bb9e45c40c9d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Multiple choice questions\n",
    "\n",
    "Why does the bottom-right corner of the **Zero Mean Montage** have lower contrast than the top-left corner? (**0.5 points**)\n",
    "\n",
    "1. Because the different subimages in the montage have different spreads of values around their mean.\n",
    "2. It is an illumination effect.\n",
    "3. The bottom-right subimages of the montage are defective.\n",
    "\n",
    "Modify the variable `answer` in the next cell to reflect your choices. As usual, there is another cell that will remind you to select a valid choice if you haven't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b263a995e31530f65c2889752a8f0009",
     "grade": false,
     "grade_id": "ans-376291a90e1ea6c5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "# Assign your answer to this variable\n",
    "answer = 1\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b47a67d87956e28607283a6c316d03b",
     "grade": true,
     "grade_id": "grad-6695b3233dbda1e7",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "assert answer in [1, 2, 3], 'Possible answers are 1, 2 or 3' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "443955debfb23ac3b03a11f9ae6e9ac5",
     "grade": false,
     "grade_id": "cell-7fc1d797c0aac343",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Why is this not the case for the other two montages? (**0.5 points**)\n",
    "\n",
    "1. Becuase the images already had zero mean.\n",
    "2. Because the other two functions modify the contrast by adjusting the range of intensities.\n",
    "\n",
    "Modify the variable `answer` in the next cell to reflect your choices. As usual, there is another cell that will remind you to select a valid choice if you haven't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da3c2b966babd86ffcca00992c02f9fc",
     "grade": false,
     "grade_id": "ans-213796640f2a5768",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "# assign your answer to this variable\n",
    "answer = 2\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b47d2be814174a38d0f22d525fa3ae4e",
     "grade": true,
     "grade_id": "grad-4cab3b4c7570a201",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "assert answer in [1, 2], 'Possible answers are 1 and 2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4554d844311f0913e66e12845789bc04",
     "grade": false,
     "grade_id": "cell-f96b682d6cdf0ff5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As you have probably realized by now, low level languages can get tedious. You can do the same thing you did in JavaScript in less lines in Python, by using NumPy arrays, so let's do it! \n",
    "\n",
    "We give you the method `make_zero_mean`. **For a total of 2 points**, implement the other two methods (`stretch_contrast` and `normalize_2nd_order_statistics`) in Python in the following cell (**1 point each**). When appropriate, use the following functions:\n",
    "- `np.mean(img)` returns the estimated mean value of `img`,\n",
    "- `np.min(img)` and `np.max(img)` return the min and max of `img` respectively,\n",
    "- `np.std(img)` returns the estimated standard deviation of `img`, based on the biased estimator of the variance (see more about the `ddof` parameter running `help(np.std)`).\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Hint:** \n",
    "- If you're unsure how to handle numpy arrays, look at Section 2.A.a of the [Introductory lab](./Introductory.ipynb),\n",
    "- Only one line of code needs to be filled in for every function, but do not worry if you prefer to use more lines.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d9ae30189d5d8f6ded51d1f36d396a8",
     "grade": false,
     "grade_id": "ans-83302634006f5760",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Function that normalizes the image so that the sample mean of the pixel values is zero.\n",
    "def make_zero_mean(img):\n",
    "    # Declare the output image\n",
    "    output = np.copy(img)\n",
    "    # Subtract the mean from the input image\n",
    "    output = img-np.mean(img)\n",
    "    # Return the output image\n",
    "    return output \n",
    "\n",
    "# Function that normalizes the image so that all pixels have values between 0 and 1.\n",
    "def stretch_contrast(img):\n",
    "    # Declare the output image\n",
    "    output = np.copy(img)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    output = (output - np.min(output)) / (np.max(output) - np.min(output))\n",
    "    # Return the output image\n",
    "    return output\n",
    "\n",
    "# Function that normalizes the image so that the sample mean of the pixel values is 0 and the sample standard deviation is 1.\n",
    "def normalize_2nd_order_statistics(img):\n",
    "    # Declare the output image\n",
    "    output = np.copy(img)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    output = (output - np.mean(output)) / np.std(output)\n",
    "    # Return the output image\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "76b81b3e253d9d497977e68244778f9e",
     "grade": false,
     "grade_id": "cell-5a6cb7268418986b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use the next two cells for a quick test on your functions. This cell tests the two characteristics requested for each function:\n",
    "* that the result of `stretch_contrast` is in the range $[0, 1]$, and\n",
    "* that the result of `normalize_2nd_order_statistics` has zero mean and unit variance. \n",
    "\n",
    "Run them, and if your implementations are correct, they shouldn't raise any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4bdd9a4bbb3d850baf4052df2cce8342",
     "grade": true,
     "grade_id": "grad-925b5b8cd5ffa921",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well done! Your stretch_contrast function seems to be correct.\n"
     ]
    }
   ],
   "source": [
    "%use sos\n",
    "\n",
    "# This cell tests your method stretch contrast\n",
    "# Here we run your function on the first slice of c_elegans\n",
    "test_stretch_contrast = stretch_contrast(c_elegans[0])\n",
    "\n",
    "# And we check that stretch_contrast effectively maps the pixels to the range [0,1]\n",
    "assert np.min(test_stretch_contrast) == 0, 'The minimum value in the result of stretch_contrast is not 0'\n",
    "assert np.max(test_stretch_contrast) == 1, 'The maximum value in the result of stretch_contrast is not 1'\n",
    "print(\"Well done! Your stretch_contrast function seems to be correct.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06efdf0dbe449b7047653725b5a35890",
     "grade": true,
     "grade_id": "grad-2e62d034adec415e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well done! Your normalization of 2nd order statistics seems to be correct.\n"
     ]
    }
   ],
   "source": [
    "%use sos\n",
    "\n",
    "# This cell tests your method normalize statistics\n",
    "# Here we run the method on the first slice of c_elegans\n",
    "test_normalize_statistics = normalize_2nd_order_statistics(c_elegans[0])\n",
    "\n",
    "# Now we check that normalize_statistics returns an image with mean = 0, \n",
    "assert np.abs(np.mean(test_normalize_statistics)) < 1e-10, 'Your mean in normalize_2nd_order_statistics is not 0'\n",
    "# And with std = 1 \n",
    "assert np.abs(np.std(test_normalize_statistics) - 1) < 1e-4 or np.abs(np.std(test_normalize_statistics, ddof=1) - 1) < 1e-5, 'Your standard deviation in normalize_2nd_order_statistics is not 1'\n",
    "print('Well done! Your normalization of 2nd order statistics seems to be correct.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fbab956ff47c72919a9d9a5f89de52ad",
     "grade": false,
     "grade_id": "cell-33317d06858fc7b5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# <a class=\"anchor\"></a> 2. Understanding the Fourier transform (5 Points)\n",
    "[Back to index](#-Index)\n",
    "\n",
    "This section is dedicated to 1) understanding the effects of the elements in an image on its Fourier transform (FT), and 2) understanding how an image is reconstructed from its FT using the inverse Fourier transform (IFT). From here on we will only use Python, since implementing a FT in a low level language is beyond the scope of this course. To compute the FT in Python, we will use the [`fft` module](https://numpy.org/doc/stable/reference/routines.fft.html) in NumPy, which implements the FT using a [fast Fourier transform (FFT)](https://en.wikipedia.org/wiki/Fast_Fourier_transform) algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a8683207ed96dc6fd278c33f0fd9f323",
     "grade": false,
     "grade_id": "cell-be46dd7a6139a1e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## <a class=\"anchor\"></a> 2.A. The FT and its inverse (3 Points)\n",
    "[Back to index](#-Index)\n",
    "\n",
    "First, we will provide the functions `fourier(img)` and `inverse_fourier(ft)`, which calculate the FT and the IFT respectively.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note:** \n",
    "- `np.fft.fft2(img)` calculates the two-dimensional FT of `img`,\n",
    "- `np.fft.fftshift(ft)` shifts the frequency range of the FT `ft` from $[0, \\pi]$ to $[-\\frac{\\pi}{2}, \\frac{\\pi}{2}]$,\n",
    "- `np.fft.ifft2(ft)` calculates the inverse FT of the two-dimensional FT `ft`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6811716fd1204dd8198ed43858012a5",
     "grade": false,
     "grade_id": "cell-3e4d343d619b0837",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "# Function that returns the FT\n",
    "def fourier(img):\n",
    "    # Generate the FT\n",
    "    ft = np.fft.fft2(img)\n",
    "    # Shift the frequency range to [-pi/2, pi/2] \n",
    "    shift_ft = np.fft.fftshift(ft)\n",
    "    return shift_ft\n",
    "\n",
    "# Function that return the inverse FT\n",
    "def inverse_fourier(ft):\n",
    "    # Shift the FT back to [0, pi]\n",
    "    ft = np.fft.ifftshift(ft)\n",
    "    # Get the inverse FT\n",
    "    ift = np.fft.ifft2(ft)\n",
    "    # Clip the imaginary part of the reconstruction\n",
    "    # (should be approximately zero anyway)\n",
    "    ift = np.real(ift)\n",
    "    return ift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5a8014b1e2a234e37854be62dc616580",
     "grade": false,
     "grade_id": "cell-9f1d3140cb97f16b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As you know, calculating the FT of an image generates a two-dimensional array (image) of complex values, which makes it challenging to find a good visualization. Therefore, we usually extract the **magnitude** and **phase** of the complex numbers, which are much easier to deal with and present useful information. Remember that the magnitude of a complex number $z\\in\\mathbb{C}$ is given by\n",
    "$$|z| = \\sqrt{\\operatorname{Re}(z)^2+\\operatorname{Im}(z)^2}.$$\n",
    "\n",
    "Further, we usually want to visualize this magnitude in dB, i.e., \n",
    "\n",
    "$$|z|~[\\mathrm{dB}] = 10\\log_{10}\\left(|z|^2\\right).$$\n",
    "\n",
    "One of the reasons for this is that the variations in the magnitude of the Fourier transform generally span very different ranges, from the very small to the very large, and the $\\log(\\cdot)$ transformation allows us to visualize both in the same image.\n",
    "\n",
    "To do this, we will first define the function `magnitude(ft)`, which should return the magnitude in decibels (dB) of a FT given as an input parameter. For **0.5 points**, complete the function `magnitude(ft)` in the cell below according to the equation given above.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Hints:**\n",
    "- With NumPy, you can extract the **real** part of a complex variable `z` using [`np.real(z)`](https://numpy.org/doc/stable/reference/generated/numpy.real.html) and the **imaginary** part using [`np.imag(z)`](https://numpy.org/doc/stable/reference/generated/numpy.imag.html),\n",
    "- if you need it, use [`np.sqrt(x)`](https://numpy.org/doc/stable/reference/generated/numpy.sqrt.html) to get the square root of `x`,\n",
    "- use [`np.log10(x)`](https://numpy.org/doc/stable/reference/generated/numpy.log10.html) to get the base-10 logarithm of `x`.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Beware:** Using `np.absolute` in this exercise will give you **0 points**! Implement the function yourself.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f9097e27ef0c807e5b544dfcac30211",
     "grade": false,
     "grade_id": "ans-7078161896540164",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "# Function that returns the magnitude of the FT in dB\n",
    "def magnitude(ft):\n",
    "    # Initialize the output to 0\n",
    "    output = 0\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    output = 10*np.log10(np.real(ft)**2 + np.imag(ft)**2)\n",
    "    # Return the output\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f44fd47e294e4022e09dbea234f5688",
     "grade": true,
     "grade_id": "grad-aab6c96c21ed9da9",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice, your magnitude function passed the basic sanity check!\n"
     ]
    }
   ],
   "source": [
    "# Let's do a sanity check\n",
    "# The complex number used for the test which has a magnitude of ~3 dB\n",
    "z = 1 + 1j\n",
    "# Check that the magnitude function is correct\n",
    "assert np.round(magnitude(z), decimals=1) == 3.0, \"Something isn't quite right yet.\"\n",
    "print(\"Nice, your magnitude function passed the basic sanity check!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d6965d7e4d172d9dd83155d81babbef",
     "grade": false,
     "grade_id": "cell-e83793b000b52116",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, we will define a function to calculate the phase of the FT. For this we define the function `phase(ft)`, which should return the phase of the FT given as input.\n",
    "\n",
    "Remember that the phase of a complex number $z$ is given by\n",
    "$$\\angle(z)=\\arctan\\left(\\frac{\\operatorname{Im}(z)}{\\operatorname{Re}(z)}\\right)\\,.$$\n",
    "\n",
    "For **0.5 points**, complete the function `phase(ft)` in the cell below according to the equation given above.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Hint:** Use [`np.arctan2(x1, x2)`](https://numpy.org/doc/stable/reference/generated/numpy.arctan2.html) to calculate the $\\arctan\\left(\\frac{x_1}{x_2}\\right)$. This function even chooses the corresponding quadrant for you, so you do not need to check for negative angles.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Beware:** Using `np.angle` in this exercise will give you **0 points**! Implement the function yourself.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "422cd3280b3b62fa511ae3cb8dbb53fa",
     "grade": false,
     "grade_id": "ans-63a15ac76c7b5d69",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Function that calculates the phase of complex numbers\n",
    "def phase(ft):\n",
    "    # Initialize output variable\n",
    "    output = 0\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    output = np.arctan2(np.imag(ft), np.real(ft))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1df7e2ab9d25bfc2b27aae16c6bc34b8",
     "grade": true,
     "grade_id": "grad-9ae7daa14c45d818",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great, your phase function passed the sanity check!\n"
     ]
    }
   ],
   "source": [
    "%use sos\n",
    "# Let's do a sanity check\n",
    "# The complex number used for the test which has a phase of pi/4\n",
    "z = 1 + 1j\n",
    "# Check that the magnitude function is correct\n",
    "assert phase(z) == np.pi/4, \"Something isn't quite right yet.\"\n",
    "print(\"Great, your phase function passed the sanity check!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9f60112d36c37e1a5ad404ba282278ae",
     "grade": false,
     "grade_id": "cell-133e10af0d745e6b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's look at the resluts of the functions we just coded. For this we will apply the FT to the `car` image, calculate its magnitude and phase with the function you coded above and visualize the result as an image. Run the next cell to see the magnitude and phase of the `car` image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a4947519d707d7e954be64231df2391",
     "grade": false,
     "grade_id": "cell-eaa553653ffc69a1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937f80f89714484189ac7a287e0b0129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86bc3c475a194f00a1a99dd901c16851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%use sos\n",
    "# Generate the FT of car\n",
    "car_ft = fourier(car)\n",
    "# Calculate the magnitude\n",
    "car_ft_mag = magnitude(car_ft)\n",
    "# Calculate the phase\n",
    "car_ft_ph = phase(car_ft)\n",
    "# Visualize the two together with the original image\n",
    "plt.close('all')\n",
    "ft_vis = viewer([car, car_ft_mag, car_ft_ph], title=['Car', 'Car FT magnitude', 'Car FT phase'], subplots=(1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bba54a7c89436f4d8b43a2c510a7b19c",
     "grade": false,
     "grade_id": "cell-82c4152b3417a148",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Multiple Choice Questions \n",
    "The following questions will test your understanding of the relationship of an image with its FT **magnitude**. The first two will ask about the image `car`, and the second two will ask about the image `pens`. Each MC question is worth **0.5 points**. As usual, we will include a cell for you to change your answer (in the variable `answer`) and a cell to check that you chose one of the possible answers. \n",
    "\n",
    "Run the next cell to visualize the images `pens` and `car` together with their FT magnitudes and answer the upcoming questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0f3cace07fc0cdadc954eb6614bfe8c",
     "grade": false,
     "grade_id": "cell-b5b291649ebc0eb0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3d83ba36ca4368b227b9d9dbc7d787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae59c3d3b7c44a9c9cc1bc40c9c1c456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%use sos\n",
    "# get the FT magnitudes of the images using the fourier and magnitude functions\n",
    "car_ft  = magnitude(fourier(car))\n",
    "pens_ft = magnitude(fourier(pens))\n",
    "\n",
    "# define the lits of images and names\n",
    "image_list = [car, car_ft, pens, pens_ft]\n",
    "title_list = ['Car', 'FT of Car', 'Pens', 'FT of Pens']\n",
    "\n",
    "# display results\n",
    "plt.close('all')\n",
    "ft_viewer = viewer(image_list, title=title_list, subplots = [2, 2], colorbar = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e79ddb90cd9f0ed5c1af844136f3fb7d",
     "grade": false,
     "grade_id": "cell-5a9789ef912c906f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "* Q1: Where do the little stars at different distances from the center in the FT of `car` come from?\n",
    "    1. From the contour of the car.\n",
    "    2. From the driver.\n",
    "    3. From the carpet under the car.\n",
    "    4. From the details of the car (JAGUAR text, doors, steering wheel, etc).\n",
    "    5. From the size of the image.\n",
    "\n",
    "In the next cell, modify the variable `answer` to reflect your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f863ff4ab1299708d4e0f953a46439b0",
     "grade": false,
     "grade_id": "ans-66af2208d33072da",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "# Assign your answer to this variable\n",
    "answer = 3\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87fdad71741484562adca2d01fc4b1ec",
     "grade": true,
     "grade_id": "grad-bda900129c0a32df",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "assert answer in [1, 2, 3, 4, 5], 'Possible answers are 1, 2, 3, 4 and 5'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bac3abb3e91f11cb43c5a9b4c67e549a",
     "grade": false,
     "grade_id": "cell-89a8354d6352e067",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "* Q2: Where do the two big intersecting lines in `car` come from? \n",
    "    1. From the contour of the car.\n",
    "    2. From the driver.\n",
    "    3. From the carpet under the car.\n",
    "    4. From the details of the car (JAGUAR text, doors, steering wheel, etc).\n",
    "    5. From the size of the image.\n",
    "\n",
    "In the next cell, modify the variable `answer` to reflect your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca07736ebfb00094ee9f6e8881ed2aa7",
     "grade": false,
     "grade_id": "ans-4a92583fb39143e6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "# Assign your answer to this variable\n",
    "answer = 1\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "427d2f95ab4bda4f0eb06ed8006c11cd",
     "grade": true,
     "grade_id": "grad-ad16b9572b4fa684",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "assert answer in [1, 2, 3, 4, 5], 'Valid answers are 1, 2, 3, 4, and 5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16f861db9ab50d0a0d7f8b4108280a0c",
     "grade": false,
     "grade_id": "cell-7ef1a6f54162f8ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "* Q3: Why is there only one main line in the FT of `pens`, if there are two pens?\n",
    "    1. Because the background is constant.\n",
    "    2. Because the two pens are aligned.\n",
    "    3. Because the two pens are close to each other.\n",
    "    4. Because they are ballpoint pens and not fountain pens.\n",
    "\n",
    "In the next cell, modify the variable `answer` to reflect your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c30d052c46ec7b28cefcb357bf620b77",
     "grade": false,
     "grade_id": "ans-b97ff3156f3b6688",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "# Assign your answer to this variable\n",
    "answer = 2\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ffe5672208c4512e06cc8b725cb6fc42",
     "grade": true,
     "grade_id": "grad-b5234dc1b8b8bafa",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "assert answer in [1, 2, 3, 4], 'Valid answers are 1, 2, 3 or 4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "00970199fb04d1cf58dab8c035edb37d",
     "grade": false,
     "grade_id": "cell-0943d62710d73c80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "* Q4: Why is the main line not aligned with the pens? \n",
    "\n",
    "    1. The main periodicity in the image is *perpendicular* to the pens because they are very similar.\n",
    "    2. The main periodicity in the image is *parallel* to the pens because they have rough surfaces.\n",
    "    3. The `viewer` rotates the FT.\n",
    "    4. Numpy rotates the FT.\n",
    "\n",
    "In the next cell, modify the variable `answer` to reflect your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3f2522a85fb5c8205f358282868d2e0",
     "grade": false,
     "grade_id": "ans-8414e8b6a1607a1e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "# Assign your answer to this variable\n",
    "answer = 1\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "990c2c02e0fa40ed67d169d153d0553b",
     "grade": true,
     "grade_id": "grad-a59ca821abb77062",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "assert answer in [1, 2, 3, 4, 5], 'Valid answers are 1, 2, 3, 4 and 5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce62e6fa2b206548b9bf120885f805ca",
     "grade": false,
     "grade_id": "cell-fa915af9bcffb903",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## <a class=\"anchor\"></a> 2.B. Reconstruction (2 Points)\n",
    "[Back to index](#-Index)\n",
    "\n",
    "As you learned in the course, it is possible to reconstruct an image from its Fourier transform by performing the inverse Fourier transform. In this next exercise we will investigate the role that the magnitude and phase of the FT has on the reconstruction of an image. For this we first need to create a function that reconstructs an image from its FT magnitude (in dB) and phase. Run the next cell to define the function `reconstruct(ft)` and make sure that you understand every line of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36906e791ab3b48bb2516b7f4e320d62",
     "grade": false,
     "grade_id": "cell-135e619da9bddb99",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Function that reconstructs an image from its FT magnitude (in dB) and phase\n",
    "def reconstruct(mag, ph):\n",
    "    # Since the magnitude is in dB we first need to convert it back\n",
    "    mag = 10 ** (mag / 20)\n",
    "    # Now we can restore the complex FT from the magnitude and phase using the polar representation\n",
    "    ft = mag * np.exp(1j * ph)\n",
    "    # Having the complex FT we can simply use the inverse_fourier function that we defined above to reconstruct the image\n",
    "    return inverse_fourier(ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d83eada5ba0c924e1f12b4b01fda7fc4",
     "grade": false,
     "grade_id": "cell-760695d66a5c92a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's see if the function works. Run the cell below to reconstruct the car image from its magnitude and phase, and visualize the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ddcd1c2b0b1cc7b25359cc1fc4ba418",
     "grade": false,
     "grade_id": "cell-d3de1befc78e32cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a598ccda3b60411c95767a0caa063944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc37b7cd623436f8d608a290bf5af2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%use sos\n",
    "# Reconstruct the car image\n",
    "car_reconstructed = reconstruct(car_ft_mag, car_ft_ph)\n",
    "# Display the result\n",
    "plt.close('all')\n",
    "ft_rec_vis = viewer([car, car_reconstructed], title=['Original car', 'Reconstructed car'], subplots=(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b8d73fb3b9fab8170f791627cf7ecdd",
     "grade": false,
     "grade_id": "cell-725bb93760893450",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Since we didn't make any changes to the FT before the reconstruction, the reconstructed image should be (almost) identical to the original image. \n",
    "\n",
    "For the next excercise we will use the `mandrill` image in addition to the car image. Run the next cell to visualize the `mandrill` image. This will help you to answer the upcoming questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa948071eafdcaf9cb4f030a64e4ec32",
     "grade": false,
     "grade_id": "cell-f2671c4dcbeb39a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4824c260df44498cbf9fdb23c887ca36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a999ea6eb94dabb9f6cf485d26deac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%use sos\n",
    "plt.close('all')\n",
    "mandrill_vis = viewer(mandrill)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5b849bacbbe77047f3c5a8b0a6d92615",
     "grade": false,
     "grade_id": "cell-3632f02d41668d81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now lets see what happens if we use the magnitude of one image and the phase of another image to do the reconstruction. What do you think will happen? Run the cell below and observe the results. Try to make a conclusion on what type of information is stored in the phase of the FT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34e18d24bdbc6fddd2a9a91e50c71b2c",
     "grade": false,
     "grade_id": "cell-edfa23d685d4fef9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce03898ac4c412baf02576086bea0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c478fe479044a597538230df3a3127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Show Widgets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%use sos\n",
    "# Generate FT of the mandrill image\n",
    "mandrill_ft = fourier(mandrill)\n",
    "# Extract the magnitude and phase\n",
    "mandrill_ft_mag = magnitude(mandrill_ft)\n",
    "mandrill_ft_ph = phase(mandrill_ft)\n",
    "# Reconstruct an image with the magnitude of car and phase of mandrill\n",
    "car_mandrill = reconstruct(car_ft_mag, mandrill_ft_ph)\n",
    "# Reconstruct an image with the magnitude of mandrill and phase of car\n",
    "mandrill_car = reconstruct(mandrill_ft_mag, car_ft_ph)\n",
    "# Visualize the results\n",
    "plt.close('all')\n",
    "rec_comp_vis = viewer([car_mandrill, mandrill_car], title=['Magn. = car, Phase = mandrill', 'Magn. = mandrill, Phase = car'], subplots=(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "457bff3073d0b15e89164af5ba2ce681",
     "grade": false,
     "grade_id": "cell-ba7b60defd1c42b0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Multiple choice question\n",
    "\n",
    "What type of information of the image is stored in the **phase** of the FT that is **not stored** in the magnitude? (**0.5 points**)\n",
    "\n",
    "1. The spacial frequencies contained in the image.\n",
    "2. The light intensity of each pixel.\n",
    "3. The location and shape of objects in the image.\n",
    "\n",
    "Modify the variable `answer`in the next cell to reflect your choice. The second cell is for you to check that you have entered a valid answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b92efe2e11c7c5c19604b424b1519e9",
     "grade": false,
     "grade_id": "ans-7e7c03216cfd90a0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Assign your answer to this variable\n",
    "answer = 3\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0dd3b671609cab9cb2c9b341a2b96eb2",
     "grade": true,
     "grade_id": "grad-5da443479b1400ff",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Sanity check\n",
    "assert answer in [1, 2, 3], 'Valid answers are 1, 2 or 3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fcb1af07cfce8dd7ddc1648f032105d5",
     "grade": false,
     "grade_id": "cell-9a92d5cbd8420331",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Reconstruction error\n",
    "\n",
    "How many Fourier coefficients do we really need to keep to still have the basic information present in an image? Do any coefficients contribute the same? In order to answer this type of questions, it is good to define an objective metric of _how good_ a certain reconstruction is. Here, we will discuss the normalized mean square error (NMSE) to reconstruct an image $f$. This metric assesses how different an image $f$ is from its reconstruction $g$, but normalizes it by the total power of $f$. In particular, we have that if $K$ and $L$ are the number of columns and rows, respectively,\n",
    "\n",
    "$$\\operatorname{NMSE}_f(g) =  \\frac{\\sum_{k=1}^{K} \\sum_{l=1}^L (g[k,l] - f[k,l])^2}{\\sum_{m=1}^{K} \\sum_{n=1}^L f[m,n]^2}\\mbox{, and } \\operatorname{NMSE}_f(g)~[\\mathrm{dB}] = 10 \\log_{10}\\left(\\operatorname{NMSE}_f(g)\\right).$$\n",
    "\n",
    "As we can see, the NMSE is often expressed in dB. This makes it easier for one to observe, for example, when the error has doubled ($+3~\\mathrm{dB}$) or halved ($-3~\\mathrm{dB}$) in plots.\n",
    "\n",
    "For **0.5 points**, complete the function `nmse(f, g)` in the cell below according to the equation given above.\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Hint:** Use [`np.mean(x)`](https://numpy.org/doc/stable/reference/generated/numpy.mean.html) to calculate the mean value of `x`, or [`np.sum(x)`](https://numpy.org/doc/stable/reference/generated/numpy.sum.html) to calculate its sum through all axis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c33abbaa307be973a5d4cdfb4948686d",
     "grade": false,
     "grade_id": "ans-8dded687cf67f4f1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "# Function that calculates the Normalized Mean Square Error in dB\n",
    "def nmse(f, g):\n",
    "    # Declare the output variable\n",
    "    output = 0\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    output = 10*np.log10(np.sum((g-f)**2)/np.sum(f**2))\n",
    "    # Return MSE\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "836c12f486a3dca103130b0670fd3bc0",
     "grade": true,
     "grade_id": "grad-f43f5970d01e3a71",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: RuntimeWarning: divide by zero encountered in log10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice, your function seems to work! Do not worry about the divide by zero warning!\n"
     ]
    }
   ],
   "source": [
    "# Sanity check (do not worry about the divide by zero note)\n",
    "assert nmse(impulse, impulse) == -np.infty, 'The error between two equal images should be zero. In log -infinity.'\n",
    "# Check your function on the hrct image\n",
    "assert nmse(impulse, 0) == 0, 'The error of any image and a zero-image should be 1. In log, 0.'\n",
    "# Print victory message\n",
    "print('Nice, your function seems to work! Do not worry about the divide by zero warning!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3326417873db01269d79cb714660965a",
     "grade": false,
     "grade_id": "cell-0a2def51f8d1b167",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Fourier components\n",
    "\n",
    "In this section we look into the reconstruction process of an image from part of its Fourier components. This touches on a topic that will continue to appear in IP1 and IP2: how much does a given transform compress an image? \n",
    "\n",
    "For a first practical approximation to the topic, we define the method `clip_fourier(img, precent)`. This method reconstructs an image for only `percent`$\\%$ of its Fourier coefficients. If `largest=True`, only the largest are kept, while \n",
    "if `largest=False`, only all the rest are kept. This will illustrate the uneven distribution of information contained in the Fourier components.\n",
    "\n",
    "Run the next cell to define the function `clip_fourier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19de603fd9e853894b53f03b153f033e",
     "grade": false,
     "grade_id": "cell-f35ca285f774a8b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "def clip_fourier(img, percent, largest=True, perc = True):\n",
    "    # Get number of coefficients to keep\n",
    "    if perc:\n",
    "        # Extract from percentage\n",
    "        n = np.round( np.prod(img.shape) * percent / 100 ).astype(np.int)\n",
    "    else: \n",
    "        # Pass directly\n",
    "        n = percent\n",
    "    # Get ft of img\n",
    "    img_ft = np.fft.fft2(img)\n",
    "    # Get the threshold value. To do this, we order the Fourier coefficients \n",
    "    # from low to high and select the n-to-last ([-n]) coefficient\n",
    "    threshold = np.sort(np.abs(img_ft.flatten()))[-n]\n",
    "    if largest == True:\n",
    "        # Get the inverse Fourier transform of the thresholded Fourier transform\n",
    "        clipped_ift = np.real(np.fft.ifft2((np.abs(img_ft) >= threshold) * img_ft))\n",
    "    else:\n",
    "        # Get the inverse Fourier transform of the thresholded Fourier transform\n",
    "        clipped_ift = np.real(np.fft.ifft2((np.abs(img_ft) < threshold) * img_ft))\n",
    "    return clipped_ift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8b67e246a989eef3a7bc7ea7a73a2e61",
     "grade": false,
     "grade_id": "cell-9445799bbeb15ffe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's use the error metric `nmse` defined before to illustrate the difference in information contained in the few largest Fourier components compared to the information contained in the rest. In the cell below we reconstruct the image `zebra` once using only the $50\\%$ largest Fourier Components and once using the $50%$ largest components. Then we compare the reconstruction error by applying the `nmse` function defined above with both reconstructions. Run the cell below to see the different reconstruction errors. Play with the variable `percent` and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reconstruction error when using the 20% largest  components: NMSE = -2.3494\n",
      "The reconstruction error when using the 80% smallest components: NMSE = 21.3549\n"
     ]
    }
   ],
   "source": [
    "%use sos\n",
    "percent = 20\n",
    "# First, reconstruct zebra using the largest components\n",
    "zebra_largest = clip_fourier(zebra, percent)\n",
    "# Reconstruct zebra using the smallest components\n",
    "zebra_smallest = clip_fourier(zebra, percent, largest=False)\n",
    "# Calculate the errors\n",
    "error_l = nmse(zebra,zebra_largest )\n",
    "error_s = nmse(zebra,zebra_smallest)\n",
    "# Compare the error\n",
    "print(f'The reconstruction error when using the {percent}% largest  components: NMSE = {error_l:.4f}')\n",
    "print(f\"The reconstruction error when using the {100 - percent}% smallest components: NMSE = {error_s:6.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ab028d52c9cd1ba12e48e384a23b27aa",
     "grade": false,
     "grade_id": "cell-af1dad6c7d299b33",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the long run, this type of characteristics of transforms are explored using graphs like the one below, where the NMSE can be seen as a function of the percentage of the largest coefficients kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c749139ea7c2f3652aa39ba02355b20e",
     "grade": false,
     "grade_id": "cell-9ee60b5808fea24d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1942fec142cb4b63b407fb904cf3f155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Pan', 'Pan axes with left…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close(\"all\")\n",
    "# Create figure\n",
    "fig = plt.figure(num=f\"SCIPER: {uid}\",figsize = (8, 5));\n",
    "# Plot the NMSE vs kept coefficients curve\n",
    "plt.plot( np.arange(.5,100,5), [nmse(zebra, clip_fourier(zebra, perc)) for perc in np.arange(.5,100,5)], 'bo-' );\n",
    "# Labels and titles for clear plotting\n",
    "plt.xlabel(\"Percentage of coefficients kept\"); plt.ylabel(\"NMSE\"); \n",
    "plt.xticks([0,20,40,60,80,100], [f\"{perc}%\" for perc in [0,20,40,60,80,100]]);\n",
    "plt.title(\"Reconstructing zebra with the largest Fourier coefs.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10601562d18d572111bf4661bc3480b7",
     "grade": false,
     "grade_id": "cell-aca9c2e4d2518fc6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we are going to create a widget to apply the function to an image and dinamically visualize its effect. \n",
    "\n",
    "We will define a slider to choose an integer `n` such that **the number largest coefficients kept is $2^n$**. \n",
    "<div class = \"alert alert-info\">\n",
    "This is because the visual difference between the reconstructions is only apparent for percentages between $0\\%$ and $2\\%$, and very small steps would be needed. Keep in mind that you are not working with percentages anymore.\n",
    "    \n",
    "</div>We will also provide a checkbox to switch between the two modes of operation (keeping the largest, or keeping all the rest). Click the button `Apply` to apply `clip_fourier()` with the chosen parameter on the image. Run the next cell and click on `Extra Widgets` to use the widget. Explore the results carefuly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a8a7ffe4ea144a660ccc4af034541bf",
     "grade": false,
     "grade_id": "cell-c4b7a812e25017e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ef9df1f4e54ea08db7c1962ff324a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(layout=Layout(width='80%')), Output(), Output(layout=Layout(width='25%'))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%use sos\n",
    "\n",
    "# Declare slider and checkbox\n",
    "n_slider = widgets.IntSlider( value = 16, min = 0, max = 16, step = 1, description = 'n' )\n",
    "checkbox = widgets.Checkbox(value=True, description='Use largest components')\n",
    "\n",
    "# Declare btutton\n",
    "button = widgets.Button(description = 'Apply')\n",
    "\n",
    "# declare the button callback\n",
    "def button_callback(image):\n",
    "    n      = n_slider.value\n",
    "    check  = checkbox.value\n",
    "    output = clip_fourier(image, 2**n, largest = check, perc = False)\n",
    "    return output\n",
    "\n",
    "# visualize\n",
    "plt.close('all')\n",
    "cfourier_viewer = viewer(zebra, title = \"Clipping the FT\", new_widgets = [n_slider, checkbox, button], callbacks = [button_callback], widgets=True, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6f0d17e8476028f6f44c4d0ca77a2044",
     "grade": false,
     "grade_id": "cell-167b4895c49676c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Multiple Choice Question\n",
    "Congratulations! You made it to the end of the notebook. Now you just need to answer these last two MCQ questions (**0.5 points** each).\n",
    "\n",
    "* Q1: How many largest Fourier coefficients are required to start noting a zebra shape in the image?\n",
    "    1. 1\n",
    "    2. 8\n",
    "    3. $2^8$\n",
    "    4. $8^2$\n",
    "\n",
    "Modify the variable `answer` to reflect your choice. The second cell will raise an error if you have not answered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8cfbb6b7dbe66e6298cacf33c9f441eb",
     "grade": false,
     "grade_id": "ans-ee040ab2d1398a93",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "# assign your answer to this variable\n",
    "answer = 3\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "488087f1aa7a188f5d5e92c570397df0",
     "grade": true,
     "grade_id": "grad-614f5700675a0260",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "assert answer in [1, 2, 3, 4], 'Possible answers are 1, 2, 3 and 4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "Python3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d72c90970f0ab1c52e8d1186e9c3cc6d",
     "grade": false,
     "grade_id": "cell-fea792cc3a05b29b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "* Q2: How is it possible to reconstruct the zebra from only periodic components if the zebra is not periodic (there is only one zebra in the image)?\n",
    "    1. The black and white stripes in the zebra make it possible.\n",
    "    2. The FT assumes that the image is periodic in space.\n",
    "    3. The biggest components of the FT are non-periodic, to account for such features in an image.\n",
    "\n",
    "Modify the variable `answer` to reflect your choice. The second cell will raise an error if you have not answered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "deletable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "023c15dba11f30728b88da14d9e133ef",
     "grade": false,
     "grade_id": "ans-9a7c38e4ea3a4322",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "# Assign your answer to this variable\n",
    "answer = 2\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fce11e97138718a90292b3c43dee2c82",
     "grade": true,
     "grade_id": "grad-08af35ecf1d0b4b8",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%use sos\n",
    "\n",
    "assert answer in [1, 2, 3], 'Possible answers are 1, 2, and 3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "kernel": "SoS",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cdc5a8249c2d01d44f58f02d4ca18e23",
     "grade": false,
     "grade_id": "cell-6deaf74b6ab1ae1f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<p><b>Congratulations on finishing Lab 1!</b></p>\n",
    "<p>\n",
    "Make sure to save your notebook (you might want to keep a copy on your personal computer) and upload it to <a href=\"https://moodle.epfl.ch/course/view.php?id=522\">Moodle</a>.\n",
    "</p>\n",
    "\n",
    "* Name it: *SCIPER_Pixel_Fourier.ipynb* (e.g. *308442_Pixel_Fourier.ipynb*)\n",
    "\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<h4>Feedback</h4>\n",
    "    <p style=\"margin:4px;\">\n",
    "    This is the first edition of the image-processing laboratories using Jupyter Notebooks running on Noto. Do not leave before giving us your <a href=\"https://moodle.epfl.ch/mod/feedback/view.php?id=1097807\">feedback here!</a></p>\n",
    "</div>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "JavaScript",
     "javascript",
     "JavaScript",
     "#c8e1ae",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0
   },
   "version": "0.21.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
